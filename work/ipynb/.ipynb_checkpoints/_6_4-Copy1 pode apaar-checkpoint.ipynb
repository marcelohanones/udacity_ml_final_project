{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Load Libraries / Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../modules/library_to_import.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../modules/Class_imdb.ipynb\n",
    "%run ../modules/transformers_imdb.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "# sns.despine()\n",
    "sns.set()\n",
    "# sns.set(style='white', context='notebook', palette='deep')\n",
    "# sns.set(style='white', palette='deep')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)  \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)  \n",
    "\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "evaluations_all -  it is a dictionary where all the information regarding models performance scores gets recorded. It`s the 'cloud'.\n",
    "\n",
    "By acessing the 'cloud' the Class Super_Analtica will work in groups.\n",
    "Analytica_bolada is lower level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../../data/movie_data.csv')\n",
    "data_raw = pd.read_csv(\"../../data/labeledTrainData.tsv\", header=0, \\\n",
    "                    delimiter=\"\\t\", quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 3 columns):\n",
      "id           25000 non-null object\n",
      "sentiment    25000 non-null int64\n",
      "review       25000 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 586.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data_raw.head()\n",
    "data_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./params_imdb.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.5\n",
       "0    0.5\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.sentiment.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "feature union is for applying different vectorizers for different columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X  y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train , Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = data_raw[:20000]\n",
    "test_raw = data_raw[20000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 3 columns):\n",
      "id           20000 non-null object\n",
      "sentiment    20000 non-null int64\n",
      "review       20000 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 468.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train_raw.head()\n",
    "train_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_style": "split",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>\"3862_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"I just watched it. A couple of laughs, but no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20001</th>\n",
       "      <td>\"674_10\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"While to most people watching the movie, this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20002</th>\n",
       "      <td>\"8828_10\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"I was so glad I came across this short film. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20003</th>\n",
       "      <td>\"2963_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"The creators of south park in their own film ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20004</th>\n",
       "      <td>\"2483_1\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Unspeakably discombobulated turkey, a mix of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  sentiment                                             review\n",
       "20000   \"3862_4\"          0  \"I just watched it. A couple of laughs, but no...\n",
       "20001   \"674_10\"          1  \"While to most people watching the movie, this...\n",
       "20002  \"8828_10\"          1  \"I was so glad I came across this short film. ...\n",
       "20003   \"2963_8\"          1  \"The creators of south park in their own film ...\n",
       "20004   \"2483_1\"          0  \"Unspeakably discombobulated turkey, a mix of ..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 20000 to 24999\n",
      "Data columns (total 3 columns):\n",
      "id           5000 non-null object\n",
      "sentiment    5000 non-null int64\n",
      "review       5000 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 117.3+ KB\n"
     ]
    }
   ],
   "source": [
    "test_raw.head()\n",
    "test_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_raw[:20000][['review']]\n",
    "y = train_raw[:20000][['sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=random_state)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5514</th>\n",
       "      <td>\"There is a DVD published in the UK in 2002 Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>\"Frownland is like one of those intensely emba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5864</th>\n",
       "      <td>\"I rented this because I'm a bit weary of '80s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15865</th>\n",
       "      <td>\"I like bad movies. I like to rent bad movies ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12892</th>\n",
       "      <td>\"The story line was very straight forward and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review\n",
       "5514   \"There is a DVD published in the UK in 2002 Co...\n",
       "1266   \"Frownland is like one of those intensely emba...\n",
       "5864   \"I rented this because I'm a bit weary of '80s...\n",
       "15865  \"I like bad movies. I like to rent bad movies ...\n",
       "12892  \"The story line was very straight forward and ..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(15000, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5514</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5864</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15865</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12892</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment\n",
       "5514           0\n",
       "1266           1\n",
       "5864           0\n",
       "15865          0\n",
       "12892          0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "X_train.head()\n",
    "y_train.shape \n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10650</th>\n",
       "      <td>\"I can't believe that Steven Segal's career ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>\"I wasn't quite sure if this was just going to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8668</th>\n",
       "      <td>\"First of all, if you'r a fan of the comic, we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>\"I really liked this movie, and went back to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13902</th>\n",
       "      <td>\"Yes, CHUNKY, this is the nick-name that Donna...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review\n",
       "10650  \"I can't believe that Steven Segal's career ha...\n",
       "2041   \"I wasn't quite sure if this was just going to...\n",
       "8668   \"First of all, if you'r a fan of the comic, we...\n",
       "1114   \"I really liked this movie, and went back to s...\n",
       "13902  \"Yes, CHUNKY, this is the nick-name that Donna..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(5000, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10650</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8668</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13902</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment\n",
       "10650          0\n",
       "2041           1\n",
       "8668           0\n",
       "1114           1\n",
       "13902          0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape \n",
    "X_val.head()\n",
    "y_val.shape\n",
    "y_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>\"3862_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"I just watched it. A couple of laughs, but no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20001</th>\n",
       "      <td>\"674_10\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"While to most people watching the movie, this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20002</th>\n",
       "      <td>\"8828_10\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"I was so glad I came across this short film. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20003</th>\n",
       "      <td>\"2963_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"The creators of south park in their own film ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20004</th>\n",
       "      <td>\"2483_1\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Unspeakably discombobulated turkey, a mix of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  sentiment                                             review\n",
       "20000   \"3862_4\"          0  \"I just watched it. A couple of laughs, but no...\n",
       "20001   \"674_10\"          1  \"While to most people watching the movie, this...\n",
       "20002  \"8828_10\"          1  \"I was so glad I came across this short film. ...\n",
       "20003   \"2963_8\"          1  \"The creators of south park in their own film ...\n",
       "20004   \"2483_1\"          0  \"Unspeakably discombobulated turkey, a mix of ..."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_raw[['review']]\n",
    "y_test = test_raw[['sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(5000, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "\n",
    "# # DATAFRAMES USED ONLY WHEN NEED MORE THAN 1 COLUMN\n",
    "# WORKS with sklearn-pandas to drive dataframes in sklearn or column extractor e To_Matrix\n",
    "\n",
    "# X_train = df.loc[:100, ['review']].reset_index(drop=True)\n",
    "# y_train = df.loc[:100, ['sentiment']].reset_index(drop=True)\n",
    "# X_test = df.loc[49900:, ['review']].reset_index(drop=True)\n",
    "# y_test = df.loc[49900:, ['sentiment']].reset_index(drop=True)\n",
    "\n",
    "# X_train = df.loc[:2000, ['review']].reset_index(drop=True)\n",
    "# y_train = df.loc[:2000, ['sentiment']].reset_index(drop=True)\n",
    "# X_test = df.loc[49000:, ['review']].reset_index(drop=True)\n",
    "# y_test = df.loc[49000:, ['sentiment']].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# # AQUIIIIIII\n",
    "# X_train = df.loc[:1000, ['review']].reset_index(drop=True)\n",
    "# y_train = df.loc[:1000, ['sentiment']].reset_index(drop=True)\n",
    "# X_test = df.loc[49500:, ['review']].reset_index(drop=True)\n",
    "# y_test = df.loc[49500:, ['sentiment']].reset_index(drop=True)\n",
    "\n",
    "# X_train = df.loc[:10000, ['review']].reset_index(drop=True)\n",
    "# y_train = df.loc[:10000, ['sentiment']].reset_index(drop=True)\n",
    "# X_test = df.loc[40000:, ['review']].reset_index(drop=True)\n",
    "# y_test = df.loc[40000:, ['sentiment']].reset_index(drop=True)\n",
    "\n",
    "# X_train = df.loc[:20000, ['review']].reset_index(drop=True)\n",
    "# y_train = df.loc[:20000, ['sentiment']].reset_index(drop=True)\n",
    "# X_val = df.loc[25000:30000, ['review']].reset_index(drop=True)\n",
    "# y_val = df.loc[25000:30000, ['sentiment']].reset_index(drop=True)\n",
    "# X_test = df.loc[30000:40000, ['review']].reset_index(drop=True)\n",
    "# y_test = df.loc[30000:40000, ['sentiment']].reset_index(drop=True)\n",
    "\n",
    "# X_train = df.loc[:2000, ['review']].reset_index(drop=True)\n",
    "# y_train = df.loc[:2000, ['sentiment']].reset_index(drop=True)\n",
    "# X_val = df.loc[2500:3000, ['review']].reset_index(drop=True)\n",
    "# y_val = df.loc[2500:3000, ['sentiment']].reset_index(drop=True)\n",
    "# X_test = df.loc[3000:4000, ['review']].reset_index(drop=True)\n",
    "# y_test = df.loc[3000:4000, ['sentiment']].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# X_train = df.loc[:20000, ['review']].reset_index(drop=True)\n",
    "# y_train = df.loc[:20000, ['sentiment']].reset_index(drop=True)\n",
    "# X_test = df.loc[45000:, ['review']].reset_index(drop=True)\n",
    "# y_test = df.loc[45000:, ['sentiment']].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# kfold = StratifiedKFold(n_splits=10, shuffle=False, random_state=random_state)\n",
    "kfold = StratifiedKFold(n_splits=8, shuffle=False, random_state=random_state)\n",
    "# kfold = 5\n",
    "# kfold = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_style": "split",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5514</th>\n",
       "      <td>\"There is a DVD published in the UK in 2002 Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>\"Frownland is like one of those intensely emba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5864</th>\n",
       "      <td>\"I rented this because I'm a bit weary of '80s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15865</th>\n",
       "      <td>\"I like bad movies. I like to rent bad movies ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12892</th>\n",
       "      <td>\"The story line was very straight forward and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5742</th>\n",
       "      <td>\"Please, someone stop Ben Stiller from acting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13653</th>\n",
       "      <td>\"The master of movie spectacle Cecil B. De Mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3780</th>\n",
       "      <td>\"This film, as low budget as it may be, is one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12574</th>\n",
       "      <td>\"The female lead was a terrible actress which ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15733</th>\n",
       "      <td>\"One measurement for the greatness of a movie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8985</th>\n",
       "      <td>\"I think 'Blackadder the Third' is the best on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14535</th>\n",
       "      <td>\"Having not seen the films before (and not bei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14107</th>\n",
       "      <td>\"\\\"House Of Evil\\\" aka \\\"Dance Of Death\\\" of 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10206</th>\n",
       "      <td>\"Really, when it comes down to it, this movie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19972</th>\n",
       "      <td>\"Jeez, only in the 70's... Antonio Margheriti ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11811</th>\n",
       "      <td>\"By no means a masterpiece, and far from Errol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>\"For starters, I didn't even know about this s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11276</th>\n",
       "      <td>\"It is so rare that I get to rate a movie with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7752</th>\n",
       "      <td>\"As a person who sought out an existence as a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5857</th>\n",
       "      <td>\"What I liked best in this film is that like t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4514</th>\n",
       "      <td>\"Slashers.....well if you like horrors its def...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7655</th>\n",
       "      <td>\"What else can you say about this movie,except...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12025</th>\n",
       "      <td>\"I have not seen this movie in ages but figure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5908</th>\n",
       "      <td>\"Sogo Ishii has taken the old myth of Musashib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19144</th>\n",
       "      <td>\"I saw the 10p.m. showing and I must say that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>\"I love the frequently misnomered \\\"Masters of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11416</th>\n",
       "      <td>\"Okay...so i've seen a lot of really odd/unusu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8845</th>\n",
       "      <td>\"To begin with, I loved göta kanal 1, it had a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2604</th>\n",
       "      <td>\"This film came recommended as a good action f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9150</th>\n",
       "      <td>\"MY BROTHER TOM &lt;br /&gt;&lt;br /&gt;Aspect ratio: 1.85...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>\"Care Bears Movie 2: A New Generation isn't at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>\"Young Mr. Lincoln marks the first film of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005</th>\n",
       "      <td>\"Prom Night is about a girl named Donna (Britt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19118</th>\n",
       "      <td>\"I saw this movie after i saw Blue Crush and o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>\"Really, everybody in this movie looks like th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2747</th>\n",
       "      <td>\"I'm not sure how I missed this one when it fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18431</th>\n",
       "      <td>\"I just don't get some of the big premises of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18942</th>\n",
       "      <td>\"Well, I suppose the good news concerning Will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8666</th>\n",
       "      <td>\"After her Oscar-nominated turn in \\\"Secrets &amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6396</th>\n",
       "      <td>\"I find it rather useless to comment on this \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19769</th>\n",
       "      <td>\"Yakitate! Ja-pan (translated as Fresh Baked! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17568</th>\n",
       "      <td>\"This review is based on the dubbed Shock-o-Ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6420</th>\n",
       "      <td>\"When I spotted that Noah Wyle and Ricky Schro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5051</th>\n",
       "      <td>\"Ain't it hilarious when an average schmo lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5311</th>\n",
       "      <td>\"Detective Tony Rome (Frank Sinatra) returns t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2433</th>\n",
       "      <td>\"In the very first episode of Friends, which a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>\"I have just recently purchased collection one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>\"The screen writing is so dumb it pains me to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8322</th>\n",
       "      <td>\"Mardi Gras: Made in china is an excellent mov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16023</th>\n",
       "      <td>\"A great story, based on a true story about a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11363</th>\n",
       "      <td>\"Admirably odd, though mean-spirited comedy-dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14423</th>\n",
       "      <td>\"Again Stacy Peralta is true first to the peop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4426</th>\n",
       "      <td>\"Jane Eyre_ is one of the greatest novels in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16850</th>\n",
       "      <td>\"* Firstly, although many say it is the worst ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>\"Such a joyous world has been created for us i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>\"\\\"Shadrach\\\" was not my favorite type of movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11964</th>\n",
       "      <td>\"A friend of mine gave me this movie. A friend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>\"Stewart is a Wyoming cattleman who dreams to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>\"1928 is in many ways a \\\"lost year\\\" in motio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>\"I felt this film - throughout. I waas impress...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review\n",
       "5514   \"There is a DVD published in the UK in 2002 Co...\n",
       "1266   \"Frownland is like one of those intensely emba...\n",
       "5864   \"I rented this because I'm a bit weary of '80s...\n",
       "15865  \"I like bad movies. I like to rent bad movies ...\n",
       "12892  \"The story line was very straight forward and ...\n",
       "5742   \"Please, someone stop Ben Stiller from acting ...\n",
       "13653  \"The master of movie spectacle Cecil B. De Mil...\n",
       "3780   \"This film, as low budget as it may be, is one...\n",
       "12574  \"The female lead was a terrible actress which ...\n",
       "15733  \"One measurement for the greatness of a movie ...\n",
       "8985   \"I think 'Blackadder the Third' is the best on...\n",
       "14535  \"Having not seen the films before (and not bei...\n",
       "14107  \"\\\"House Of Evil\\\" aka \\\"Dance Of Death\\\" of 1...\n",
       "10206  \"Really, when it comes down to it, this movie ...\n",
       "19972  \"Jeez, only in the 70's... Antonio Margheriti ...\n",
       "11811  \"By no means a masterpiece, and far from Errol...\n",
       "1566   \"For starters, I didn't even know about this s...\n",
       "11276  \"It is so rare that I get to rate a movie with...\n",
       "7752   \"As a person who sought out an existence as a ...\n",
       "5857   \"What I liked best in this film is that like t...\n",
       "4514   \"Slashers.....well if you like horrors its def...\n",
       "7655   \"What else can you say about this movie,except...\n",
       "12025  \"I have not seen this movie in ages but figure...\n",
       "5908   \"Sogo Ishii has taken the old myth of Musashib...\n",
       "19144  \"I saw the 10p.m. showing and I must say that ...\n",
       "1544   \"I love the frequently misnomered \\\"Masters of...\n",
       "11416  \"Okay...so i've seen a lot of really odd/unusu...\n",
       "8845   \"To begin with, I loved göta kanal 1, it had a...\n",
       "2604   \"This film came recommended as a good action f...\n",
       "9150   \"MY BROTHER TOM <br /><br />Aspect ratio: 1.85...\n",
       "...                                                  ...\n",
       "1267   \"Care Bears Movie 2: A New Generation isn't at...\n",
       "1899   \"Young Mr. Lincoln marks the first film of the...\n",
       "3005   \"Prom Night is about a girl named Donna (Britt...\n",
       "19118  \"I saw this movie after i saw Blue Crush and o...\n",
       "189    \"Really, everybody in this movie looks like th...\n",
       "2747   \"I'm not sure how I missed this one when it fi...\n",
       "18431  \"I just don't get some of the big premises of ...\n",
       "18942  \"Well, I suppose the good news concerning Will...\n",
       "8666   \"After her Oscar-nominated turn in \\\"Secrets &...\n",
       "6396   \"I find it rather useless to comment on this \\...\n",
       "19769  \"Yakitate! Ja-pan (translated as Fresh Baked! ...\n",
       "17568  \"This review is based on the dubbed Shock-o-Ra...\n",
       "6420   \"When I spotted that Noah Wyle and Ricky Schro...\n",
       "5051   \"Ain't it hilarious when an average schmo lead...\n",
       "5311   \"Detective Tony Rome (Frank Sinatra) returns t...\n",
       "2433   \"In the very first episode of Friends, which a...\n",
       "769    \"I have just recently purchased collection one...\n",
       "1685   \"The screen writing is so dumb it pains me to ...\n",
       "8322   \"Mardi Gras: Made in china is an excellent mov...\n",
       "16023  \"A great story, based on a true story about a ...\n",
       "11363  \"Admirably odd, though mean-spirited comedy-dr...\n",
       "14423  \"Again Stacy Peralta is true first to the peop...\n",
       "4426   \"Jane Eyre_ is one of the greatest novels in t...\n",
       "16850  \"* Firstly, although many say it is the worst ...\n",
       "6265   \"Such a joyous world has been created for us i...\n",
       "11284  \"\\\"Shadrach\\\" was not my favorite type of movi...\n",
       "11964  \"A friend of mine gave me this movie. A friend...\n",
       "5390   \"Stewart is a Wyoming cattleman who dreams to ...\n",
       "860    \"1928 is in many ways a \\\"lost year\\\" in motio...\n",
       "15795  \"I felt this film - throughout. I waas impress...\n",
       "\n",
       "[15000 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_style": "split",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>\"I just watched it. A couple of laughs, but no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20001</th>\n",
       "      <td>\"While to most people watching the movie, this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20002</th>\n",
       "      <td>\"I was so glad I came across this short film. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20003</th>\n",
       "      <td>\"The creators of south park in their own film ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20004</th>\n",
       "      <td>\"Unspeakably discombobulated turkey, a mix of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20005</th>\n",
       "      <td>\"If an auteur gives himself 2 credits before t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20006</th>\n",
       "      <td>\"I can't believe that so much talent can be wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20007</th>\n",
       "      <td>\"This should be re-titled \\\"The Curious Case O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20008</th>\n",
       "      <td>\"A woman who hates cats (Alice Krige) and her ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20009</th>\n",
       "      <td>\"I've always been a great fan of Woody Allen a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20010</th>\n",
       "      <td>\"Mesmerizing, breathtaking and horrifying, thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20011</th>\n",
       "      <td>\"\\\"Houseboat Horror\\\" is often regarded as the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20012</th>\n",
       "      <td>\"I saw this film under the title of \\\"Tied Up\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20013</th>\n",
       "      <td>\"If you like a syfi soap opera this show is fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20014</th>\n",
       "      <td>\"The longer this film went on-and it seemed to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20015</th>\n",
       "      <td>\"It's the same old, \\\"If I can't get the fundi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20016</th>\n",
       "      <td>\"The Cowboys could leave you a little sore in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20017</th>\n",
       "      <td>\"War is hell. But this documentary of WWII is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20018</th>\n",
       "      <td>\"This final Voyager episode begins 23 years in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20019</th>\n",
       "      <td>\"I guess you have to give some points for the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20020</th>\n",
       "      <td>\"\\\"Rois et Reine\\\" is a sprawling mess of a mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20021</th>\n",
       "      <td>\"This series gets 2 stars solely because it pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20022</th>\n",
       "      <td>\"I cannot stop saying how much I loved this mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20023</th>\n",
       "      <td>\"What a time we live in when someone like this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20024</th>\n",
       "      <td>\"Just the fact that the cover is a drawing, li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20025</th>\n",
       "      <td>\"1927, and Hollywood had been on the map as th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20026</th>\n",
       "      <td>\"i was disappointed. the film was a bit predic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20027</th>\n",
       "      <td>\"Excellent, pre-code amoral tale with Barbara ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20028</th>\n",
       "      <td>\"The Menagerie parts one and two was the only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20029</th>\n",
       "      <td>\"I just saw this film on Turner Classic Movies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24970</th>\n",
       "      <td>\"Red Rock West (1993)&lt;br /&gt;&lt;br /&gt;Nicolas Cage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24971</th>\n",
       "      <td>\"what can i say?, ms Erika Eleniak is my favor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24972</th>\n",
       "      <td>\"The spoiler warning is for those people who w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24973</th>\n",
       "      <td>\"What do you call a horror story without horro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24974</th>\n",
       "      <td>\"Though not a horror film in the traditional s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24975</th>\n",
       "      <td>\"This was what black society was like before t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24976</th>\n",
       "      <td>\"They probably should have called this movie T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24977</th>\n",
       "      <td>\"Attractive Marjorie(Farrah Fawcett)lives in f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24978</th>\n",
       "      <td>\"Vaguely reminiscent of great 1940's westerns,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24979</th>\n",
       "      <td>\"I admit I had no idea what to expect before v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24980</th>\n",
       "      <td>\"To me, the final scene, in which Harris respo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24981</th>\n",
       "      <td>\"This is by far the funniest short made by the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24982</th>\n",
       "      <td>\"To be a Buster Keaton fan is to have your hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24983</th>\n",
       "      <td>\"I was one of those \\\"few Americans\\\" that gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24984</th>\n",
       "      <td>\"Visually disjointed and full of itself, the d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24985</th>\n",
       "      <td>\"this movie had more holes than a piece of swi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24986</th>\n",
       "      <td>\"Last November, I had a chance to see this fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24987</th>\n",
       "      <td>\"First off, I'd like to make a correction on a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24988</th>\n",
       "      <td>\"While originally reluctant to jump on the ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24989</th>\n",
       "      <td>\"I heard about this movie when watching VH1's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24990</th>\n",
       "      <td>\"I've never been huge on IMAX films. They're c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24991</th>\n",
       "      <td>\"Steve McQueen has certainly a lot of loyal fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24992</th>\n",
       "      <td>\"Sometimes you wonder how some people get fund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24993</th>\n",
       "      <td>\"I am a student of film, and have been for sev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>\"Unimaginably stupid, redundant and humiliatin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>\"It seems like more consideration has gone int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>\"I don't believe they made this film. Complete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>\"Guy is a loser. Can't get girls, needs to bui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>\"This 30 minute documentary Buñuel made in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>\"I saw this movie as a child and it broke my h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review\n",
       "20000  \"I just watched it. A couple of laughs, but no...\n",
       "20001  \"While to most people watching the movie, this...\n",
       "20002  \"I was so glad I came across this short film. ...\n",
       "20003  \"The creators of south park in their own film ...\n",
       "20004  \"Unspeakably discombobulated turkey, a mix of ...\n",
       "20005  \"If an auteur gives himself 2 credits before t...\n",
       "20006  \"I can't believe that so much talent can be wa...\n",
       "20007  \"This should be re-titled \\\"The Curious Case O...\n",
       "20008  \"A woman who hates cats (Alice Krige) and her ...\n",
       "20009  \"I've always been a great fan of Woody Allen a...\n",
       "20010  \"Mesmerizing, breathtaking and horrifying, thi...\n",
       "20011  \"\\\"Houseboat Horror\\\" is often regarded as the...\n",
       "20012  \"I saw this film under the title of \\\"Tied Up\\...\n",
       "20013  \"If you like a syfi soap opera this show is fo...\n",
       "20014  \"The longer this film went on-and it seemed to...\n",
       "20015  \"It's the same old, \\\"If I can't get the fundi...\n",
       "20016  \"The Cowboys could leave you a little sore in ...\n",
       "20017  \"War is hell. But this documentary of WWII is ...\n",
       "20018  \"This final Voyager episode begins 23 years in...\n",
       "20019  \"I guess you have to give some points for the ...\n",
       "20020  \"\\\"Rois et Reine\\\" is a sprawling mess of a mo...\n",
       "20021  \"This series gets 2 stars solely because it pu...\n",
       "20022  \"I cannot stop saying how much I loved this mo...\n",
       "20023  \"What a time we live in when someone like this...\n",
       "20024  \"Just the fact that the cover is a drawing, li...\n",
       "20025  \"1927, and Hollywood had been on the map as th...\n",
       "20026  \"i was disappointed. the film was a bit predic...\n",
       "20027  \"Excellent, pre-code amoral tale with Barbara ...\n",
       "20028  \"The Menagerie parts one and two was the only ...\n",
       "20029  \"I just saw this film on Turner Classic Movies...\n",
       "...                                                  ...\n",
       "24970  \"Red Rock West (1993)<br /><br />Nicolas Cage ...\n",
       "24971  \"what can i say?, ms Erika Eleniak is my favor...\n",
       "24972  \"The spoiler warning is for those people who w...\n",
       "24973  \"What do you call a horror story without horro...\n",
       "24974  \"Though not a horror film in the traditional s...\n",
       "24975  \"This was what black society was like before t...\n",
       "24976  \"They probably should have called this movie T...\n",
       "24977  \"Attractive Marjorie(Farrah Fawcett)lives in f...\n",
       "24978  \"Vaguely reminiscent of great 1940's westerns,...\n",
       "24979  \"I admit I had no idea what to expect before v...\n",
       "24980  \"To me, the final scene, in which Harris respo...\n",
       "24981  \"This is by far the funniest short made by the...\n",
       "24982  \"To be a Buster Keaton fan is to have your hea...\n",
       "24983  \"I was one of those \\\"few Americans\\\" that gre...\n",
       "24984  \"Visually disjointed and full of itself, the d...\n",
       "24985  \"this movie had more holes than a piece of swi...\n",
       "24986  \"Last November, I had a chance to see this fil...\n",
       "24987  \"First off, I'd like to make a correction on a...\n",
       "24988  \"While originally reluctant to jump on the ban...\n",
       "24989  \"I heard about this movie when watching VH1's ...\n",
       "24990  \"I've never been huge on IMAX films. They're c...\n",
       "24991  \"Steve McQueen has certainly a lot of loyal fa...\n",
       "24992  \"Sometimes you wonder how some people get fund...\n",
       "24993  \"I am a student of film, and have been for sev...\n",
       "24994  \"Unimaginably stupid, redundant and humiliatin...\n",
       "24995  \"It seems like more consideration has gone int...\n",
       "24996  \"I don't believe they made this film. Complete...\n",
       "24997  \"Guy is a loser. Can't get girls, needs to bui...\n",
       "24998  \"This 30 minute documentary Buñuel made in the...\n",
       "24999  \"I saw this movie as a child and it broke my h...\n",
       "\n",
       "[5000 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_style": "split",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5514</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5864</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15865</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12892</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5742</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13653</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3780</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12574</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15733</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8985</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14535</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14107</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10206</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19972</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11811</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11276</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7752</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5857</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4514</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7655</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12025</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5908</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19144</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11416</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8845</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2604</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9150</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19118</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2747</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18431</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18942</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8666</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6396</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19769</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17568</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6420</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5051</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5311</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2433</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8322</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16023</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11363</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14423</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4426</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16850</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11964</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment\n",
       "5514           0\n",
       "1266           1\n",
       "5864           0\n",
       "15865          0\n",
       "12892          0\n",
       "5742           0\n",
       "13653          1\n",
       "3780           1\n",
       "12574          0\n",
       "15733          1\n",
       "8985           1\n",
       "14535          1\n",
       "14107          0\n",
       "10206          0\n",
       "19972          0\n",
       "11811          1\n",
       "1566           1\n",
       "11276          0\n",
       "7752           1\n",
       "5857           1\n",
       "4514           0\n",
       "7655           0\n",
       "12025          0\n",
       "5908           1\n",
       "19144          0\n",
       "1544           0\n",
       "11416          0\n",
       "8845           1\n",
       "2604           0\n",
       "9150           0\n",
       "...          ...\n",
       "1267           1\n",
       "1899           1\n",
       "3005           0\n",
       "19118          1\n",
       "189            0\n",
       "2747           1\n",
       "18431          0\n",
       "18942          0\n",
       "8666           1\n",
       "6396           0\n",
       "19769          1\n",
       "17568          0\n",
       "6420           0\n",
       "5051           0\n",
       "5311           0\n",
       "2433           1\n",
       "769            1\n",
       "1685           0\n",
       "8322           1\n",
       "16023          1\n",
       "11363          0\n",
       "14423          1\n",
       "4426           0\n",
       "16850          1\n",
       "6265           1\n",
       "11284          0\n",
       "11964          0\n",
       "5390           1\n",
       "860            1\n",
       "15795          1\n",
       "\n",
       "[15000 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_style": "split",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20001</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20002</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20003</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20004</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20005</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20006</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20007</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20008</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20009</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20010</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20011</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20012</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20013</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20014</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20015</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20016</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20017</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20018</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20019</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20020</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20021</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20022</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20023</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20024</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20025</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20026</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20027</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20028</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20029</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24970</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24971</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24972</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24973</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24974</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24975</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24976</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24977</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24978</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24979</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24980</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24981</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24982</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24983</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24984</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24985</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24986</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24987</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24988</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24989</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24990</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24991</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24992</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24993</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment\n",
       "20000          0\n",
       "20001          1\n",
       "20002          1\n",
       "20003          1\n",
       "20004          0\n",
       "20005          0\n",
       "20006          0\n",
       "20007          0\n",
       "20008          1\n",
       "20009          0\n",
       "20010          1\n",
       "20011          0\n",
       "20012          0\n",
       "20013          0\n",
       "20014          0\n",
       "20015          0\n",
       "20016          0\n",
       "20017          1\n",
       "20018          1\n",
       "20019          0\n",
       "20020          0\n",
       "20021          0\n",
       "20022          1\n",
       "20023          0\n",
       "20024          0\n",
       "20025          1\n",
       "20026          0\n",
       "20027          1\n",
       "20028          1\n",
       "20029          1\n",
       "...          ...\n",
       "24970          1\n",
       "24971          1\n",
       "24972          1\n",
       "24973          0\n",
       "24974          1\n",
       "24975          1\n",
       "24976          0\n",
       "24977          1\n",
       "24978          1\n",
       "24979          1\n",
       "24980          1\n",
       "24981          1\n",
       "24982          0\n",
       "24983          0\n",
       "24984          0\n",
       "24985          0\n",
       "24986          1\n",
       "24987          1\n",
       "24988          1\n",
       "24989          1\n",
       "24990          1\n",
       "24991          0\n",
       "24992          0\n",
       "24993          0\n",
       "24994          0\n",
       "24995          0\n",
       "24996          0\n",
       "24997          0\n",
       "24998          0\n",
       "24999          1\n",
       "\n",
       "[5000 rows x 1 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cell_style": "split",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "# X_train.info()\n",
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cell_style": "split",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n",
    "# y_train.info()\n",
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(5000, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape\n",
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_style": "split",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n",
    "# X_test.info()\n",
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cell_style": "split",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape\n",
    "# y_train.info()\n",
    "type(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_split(text):\n",
    "    return [porter.stem(w) for w in text.split(' ')]\n",
    "\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(w) for w in text.split(' ') if not w in stop_words ]\n",
    "\n",
    "tfidf = TfidfVectorizer(strip_accents=None, lowercase=False, preprocessor=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = Super_Analytica('master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../modules/params_imdb.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Implementacao que da erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# implementacao sem predict_proba\n",
    "class A2(object):\n",
    "\n",
    "    def __init__(self, instance, param_grid, my_name):\n",
    "        self.my_name = my_name\n",
    "        self.instance = instance\n",
    "        self.param_grid = param_grid\n",
    "        \n",
    "    def evaluate_HP_lGBM(self, pipe, pkl_W=False): \n",
    "        '''\n",
    "        aceita pipeline sem o step final. pipe.append()\n",
    "        '''\n",
    "        start= timer()\n",
    "        result_dict = {}\n",
    "\n",
    "    #         key = self.my_name.split('_')[0] # to use in pipe. From KNN_2 -> KNN. Must mach param_grid prefix\n",
    "        instance = self.instance\n",
    "        param_grid = self.param_grid\n",
    "\n",
    "        pipe_copy = None\n",
    "        pipe_copy = clone(pipe)\n",
    "        pipe_copy.steps.append([instance, clf[instance]])\n",
    "\n",
    "        def objective(params):\n",
    "            # Make sure parameters that need to be integers are integers\n",
    "            for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "                params[parameter_name] = int(params[parameter_name])\n",
    "\n",
    "\n",
    "            score = lgb.cv(params, data_train, nfold = 10, num_boost_round = 10000, \n",
    "                        early_stopping_rounds = 10, metrics = 'auc', seed = 50)\n",
    "            best_score = max(score['auc-mean'])\n",
    "            print(best_score)\n",
    "            return 1 - best_score\n",
    "\n",
    "        train_feature_matrix = pipe.fit_transform(X_train) # pipe descalco sem o ultimo\n",
    "        data_train = lgb.Dataset(train_feature_matrix, label=list(y_train.values.ravel()))\n",
    "\n",
    "        test_feature_matrix = pipe.fit_transform(X_test) # pipe descalco sem o ultimo\n",
    "        data_test = lgb.Dataset(test_feature_matrix, label=list(y_test.values.ravel()))\n",
    "\n",
    "\n",
    "        T = Trials()\n",
    "        space = param_grid\n",
    "        best = fmin(objective, space, algo=tpe.suggest, max_evals=5, trials=T)  #  <---------------------------HERE<-----\n",
    "        best_params = space_eval(space, best) # is the translation of best. Real Values, not steps.\n",
    "\n",
    "        for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "                best_params[parameter_name] = int(best_params[parameter_name])\n",
    "\n",
    "\n",
    "        best_model = lgb.train(best_params, data_train, valid_sets=[data_test], valid_names=['data_test'])   \n",
    "        print(best_model)\n",
    "#         y_pred = best_model.predict(test_feature_matrix)\n",
    "        y_pred = best_model.predict(test_feature_matrix)   # -------> AQUI o ERRO !!!!!!!\n",
    "        print(y_pred)\n",
    "        acc = accuracy_score(y_test, y_pred) \n",
    "        print('acc :', acc)\n",
    "        end = timer()\n",
    "        minutes_elapsed = (end - start)//60\n",
    "        Super_Analytica.evaluations_all[self.my_name] = {'score': acc, 'best_estimator': best_model, \\\n",
    "                                 'param_grid': param_grid, 'y_pred': y_pred, \\\n",
    "                                 'param_pipe': pipe_copy, 'instance':instance,\\\n",
    "                                 'best_params' : best_params, 'T': T, 'minutes': minutes_elapsed} \n",
    "\n",
    "\n",
    "        if  pkl_W:\n",
    "            D = {}\n",
    "            D[self.my_name]= Super_Analytica.evaluations_all[self.my_name]\n",
    "            joblib.dump(D, '../pkl/clf_'+ self.my_name + '.pkl') \n",
    "            print(self.my_name, ' HP_lightGBM and pickled to disk Done in',  minutes_elapsed, ' minutes' ) \n",
    "        else:\n",
    "            print(self.my_name, '  HP_lightGBM done in ', minutes_elapsed, ' minutes') \n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Por alguma razao o metodo predict esta gerando probabilidades ao inves de previsoes binarias [0,1]. Por isso o erro em accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "clf['LGBM'] = lgb.LGBMClassifier(objective = 'binary', metric = ['auc'])\n",
    "md_LGBM = A2('LGBM', param['LGBM2'], '_1')\n",
    "md_LGBM.evaluate_HP_lGBM(pipe_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGNM Tests YYYEEahhhhhhhhh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]\n",
    "\n",
    "    \n",
    "pipe_4 = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "    ('to_array', To_array()),\n",
    "    ('vec', TfidfVectorizer(stop_words='english'))\n",
    "])\n",
    "\n",
    "# TREES\n",
    "pipe_9 = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "    ('to_array', To_array()),\n",
    "    ('vec', TfidfVectorizer(max_features=4000, stop_words='english', tokenizer=LemmaTokenizer())),\n",
    "    ('kbest', SelectPercentile(chi2))\n",
    "])\n",
    "\n",
    "#KNN\n",
    "pipe_11 = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "    ('to_array', To_array()),\n",
    "    ('vec', TfidfVectorizer(max_features=20000, stop_words='english'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf['LGBM'] = lgb.LGBMClassifier(objective = 'binary', metric = 'auc')\n",
    "# clf['LGBM'] = lgb.LGBMClassifier(objective = 'multiclass', metric = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "param['LGBM2'] = {\n",
    "    'num_leaves': hp.choice('num_leaves',[15, 31, 63, 127, 255, 511, 1023, 2047, 4095]),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n",
    "    'max_depth': hp.choice('max_depth', range(4,13)),\n",
    "    'subsample_for_bin': 200000\n",
    "}\n",
    "param_grid = param['LGBM2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .cv  -->prone to overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementacao SKLEARN API \n",
    "# com predict proba\n",
    "class A2(object):\n",
    "\n",
    "    def __init__(self, instance, param_grid, my_name):\n",
    "        self.my_name = my_name\n",
    "        self.instance = instance\n",
    "        self.param_grid = param_grid\n",
    "        \n",
    "    def evaluate_HP_lGBM(self, pipe, pkl_W=False): \n",
    "        '''\n",
    "        aceita pipeline sem o step final. pipe.append()\n",
    "        '''\n",
    "        start= timer()\n",
    "        result_dict = {}\n",
    "\n",
    "        instance = self.instance\n",
    "        param_grid = self.param_grid\n",
    "\n",
    "        pipe_copy = None\n",
    "        pipe_copy = clone(pipe)\n",
    "        pipe_copy.steps.append([instance, clf[instance]])\n",
    "\n",
    "        def objective(params):\n",
    "            # Make sure parameters that need to be integers are integers\n",
    "            for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "#             for parameter_name in ['num_leaves']:\n",
    "                params[parameter_name] = int(params[parameter_name])\n",
    "\n",
    "            score = lgb.cv(params, data_train, nfold = 10, num_boost_round = 100, \n",
    "                        early_stopping_rounds = 10, metrics = 'auc', seed = 50)\n",
    "            best_score = max(score['auc-mean'])\n",
    "            print('cv score:',  best_score)\n",
    "            return 1 - best_score\n",
    "\n",
    "        train_feature_matrix = pipe.fit_transform(X_train) # pipe descalco sem o ultimo\n",
    "        data_train = lgb.Dataset(train_feature_matrix, label=list(y_train.values.ravel()))\n",
    "\n",
    "        test_feature_matrix = pipe.fit_transform(X_test) # pipe descalco sem o ultimo\n",
    "        data_test = lgb.Dataset(test_feature_matrix, label=list(y_test.values.ravel()))\n",
    "\n",
    "        T = Trials()\n",
    "        space = param_grid\n",
    "        best = fmin(objective, space, algo=tpe.suggest, max_evals=5, trials=T)  #  <---------------------------HERE<-----\n",
    "        best_params = space_eval(space, best) \n",
    "\n",
    "        for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "                best_params[parameter_name] = int(best_params[parameter_name])\n",
    "\n",
    "        best_model = clf[instance].set_params(**best_params)\n",
    "        best_model.fit(train_feature_matrix, y_train.values.ravel())\n",
    "        y_pred = best_model.predict_proba(test_feature_matrix)[:,1]\n",
    "#         y_pred = best_model.predict(test_feature_matrix)\n",
    "#         print(y_pred)\n",
    "        acc = roc_auc_score(y_test, y_pred) \n",
    "        print('acc :', acc)\n",
    "        end = timer()\n",
    "        minutes_elapsed = (end - start)//60\n",
    "        Super_Analytica.evaluations_all[self.my_name] = {'score': acc, 'best_estimator': best_model, \\\n",
    "                                 'param_grid': param_grid, 'y_pred': y_pred, \n",
    "                                 'param_pipe': pipe_copy, 'instance':instance, # é somente uma string, nao é a instance em si\\ \n",
    "                                 'best_params' : best_params, 'T': T, 'minutes': minutes_elapsed} \n",
    "\n",
    "\n",
    "        if  pkl_W:\n",
    "            D = {}\n",
    "            D[self.my_name]= Super_Analytica.evaluations_all[self.my_name]\n",
    "            joblib.dump(D, '../pkl/clf_'+ self.my_name + '.pkl') \n",
    "            print(self.my_name, ' HP_lightGBM and pickled to disk Done in',  minutes_elapsed, ' minutes' ) \n",
    "        else:\n",
    "            print(self.my_name, '  HP_lightGBM done in ', minutes_elapsed, ' minutes') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_10 = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "    ('to_array', To_array()),\n",
    "    ('vec', TfidfVectorizer(max_features=15000, stop_words='english')),\n",
    "    ('svd', TruncatedSVD(n_components=400))\n",
    "])\n",
    "\n",
    "\n",
    "# se implementar transformando o data set antes, sera q o kernel aguenta max_feat=20k ?\n",
    "# usando SVD rolou bem mesmo com max_features = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score: 0.9043274646331323\n",
      "cv score: 0.9010760346995147\n",
      "cv score: 0.9072678369970963\n",
      "cv score: 0.9105944107530679\n",
      "cv score: 0.9019702717170768\n",
      "acc : 0.6947127447667035\n",
      "_1   HP_lightGBM done in  3.0  minutes\n"
     ]
    }
   ],
   "source": [
    "md_LGBM2 = A2('LGBM', param['LGBM2'], '_1')\n",
    "md_LGBM2.evaluate_HP_lGBM(pipe_10)\n",
    "\n",
    "# aumentando n_fold reduz o overfitting ?  Nao rodou com fold = 10 e max_feat =None\n",
    "# max_feat=20k svd__n_components=400 - ?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-42-0f96026f6f6b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-42-0f96026f6f6b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pare aqui espertinho\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pare aqui espertinho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementacao SKLEARN API \n",
    "# com predict proba\n",
    "class A2(object):\n",
    "\n",
    "    def __init__(self, instance, param_grid, my_name):\n",
    "        self.my_name = my_name\n",
    "        self.instance = instance\n",
    "        self.param_grid = param_grid\n",
    "        \n",
    "    def evaluate_HP_lGBM_val(self, pipe, pkl_W=False): \n",
    "        '''\n",
    "        aceita pipeline sem o step final. pipe.append()\n",
    "        '''\n",
    "        start= timer()\n",
    "        result_dict = {}\n",
    "\n",
    "        instance = self.instance\n",
    "        param_grid = self.param_grid\n",
    "\n",
    "        pipe_copy = None\n",
    "        pipe_copy = clone(pipe)\n",
    "        pipe_copy.steps.append([instance, clf[instance]])\n",
    "\n",
    "        def objective(params):\n",
    "            # Make sure parameters that need to be integers are integers\n",
    "            for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "                params[parameter_name] = int(params[parameter_name])\n",
    "\n",
    "            model = clf[instance].set_params(**params)\n",
    "            model.fit(train_feature_matrix, y_train, eval_set=(val_feature_matrix, y_val), eval_names=['val_feature_matrix', 'y_val'], eval_metric='auc', early_stopping_rounds=10)             \n",
    "            best_score = model.best_score_['val_feature_matrix']['auc']\n",
    "            return 1 - best_score\n",
    "\n",
    "\n",
    "        train_feature_matrix = pipe.fit_transform(X_train) # pipe descalco sem o ultimo\n",
    "        data_train = lgb.Dataset(train_feature_matrix, label=list(y_train.values.ravel()))\n",
    "\n",
    "        test_feature_matrix = pipe.fit_transform(X_test) # pipe descalco sem o ultimo\n",
    "        data_test = lgb.Dataset(test_feature_matrix, label=list(y_test.values.ravel()))\n",
    "        \n",
    "        val_feature_matrix = pipe.fit_transform(X_val) \n",
    "\n",
    "        T = Trials()\n",
    "        space = param_grid\n",
    "        best = fmin(objective, space, algo=tpe.suggest, max_evals=5, trials=T)  #  <---------------------------HERE<-----\n",
    "        best_params = space_eval(space, best) \n",
    "\n",
    "        for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "                best_params[parameter_name] = int(best_params[parameter_name])\n",
    "\n",
    "        best_model = clf[instance].set_params(**best_params)\n",
    "        best_model.fit(train_feature_matrix, y_train.values.ravel())\n",
    "        y_pred = best_model.predict_proba(test_feature_matrix)[:,1]\n",
    "#         y_pred = best_model.predict(test_feature_matrix)\n",
    "#         print(y_pred)\n",
    "        acc = roc_auc_score(y_test, y_pred) \n",
    "        print('acc :', acc)\n",
    "        end = timer()\n",
    "        minutes_elapsed = (end - start)//60\n",
    "        Super_Analytica.evaluations_all[self.my_name] = {'score': acc, 'best_estimator': best_model, \\\n",
    "                                 'param_grid': param_grid, 'y_pred': y_pred, \n",
    "                                 'param_pipe': pipe_copy, 'instance':instance, # é somente uma string, nao é a instance em si\\ \n",
    "                                 'best_params' : best_params, 'T': T, 'minutes': minutes_elapsed} \n",
    "\n",
    "\n",
    "        if  pkl_W:\n",
    "            D = {}\n",
    "            D[self.my_name]= Super_Analytica.evaluations_all[self.my_name]\n",
    "            joblib.dump(D, '../pkl/clf_'+ self.my_name + '.pkl') \n",
    "            print(self.my_name, ' HP_lightGBM and pickled to disk Done in',  minutes_elapsed, ' minutes' ) \n",
    "        else:\n",
    "            print(self.my_name, '  HP_lightGBM done in ', minutes_elapsed, ' minutes') \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "md_LGBM3 = A2('LGBM', param['LGBM2'], '_3')\n",
    "md_LGBM3.evaluate_HP_lGBM_val(pipe_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pare aqui espertinho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### direto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start= timer()\n",
    "result_dict = {}\n",
    "\n",
    "pipe = pipe_10\n",
    "instance = 'LGBM'\n",
    "param_grid = param['LGBM2']\n",
    "\n",
    "pipe_copy = None\n",
    "pipe_copy = clone(pipe)\n",
    "pipe_copy.steps.append([instance, clf[instance]])\n",
    "\n",
    "def objective(params):\n",
    "    # Make sure parameters that need to be integers are integers\n",
    "    for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "#             for parameter_name in ['num_leaves']:\n",
    "        params[parameter_name] = int(params[parameter_name])\n",
    "\n",
    "    model = clf[instance].set_params(**params)\n",
    "    model.fit(train_feature_matrix, y_train, eval_set=(val_feature_matrix, y_val), eval_names=['val_feature_matrix', 'y_val'], eval_metric='auc', early_stopping_rounds=10)             \n",
    "    best_score = model.best_score_['val_feature_matrix']['auc']\n",
    "    return 1 - best_score\n",
    "\n",
    "train_feature_matrix = pipe.fit_transform(X_train) # pipe descalco sem o ultimo\n",
    "data_train = lgb.Dataset(train_feature_matrix, label=list(y_train.values.ravel()))\n",
    "\n",
    "test_feature_matrix = pipe.fit_transform(X_test) # pipe descalco sem o ultimo\n",
    "data_test = lgb.Dataset(test_feature_matrix, label=list(y_test.values.ravel()))\n",
    "\n",
    "val_feature_matrix = pipe.fit_transform(X_val) # pipe descalco sem o ultimo\n",
    "# data_test = lgb.Dataset(test_feature_matrix, label=list(y_test.values.ravel()))\n",
    "\n",
    "\n",
    "T = Trials()\n",
    "space = param_grid\n",
    "best = fmin(objective, space, algo=tpe.suggest, max_evals=10, trials=T)  #  <---------------------------HERE<-----\n",
    "best_params = space_eval(space, best) \n",
    "\n",
    "for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "        best_params[parameter_name] = int(best_params[parameter_name])\n",
    "\n",
    "best_model = clf[instance].set_params(**best_params)\n",
    "best_model.fit(train_feature_matrix, y_train.values.ravel())\n",
    "y_pred = best_model.predict_proba(test_feature_matrix)[:,1]\n",
    "#         y_pred = best_model.predict(test_feature_matrix)\n",
    "#         print(y_pred)\n",
    "acc = roc_auc_score(y_test, y_pred) \n",
    "print('acc :', acc)\n",
    "end = timer()\n",
    "minutes_elapsed = (end - start)//60\n",
    "Super_Analytica.evaluations_all[self.my_name] = {'score': acc, 'best_estimator': best_model, \\\n",
    "                         'param_grid': param_grid, 'y_pred': y_pred, \n",
    "                         'param_pipe': pipe_copy, 'instance':instance, # é somente uma string, nao é a instance em si\\ \n",
    "                         'best_params' : best_params, 'T': T, 'minutes': minutes_elapsed} \n",
    "\n",
    "\n",
    "if  pkl_W:\n",
    "    D = {}\n",
    "    D[self.my_name]= Super_Analytica.evaluations_all[self.my_name]\n",
    "    joblib.dump(D, '../pkl/clf_'+ self.my_name + '.pkl') \n",
    "    print(self.my_name, ' HP_lightGBM and pickled to disk Done in',  minutes_elapsed, ' minutes' ) \n",
    "else:\n",
    "    print(self.my_name, '  HP_lightGBM done in ', minutes_elapsed, ' minutes') \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hp.choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "param['LGBM3'] = {\n",
    "\n",
    "    'num_leaves': hp.choice('num_leaves', [15, 31, 63, 127, 255, 511, 1023, 2047, 4095]),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n",
    "    'max_depth': hp.choice('max_depth', range(4, 13)),\n",
    "    'boosting_type': hp.choice('boosting_type', [\n",
    "        {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'subsample': hp.uniform('gdbt_subsample', 0.5, 1)\n",
    "        },\n",
    "        {\n",
    "            'boosting_type': 'dart',\n",
    "            'subsample': hp.uniform('dart_subsample', 0.5, 1)\n",
    "        },\n",
    "        {'boosting_type': 'goss'}\n",
    "    ]),\n",
    "    'subsample_for_bin': 200000\n",
    "\n",
    "}\n",
    "sample(param['LGBM3'])\n",
    "param_grid = param['LGBM3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "md_LGBM3 = A2('LGBM', param['LGBM3'], '_3')\n",
    "md_LGBM3.evaluate_HP_lGBM_val(pipe_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param['LGBM4'] = {\n",
    "    'class_weight': hp.choice('class_weight', [None, 'balanced']),\n",
    "    'boosting_type': hp.choice('boosting_type', [{'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}, \n",
    "                                                 {'boosting_type': 'dart', 'subsample': hp.uniform('dart_subsample', 0.5, 1)},\n",
    "                                                 {'boosting_type': 'goss', 'subsample': 1.0}]),\n",
    "    'num_leaves': hp.quniform('num_leaves', 30, 150, 1),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "    'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boosting_type and subsample are mandatory as param in space\n",
    "\n",
    "\n",
    "start = timer()\n",
    "result_dict = {}\n",
    "\n",
    "pipe = pipe_10\n",
    "instance = 'LGBM'\n",
    "param_grid = param['LGBM4']\n",
    "\n",
    "pipe_copy = None\n",
    "# pipe_copy = clone(pipe)\n",
    "# pipe_copy.steps.append([instance, clf[instance]])\n",
    "\n",
    "\n",
    "def objective(params):\n",
    "\n",
    "    # Retrieve the subsample if present otherwise set to 1.0\n",
    "    subsample = params['boosting_type'].get('subsample', 1.0)\n",
    "    # Extract the boosting type\n",
    "    params['boosting_type'] = params['boosting_type']['boosting_type']\n",
    "    params['subsample'] = subsample\n",
    "    \n",
    "    # Make sure parameters that need to be integers are integers\n",
    "    for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "        params[parameter_name] = int(params[parameter_name])\n",
    "    \n",
    "#     print(params)\n",
    "    model = clf[instance].set_params(**params)\n",
    "    model.fit(train_feature_matrix, y_train, eval_set=(val_feature_matrix, y_val), eval_names=[\n",
    "              'val_feature_matrix', 'y_val'], eval_metric='auc', early_stopping_rounds=10)\n",
    "    best_score = model.best_score_['val_feature_matrix']['auc']\n",
    "    return 1 - best_score\n",
    "\n",
    "\n",
    "train_feature_matrix = pipe.fit_transform(X_train)  # pipe descalco sem o ultimo\n",
    "data_train = lgb.Dataset(train_feature_matrix,label=list(y_train.values.ravel()))\n",
    "\n",
    "test_feature_matrix = pipe.fit_transform(X_test)  # pipe descalco sem o ultimo\n",
    "data_test = lgb.Dataset(test_feature_matrix, label=list(y_test.values.ravel()))\n",
    "\n",
    "val_feature_matrix = pipe.fit_transform(X_val)  # pipe descalco sem o ultimo\n",
    "# data_test = lgb.Dataset(test_feature_matrix, label=list(y_test.values.ravel()))\n",
    "\n",
    "\n",
    "T = Trials()\n",
    "space = param_grid\n",
    "best = fmin(objective, space, algo=tpe.suggest, max_evals=1, trials=T)  # <---------------------------HERE<-----\n",
    "print('best:', best, '\\n')\n",
    "best_params = space_eval(space, best)\n",
    "print('best_params: ', best_params)\n",
    "\n",
    "# Retrieve the subsample if present otherwise set to 1.0\n",
    "subsample = best_params['boosting_type'].get('subsample', 1.0)\n",
    "# Extract the boosting type\n",
    "best_params['boosting_type'] = best_params['boosting_type']['boosting_type']\n",
    "best_params['subsample'] = subsample\n",
    "# Make sure parameters that need to be integers are integers\n",
    "for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "    best_params[parameter_name] = int(best_params[parameter_name])\n",
    "\n",
    "\n",
    "best_model = clf[instance].set_params(**best_params)\n",
    "best_model.fit(train_feature_matrix, y_train.values.ravel())\n",
    "y_pred = best_model.predict_proba(test_feature_matrix)[:, 1]\n",
    "#         y_pred = best_model.predict(test_feature_matrix)\n",
    "#         print(y_pred)\n",
    "acc = roc_auc_score(y_test, y_pred)\n",
    "print('acc :', acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hp.choice  -->  boosting,  subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# hp.choice -->  boosting_type, subsample\n",
    "\n",
    "class A2(object):\n",
    "\n",
    "    def __init__(self, instance, param_grid, my_name):\n",
    "        self.my_name = my_name\n",
    "        self.instance = instance\n",
    "        self.param_grid = param_grid\n",
    "        \n",
    "    def evaluate_HP_lGBM_val_choice(self, pipe, pkl_W=False): \n",
    "        '''\n",
    "        aceita pipeline sem o step final. pipe.append()\n",
    "        '''\n",
    "        start= timer()\n",
    "        result_dict = {}\n",
    "\n",
    "        instance = self.instance\n",
    "        param_grid = self.param_grid\n",
    "\n",
    "        pipe_copy = None\n",
    "        pipe_copy = clone(pipe)\n",
    "        pipe_copy.steps.append([instance, clf[instance]])\n",
    "\n",
    "        def objective(params):\n",
    "\n",
    "            # Retrieve the subsample if present otherwise set to 1.0\n",
    "            subsample = params['boosting_type'].get('subsample', 1.0)\n",
    "            # Extract the boosting type\n",
    "            params['boosting_type'] = params['boosting_type']['boosting_type']\n",
    "            params['subsample'] = subsample\n",
    "\n",
    "            # Make sure parameters that need to be integers are integers\n",
    "            for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "                params[parameter_name] = int(params[parameter_name])\n",
    "\n",
    "        #     print(params)\n",
    "            model = clf[instance].set_params(**params)\n",
    "            model.fit(train_feature_matrix, y_train, eval_set=(val_feature_matrix, y_val), eval_names=[\n",
    "                      'val_feature_matrix', 'y_val'], eval_metric='auc', early_stopping_rounds=10)\n",
    "            best_score = model.best_score_['val_feature_matrix']['auc']\n",
    "            return 1 - best_score\n",
    "\n",
    "\n",
    "\n",
    "        train_feature_matrix = pipe.fit_transform(X_train) # pipe descalco sem o ultimo\n",
    "        data_train = lgb.Dataset(train_feature_matrix, label=list(y_train.values.ravel()))\n",
    "\n",
    "        test_feature_matrix = pipe.fit_transform(X_test) # pipe descalco sem o ultimo\n",
    "        data_test = lgb.Dataset(test_feature_matrix, label=list(y_test.values.ravel()))\n",
    "        \n",
    "        val_feature_matrix = pipe.fit_transform(X_val) \n",
    "\n",
    "        T = Trials()\n",
    "        space = param_grid\n",
    "        best = fmin(objective, space, algo=tpe.suggest, max_evals=5, trials=T)  #  <---------------------------HERE<-----\n",
    "        best_params = space_eval(space, best) \n",
    "\n",
    "        # Retrieve the subsample if present otherwise set to 1.0\n",
    "        subsample = best_params['boosting_type'].get('subsample', 1.0)\n",
    "        # Extract the boosting type\n",
    "        best_params['boosting_type'] = best_params['boosting_type']['boosting_type']\n",
    "        best_params['subsample'] = subsample\n",
    "        # Make sure parameters that need to be integers are integers\n",
    "        for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "            best_params[parameter_name] = int(best_params[parameter_name])\n",
    "\n",
    "\n",
    "        best_model = clf[instance].set_params(**best_params)\n",
    "        best_model.fit(train_feature_matrix, y_train.values.ravel())\n",
    "        y_pred = best_model.predict_proba(test_feature_matrix)[:,1]\n",
    "#         y_pred = best_model.predict(test_feature_matrix)\n",
    "#         print(y_pred)\n",
    "        acc = roc_auc_score(y_test, y_pred) \n",
    "        print('acc :', acc)\n",
    "        end = timer()\n",
    "        minutes_elapsed = (end - start)//60\n",
    "        Super_Analytica.evaluations_all[self.my_name] = {'score': acc, 'best_estimator': best_model, \\\n",
    "                                 'param_grid': param_grid, 'y_pred': y_pred, \n",
    "                                 'param_pipe': pipe_copy, 'instance':instance, # é somente uma string, nao é a instance em si\\ \n",
    "                                 'best_params' : best_params, 'T': T, 'minutes': minutes_elapsed} \n",
    "\n",
    "\n",
    "        if  pkl_W:\n",
    "            D = {}\n",
    "            D[self.my_name]= Super_Analytica.evaluations_all[self.my_name]\n",
    "            joblib.dump(D, '../pkl/clf_'+ self.my_name + '.pkl') \n",
    "            print(self.my_name, ' HP_lightGBM and pickled to disk Done in',  minutes_elapsed, ' minutes' ) \n",
    "        else:\n",
    "            print(self.my_name, '  HP_lightGBM done in ', minutes_elapsed, ' minutes') \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hp.choice  -->  max_depth,  num_leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "param['LGBM5'] = {\n",
    "\n",
    "#     'num_leaves': hp.choice('num_leaves', [15, 31, 63, 127, 255, 511, 1023, 2047, 4095]),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n",
    "#     'max_depth': hp.choice('max_depth', range(4, 13)),\n",
    "    'max_depth': hp.choice('max_depth', [\n",
    "        {'max_depth': 4,\n",
    "         'num_leaves': 15\n",
    "         },\n",
    "        {'max_depth': 5,\n",
    "         'num_leaves': 31\n",
    "         },\n",
    "        {'max_depth': 6,\n",
    "         'num_leaves': 63\n",
    "         },\n",
    "        {'max_depth': 7,\n",
    "         'num_leaves': 127\n",
    "         },\n",
    "        {'max_depth': 8,\n",
    "         'num_leaves': 255\n",
    "         },\n",
    "        {'max_depth': 9,\n",
    "         'num_leaves': 511\n",
    "         },\n",
    "        {'max_depth': 10,\n",
    "         'num_leaves': 1023\n",
    "         }\n",
    "    ]),\n",
    "    'subsample_for_bin': 200000\n",
    "\n",
    "}\n",
    "# sample(param['LGBM5'])\n",
    "# param_grid = param['LGBM5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hp.choice -->  boosting_type, subsample\n",
    "\n",
    "class A2(object):\n",
    "\n",
    "    def __init__(self, instance, param_grid, my_name):\n",
    "        self.my_name = my_name\n",
    "        self.instance = instance\n",
    "        self.param_grid = param_grid\n",
    "        \n",
    "    def evaluate_HP_lGBM_val_choice(self, pipe, pkl_W=False): \n",
    "        '''\n",
    "        aceita pipeline sem o step final. pipe.append()\n",
    "        '''\n",
    "        start= timer()\n",
    "        result_dict = {}\n",
    "\n",
    "        instance = self.instance\n",
    "        param_grid = self.param_grid\n",
    "\n",
    "        pipe_copy = None\n",
    "        pipe_copy = clone(pipe)\n",
    "#         pipe_copy.steps.append([instance, clf[instance]])\n",
    "\n",
    "        def objective(params):\n",
    "\n",
    "            # Retrieve the subsample if present otherwise set to 1.0\n",
    "            max_depth = params['max_depth']['max_depth']\n",
    "            # Extract the boosting type\n",
    "            params['num_leaves'] = params['max_depth']['num_leaves']\n",
    "            params['max_depth'] = max_depth\n",
    "\n",
    "            # Make sure parameters that need to be integers are integers\n",
    "            for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "                params[parameter_name] = int(params[parameter_name])\n",
    "\n",
    "            print(params)\n",
    "            model = clf[instance].set_params(**params)\n",
    "            model.fit(train_feature_matrix, y_train, eval_set=(val_feature_matrix, y_val), eval_names=[\n",
    "                      'val_feature_matrix', 'y_val'], eval_metric='auc', early_stopping_rounds=10)\n",
    "            best_score = model.best_score_['val_feature_matrix']['auc']\n",
    "            return 1 - best_score\n",
    "\n",
    "\n",
    "\n",
    "        train_feature_matrix = pipe.fit_transform(X_train) # pipe descalco sem o ultimo\n",
    "        data_train = lgb.Dataset(train_feature_matrix, label=list(y_train.values.ravel()))\n",
    "\n",
    "        test_feature_matrix = pipe.fit_transform(X_test) # pipe descalco sem o ultimo\n",
    "        data_test = lgb.Dataset(test_feature_matrix, label=list(y_test.values.ravel()))\n",
    "        \n",
    "        val_feature_matrix = pipe.fit_transform(X_val) \n",
    "\n",
    "        T = Trials()\n",
    "        space = param_grid\n",
    "        best = fmin(objective, space, algo=tpe.suggest, max_evals=200, trials=T)  #  <-----HERE<-----\n",
    "        best_params = space_eval(space, best) \n",
    "\n",
    "        max_depth = best_params['max_depth']['max_depth']\n",
    "        # Extract the boosting type\n",
    "        best_params['num_leaves'] = best_params['max_depth']['num_leaves']\n",
    "        best_params['max_depth'] = max_depth\n",
    "        \n",
    "        for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "            best_params[parameter_name] = int(best_params[parameter_name])\n",
    "\n",
    "\n",
    "        best_model = clf[instance].set_params(**best_params)\n",
    "        best_model.fit(train_feature_matrix, y_train.values.ravel())\n",
    "        y_pred = best_model.predict_proba(test_feature_matrix)[:,1]\n",
    "#         y_pred = best_model.predict(test_feature_matrix)\n",
    "#         print(y_pred)\n",
    "        acc = roc_auc_score(y_test, y_pred) \n",
    "        print('acc :', acc)\n",
    "        end = timer()\n",
    "        minutes_elapsed = (end - start)//60\n",
    "        Super_Analytica.evaluations_all[self.my_name] = {'score': acc, 'best_estimator': best_model, \\\n",
    "                                 'param_grid': param_grid, 'y_pred': y_pred, \n",
    "                                 'param_pipe': pipe_copy, 'instance':instance, # é somente uma string, nao é a instance em si\\ \n",
    "                                 'best_params' : best_params, 'T': T, 'minutes': minutes_elapsed} \n",
    "\n",
    "\n",
    "        if  pkl_W:\n",
    "            D = {}\n",
    "            D[self.my_name]= Super_Analytica.evaluations_all[self.my_name]\n",
    "            joblib.dump(D, '../pkl/clf_'+ self.my_name + '.pkl') \n",
    "            print(self.my_name, ' HP_lightGBM and pickled to disk Done in',  minutes_elapsed, ' minutes' ) \n",
    "        else:\n",
    "            print(self.my_name, '  HP_lightGBM done in ', minutes_elapsed, ' minutes') \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_LGBM5 = A2('LGBM', param['LGBM5'], '_5')\n",
    "md_LGBM5.evaluate_HP_lGBM_val_choice(pipe_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "master.get_members_evaluations_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "master.plot_validation_curve(chosen=['_5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "287px",
    "left": "812px",
    "top": "528px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
