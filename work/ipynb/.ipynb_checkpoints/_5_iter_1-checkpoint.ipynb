{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Load Libraries / Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ../modules/library_to_import.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../modules/Class_imdb.ipynb\n",
    "%run ../modules/transformers_imdb.ipynb"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "evaluations_all -  it is a dictionary where all the information regarding models performance scores gets recorded. It`s the 'cloud'.\n",
    "\n",
    "By acessing the 'cloud' the Class Super_Analtica will work in groups.\n",
    "Analytica_bolada is lower level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's hard to put your finger on this one. Basi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I mean, nothing happens, 5 dumb kids go to Okl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Så som in himmelen\" was probably one of the 3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This noir may not be the best remembered film ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'll be honest with yall, I was a junior in hi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  It's hard to put your finger on this one. Basi...          1\n",
       "1  I mean, nothing happens, 5 dumb kids go to Okl...          0\n",
       "2  \"Så som in himmelen\" was probably one of the 3...          1\n",
       "3  This noir may not be the best remembered film ...          1\n",
       "4  I'll be honest with yall, I was a junior in hi...          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/movie_data.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['review'].values\n",
    "y = df['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./params_imdb.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's hard to put your finger on this one. Basi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I mean, nothing happens, 5 dumb kids go to Okl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Så som in himmelen\" was probably one of the 3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This noir may not be the best remembered film ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'll be honest with yall, I was a junior in hi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  It's hard to put your finger on this one. Basi...          1\n",
       "1  I mean, nothing happens, 5 dumb kids go to Okl...          0\n",
       "2  \"Så som in himmelen\" was probably one of the 3...          1\n",
       "3  This noir may not be the best remembered film ...          1\n",
       "4  I'll be honest with yall, I was a junior in hi...          1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      "review       50000 non-null object\n",
      "sentiment    50000 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 781.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.head()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.5\n",
       "0    0.5\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "feature union is for applying different vectorizers for different columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X  y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "\n",
    "# # DATAFRAMES USED ONLY WHEN NEED MORE THAN 1 COLUMN\n",
    "# WORKS with sklearn-pandas to drive dataframes in sklearn or column extractor e To_Matrix\n",
    "# X_train = df.loc[:5000, ['review']].reset_index(drop=True)\n",
    "# y_train = df.loc[:5000, ['sentiment']].reset_index(drop=True)\n",
    "# X_test = df.loc[45000:, ['review']].reset_index(drop=True)\n",
    "# y_test = df.loc[45000:, ['sentiment']].reset_index(drop=True)\n",
    "\n",
    "X_train = df.loc[:25000, ['review']].reset_index(drop=True)\n",
    "y_train = df.loc[:25000, ['sentiment']].reset_index(drop=True)\n",
    "X_test = df.loc[25000:, ['review']].reset_index(drop=True)\n",
    "y_test = df.loc[25000:, ['sentiment']].reset_index(drop=True)\n",
    "\n",
    "# X_train = df.loc[:100, ['review']].reset_index(drop=True)\n",
    "# y_train = df.loc[:100, ['sentiment']].reset_index(drop=True)\n",
    "# X_test = df.loc[49900:, ['review']].reset_index(drop=True)\n",
    "# y_test = df.loc[49900:, ['sentiment']].reset_index(drop=True)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=random_state)\n",
    "# kfold = 5\n",
    "# kfold = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_style": "split",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's hard to put your finger on this one. Basi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I mean, nothing happens, 5 dumb kids go to Okl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Så som in himmelen\" was probably one of the 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This noir may not be the best remembered film ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'll be honest with yall, I was a junior in hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Damon Runyon's world of Times Square, in New Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>After a group of young friends experience car ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What makes for Best Picture material? The Osca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I found this film extremely disturbing. Treadw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This DVD set is the complete widescreen 15-epi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kevin Kline and Meg Ryan are among that class ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Well...there were some great, creamy-smooth fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>If I had not read Pat Barker's 'Union Street' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>This movie is fun to watch. If you liked \"Dave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A charming, funny film that gets a solid grade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The movie is about a day in the life of a woma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I just rented this movie from the video store ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I suppose I always felt that Hotel du Nord was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I saw this on cable. Someone had to lose their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>I was one of quite a few extras in this big bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Raising Victor Vargas is a movie you definitel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>First of all, I believe that this movie is muc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Jörg Buttgereit goes a bit too far with his mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>I had the opportunity to see this last evening...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Certainly not horrible, but definitely not goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Before watching this movie from beginning to e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Outrageously trashy karate/horror thriller wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\"Death Promise\" is a lost 70's exploitation ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Of the Korean movies I've seen, only three had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Of course I have disappeared into the movies. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24971</th>\n",
       "      <td>William Shatner in small doses is tolerable. U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24972</th>\n",
       "      <td>My mother worked with Dennis L. Raider for ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24973</th>\n",
       "      <td>First of all, as a long time student of the Ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24974</th>\n",
       "      <td>Kids - of whatever age - do not want to know a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24975</th>\n",
       "      <td>It is a superb Swedish film .. it was the firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24976</th>\n",
       "      <td>...about the importance of being young, having...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24977</th>\n",
       "      <td>Ironically the most talked-about American film...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24978</th>\n",
       "      <td>Stupid! Stupid! Stupid! I can not stand Ben st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24979</th>\n",
       "      <td>This is an excellent James Bond movie. Althoug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24980</th>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt;When I first started watching this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24981</th>\n",
       "      <td>Let's not fool ourselves, okay? We all know th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24982</th>\n",
       "      <td>Strange but acceptable mob comedy that has an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24983</th>\n",
       "      <td>Are you kidding me?! A show highlighting someo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24984</th>\n",
       "      <td>A mediocre Sci-Fi Channel original picture. A ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24985</th>\n",
       "      <td>Did this gem go direct to video? Fabulous art ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24986</th>\n",
       "      <td>Flynn, known mostly for his swashbuckling role...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24987</th>\n",
       "      <td>I just came back from the Late-night cinema an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24988</th>\n",
       "      <td>I think Purvis starts out to do a gay \"Gone Wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24989</th>\n",
       "      <td>Along with virtually every Republic Picture ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24990</th>\n",
       "      <td>This movie is a crappy and forgettable Sean Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24991</th>\n",
       "      <td>This film is totally mindblowing. It manages t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24992</th>\n",
       "      <td>How amazing this film is! I've seen it over an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24993</th>\n",
       "      <td>Jimmy Cagney races by your eyes constantly in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>I was entranced by this touching and hilarious...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>This is a very beautiful and almost meditative...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>If you were ever sad for not being able to get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>I am sitting here watching the film, Tango and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>It's really just terrible. Quaid overacts more...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>Almost no information is available about this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25000</th>\n",
       "      <td>This movie is just like every other dutch movi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25001 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review\n",
       "0      It's hard to put your finger on this one. Basi...\n",
       "1      I mean, nothing happens, 5 dumb kids go to Okl...\n",
       "2      \"Så som in himmelen\" was probably one of the 3...\n",
       "3      This noir may not be the best remembered film ...\n",
       "4      I'll be honest with yall, I was a junior in hi...\n",
       "5      Damon Runyon's world of Times Square, in New Y...\n",
       "6      After a group of young friends experience car ...\n",
       "7      What makes for Best Picture material? The Osca...\n",
       "8      I found this film extremely disturbing. Treadw...\n",
       "9      This DVD set is the complete widescreen 15-epi...\n",
       "10     Kevin Kline and Meg Ryan are among that class ...\n",
       "11     Well...there were some great, creamy-smooth fa...\n",
       "12     If I had not read Pat Barker's 'Union Street' ...\n",
       "13     This movie is fun to watch. If you liked \"Dave...\n",
       "14     A charming, funny film that gets a solid grade...\n",
       "15     The movie is about a day in the life of a woma...\n",
       "16     I just rented this movie from the video store ...\n",
       "17     I suppose I always felt that Hotel du Nord was...\n",
       "18     I saw this on cable. Someone had to lose their...\n",
       "19     I was one of quite a few extras in this big bo...\n",
       "20     Raising Victor Vargas is a movie you definitel...\n",
       "21     First of all, I believe that this movie is muc...\n",
       "22     Jörg Buttgereit goes a bit too far with his mo...\n",
       "23     I had the opportunity to see this last evening...\n",
       "24     Certainly not horrible, but definitely not goo...\n",
       "25     Before watching this movie from beginning to e...\n",
       "26     Outrageously trashy karate/horror thriller wit...\n",
       "27     \"Death Promise\" is a lost 70's exploitation ge...\n",
       "28     Of the Korean movies I've seen, only three had...\n",
       "29     Of course I have disappeared into the movies. ...\n",
       "...                                                  ...\n",
       "24971  William Shatner in small doses is tolerable. U...\n",
       "24972  My mother worked with Dennis L. Raider for ele...\n",
       "24973  First of all, as a long time student of the Ti...\n",
       "24974  Kids - of whatever age - do not want to know a...\n",
       "24975  It is a superb Swedish film .. it was the firs...\n",
       "24976  ...about the importance of being young, having...\n",
       "24977  Ironically the most talked-about American film...\n",
       "24978  Stupid! Stupid! Stupid! I can not stand Ben st...\n",
       "24979  This is an excellent James Bond movie. Althoug...\n",
       "24980  <br /><br />When I first started watching this...\n",
       "24981  Let's not fool ourselves, okay? We all know th...\n",
       "24982  Strange but acceptable mob comedy that has an ...\n",
       "24983  Are you kidding me?! A show highlighting someo...\n",
       "24984  A mediocre Sci-Fi Channel original picture. A ...\n",
       "24985  Did this gem go direct to video? Fabulous art ...\n",
       "24986  Flynn, known mostly for his swashbuckling role...\n",
       "24987  I just came back from the Late-night cinema an...\n",
       "24988  I think Purvis starts out to do a gay \"Gone Wi...\n",
       "24989  Along with virtually every Republic Picture ev...\n",
       "24990  This movie is a crappy and forgettable Sean Co...\n",
       "24991  This film is totally mindblowing. It manages t...\n",
       "24992  How amazing this film is! I've seen it over an...\n",
       "24993  Jimmy Cagney races by your eyes constantly in ...\n",
       "24994  I was entranced by this touching and hilarious...\n",
       "24995  This is a very beautiful and almost meditative...\n",
       "24996  If you were ever sad for not being able to get...\n",
       "24997  I am sitting here watching the film, Tango and...\n",
       "24998  It's really just terrible. Quaid overacts more...\n",
       "24999  Almost no information is available about this ...\n",
       "25000  This movie is just like every other dutch movi...\n",
       "\n",
       "[25001 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_style": "split",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This movie is just like every other dutch movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I just recently viewed Shame which is directed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Larry Bishop is 60-years old, dirty and not go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pretentious storytelling such as this always u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>... and how they bore you right out of your mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I remember flipping through channels on HBO an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I felt compelled to write about this movie aft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Make no mistake, Maureen O'Sullivan is easily ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Looking for a REAL super bad movie? If you wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>One of the worst movies ever made... If you ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>After viewing this film, I felt the compelling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>It's difficult to make it through this movie w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>There is no possible reason I can fathom why t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>This is a excellent series. You will laugh, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The comparison is perhaps unfair, but inevitab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I saw this movie twice. I can't believe Pintil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>This is a disappointing adaptation of the Jame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Who could possibly have wished for a sequel to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Despite a tight narrative, Johnnie To's Electi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>This film is about a deadly poison that is con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>What a wonderful documentary - I sat down thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Iberia is nice to see on TV. But why see this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Featuring a few of Hammer's all-stars, this hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The superb star quality of Gerard Philipe, who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>I have never read the book\"A wrinkle in time\"....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>This is by far the worst horror/thriller I've ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>When I saw the poster at the theater, I though...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>I think it was a pretty good film. It shows ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>The only reason I'm giving this a 9 is that th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>I usually enjoy underground movies and antiher...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24970</th>\n",
       "      <td>I understand what this movie was trying to por...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24971</th>\n",
       "      <td>There is part of one sequence where some water...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24972</th>\n",
       "      <td>I think we all begin a lot of reviews with, \"T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24973</th>\n",
       "      <td>My daughter liked it but I was aghast, that a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24974</th>\n",
       "      <td>I just saw this film again, I believe for the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24975</th>\n",
       "      <td>It utterly defeats me why Godard is taken so s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24976</th>\n",
       "      <td>Jimmy (Heath Ledger) is given a simple job by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24977</th>\n",
       "      <td>I attempted to watch this film without being a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24978</th>\n",
       "      <td>Bloody Birthday plays on the assumed innocence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24979</th>\n",
       "      <td>Disappointing film. Performance of actors is w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24980</th>\n",
       "      <td>One of Warner Brothers best and highest grossi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24981</th>\n",
       "      <td>How this has not become a cult film I do not k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24982</th>\n",
       "      <td>The laughs are few and far between in this dul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24983</th>\n",
       "      <td>I wouldn't call \"We're Back! A Dinosaur's Stor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24984</th>\n",
       "      <td>I contend that whoever is ultimately responsib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24985</th>\n",
       "      <td>This was a well written tale of the Making of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24986</th>\n",
       "      <td>Even if you know absolutely nothing about Irel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24987</th>\n",
       "      <td>`Rock star' is not on its way to any `stairway...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24988</th>\n",
       "      <td>I bought this game on an impulse buy from walm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24989</th>\n",
       "      <td>A poorly-paced sf/horror venture that takes it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24990</th>\n",
       "      <td>I don't understand how this garbage got on the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24991</th>\n",
       "      <td>What seemed as a good premise for a movie...un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24992</th>\n",
       "      <td>Although compared with \"Mad Max\", this film is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24993</th>\n",
       "      <td>This show is a show that is great for adults a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>(No spoilers, just plot details) I can't under...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>I'd heard this Japanese flick is edgy, creativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>The director does not know what to do with a c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>I've seen this movie after watching Paltrow's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>I could never stand watching Happy Days after ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>Stephen Hawkings is a genius. He is the king o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review\n",
       "0      This movie is just like every other dutch movi...\n",
       "1      I just recently viewed Shame which is directed...\n",
       "2      Larry Bishop is 60-years old, dirty and not go...\n",
       "3      Pretentious storytelling such as this always u...\n",
       "4      ... and how they bore you right out of your mi...\n",
       "5      I remember flipping through channels on HBO an...\n",
       "6      I felt compelled to write about this movie aft...\n",
       "7      Make no mistake, Maureen O'Sullivan is easily ...\n",
       "8      Looking for a REAL super bad movie? If you wan...\n",
       "9      One of the worst movies ever made... If you ca...\n",
       "10     After viewing this film, I felt the compelling...\n",
       "11     It's difficult to make it through this movie w...\n",
       "12     There is no possible reason I can fathom why t...\n",
       "13     This is a excellent series. You will laugh, yo...\n",
       "14     The comparison is perhaps unfair, but inevitab...\n",
       "15     I saw this movie twice. I can't believe Pintil...\n",
       "16     This is a disappointing adaptation of the Jame...\n",
       "17     Who could possibly have wished for a sequel to...\n",
       "18     Despite a tight narrative, Johnnie To's Electi...\n",
       "19     This film is about a deadly poison that is con...\n",
       "20     What a wonderful documentary - I sat down thin...\n",
       "21     Iberia is nice to see on TV. But why see this ...\n",
       "22     Featuring a few of Hammer's all-stars, this hi...\n",
       "23     The superb star quality of Gerard Philipe, who...\n",
       "24     I have never read the book\"A wrinkle in time\"....\n",
       "25     This is by far the worst horror/thriller I've ...\n",
       "26     When I saw the poster at the theater, I though...\n",
       "27     I think it was a pretty good film. It shows ho...\n",
       "28     The only reason I'm giving this a 9 is that th...\n",
       "29     I usually enjoy underground movies and antiher...\n",
       "...                                                  ...\n",
       "24970  I understand what this movie was trying to por...\n",
       "24971  There is part of one sequence where some water...\n",
       "24972  I think we all begin a lot of reviews with, \"T...\n",
       "24973  My daughter liked it but I was aghast, that a ...\n",
       "24974  I just saw this film again, I believe for the ...\n",
       "24975  It utterly defeats me why Godard is taken so s...\n",
       "24976  Jimmy (Heath Ledger) is given a simple job by ...\n",
       "24977  I attempted to watch this film without being a...\n",
       "24978  Bloody Birthday plays on the assumed innocence...\n",
       "24979  Disappointing film. Performance of actors is w...\n",
       "24980  One of Warner Brothers best and highest grossi...\n",
       "24981  How this has not become a cult film I do not k...\n",
       "24982  The laughs are few and far between in this dul...\n",
       "24983  I wouldn't call \"We're Back! A Dinosaur's Stor...\n",
       "24984  I contend that whoever is ultimately responsib...\n",
       "24985  This was a well written tale of the Making of ...\n",
       "24986  Even if you know absolutely nothing about Irel...\n",
       "24987  `Rock star' is not on its way to any `stairway...\n",
       "24988  I bought this game on an impulse buy from walm...\n",
       "24989  A poorly-paced sf/horror venture that takes it...\n",
       "24990  I don't understand how this garbage got on the...\n",
       "24991  What seemed as a good premise for a movie...un...\n",
       "24992  Although compared with \"Mad Max\", this film is...\n",
       "24993  This show is a show that is great for adults a...\n",
       "24994  (No spoilers, just plot details) I can't under...\n",
       "24995  I'd heard this Japanese flick is edgy, creativ...\n",
       "24996  The director does not know what to do with a c...\n",
       "24997  I've seen this movie after watching Paltrow's ...\n",
       "24998  I could never stand watching Happy Days after ...\n",
       "24999  Stephen Hawkings is a genius. He is the king o...\n",
       "\n",
       "[25000 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_style": "split",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24971</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24972</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24973</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24974</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24975</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24976</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24977</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24978</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24979</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24980</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24981</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24982</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24983</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24984</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24985</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24986</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24987</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24988</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24989</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24990</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24991</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24992</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24993</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25000</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25001 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment\n",
       "0              1\n",
       "1              0\n",
       "2              1\n",
       "3              1\n",
       "4              1\n",
       "5              1\n",
       "6              1\n",
       "7              1\n",
       "8              0\n",
       "9              1\n",
       "10             0\n",
       "11             0\n",
       "12             0\n",
       "13             1\n",
       "14             1\n",
       "15             0\n",
       "16             1\n",
       "17             1\n",
       "18             0\n",
       "19             0\n",
       "20             1\n",
       "21             1\n",
       "22             1\n",
       "23             1\n",
       "24             0\n",
       "25             1\n",
       "26             0\n",
       "27             1\n",
       "28             1\n",
       "29             0\n",
       "...          ...\n",
       "24971          0\n",
       "24972          0\n",
       "24973          0\n",
       "24974          1\n",
       "24975          1\n",
       "24976          1\n",
       "24977          1\n",
       "24978          0\n",
       "24979          1\n",
       "24980          0\n",
       "24981          0\n",
       "24982          1\n",
       "24983          0\n",
       "24984          0\n",
       "24985          1\n",
       "24986          1\n",
       "24987          1\n",
       "24988          0\n",
       "24989          1\n",
       "24990          0\n",
       "24991          1\n",
       "24992          1\n",
       "24993          1\n",
       "24994          1\n",
       "24995          1\n",
       "24996          1\n",
       "24997          0\n",
       "24998          0\n",
       "24999          1\n",
       "25000          0\n",
       "\n",
       "[25001 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_style": "split",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24970</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24971</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24972</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24973</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24974</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24975</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24976</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24977</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24978</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24979</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24980</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24981</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24982</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24983</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24984</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24985</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24986</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24987</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24988</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24989</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24990</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24991</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24992</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24993</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment\n",
       "0              0\n",
       "1              0\n",
       "2              0\n",
       "3              0\n",
       "4              0\n",
       "5              0\n",
       "6              0\n",
       "7              1\n",
       "8              0\n",
       "9              0\n",
       "10             0\n",
       "11             0\n",
       "12             0\n",
       "13             1\n",
       "14             0\n",
       "15             0\n",
       "16             0\n",
       "17             0\n",
       "18             1\n",
       "19             1\n",
       "20             1\n",
       "21             0\n",
       "22             1\n",
       "23             1\n",
       "24             0\n",
       "25             0\n",
       "26             0\n",
       "27             1\n",
       "28             1\n",
       "29             0\n",
       "...          ...\n",
       "24970          0\n",
       "24971          0\n",
       "24972          0\n",
       "24973          0\n",
       "24974          1\n",
       "24975          0\n",
       "24976          1\n",
       "24977          0\n",
       "24978          1\n",
       "24979          0\n",
       "24980          1\n",
       "24981          1\n",
       "24982          0\n",
       "24983          1\n",
       "24984          1\n",
       "24985          1\n",
       "24986          1\n",
       "24987          1\n",
       "24988          1\n",
       "24989          0\n",
       "24990          0\n",
       "24991          0\n",
       "24992          1\n",
       "24993          1\n",
       "24994          1\n",
       "24995          0\n",
       "24996          0\n",
       "24997          1\n",
       "24998          0\n",
       "24999          1\n",
       "\n",
       "[25000 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_style": "split",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25001, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "# X_train.info()\n",
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_style": "split",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25001, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n",
    "# y_train.info()\n",
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n",
    "# X_test.info()\n",
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape\n",
    "# y_train.info()\n",
    "type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_split(text):\n",
    "    return [porter.stem(w) for w in text.split(' ')]\n",
    "\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(w) for w in text.split(' ') if not w in stop_words ]\n",
    "\n",
    "tfidf = TfidfVectorizer(strip_accents=None, lowercase=False, preprocessor=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = Super_Analytica('master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../modules/params_imdb.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = ['num_words', 'num_unique_words' ,'num_chars', 'num_stopwords' ,'num_words_upper' ,'num_words_title', 'mean_word_len']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Pipeline standard \n",
    "explicar o prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 12s, sys: 439 ms, total: 1min 13s\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "    ('to_array', To_array()),\n",
    "    ('counts', CountVectorizer(analyzer=\"word\",\n",
    "                               tokenizer=tokenizer_porter,\n",
    "                               stop_words=stop_words,\n",
    "                               max_features=5000))\n",
    "])\n",
    "\n",
    "train_features_matrix = pipe.fit_transform(X_train)\n",
    "vocab = pipe.named_steps['counts'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25001x5000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2103321 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_matrix\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE IMPORTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to measure feature importance for the new engineered features \n",
    "# we gonna use DataFrame Mapper from sklearn-pandas. \n",
    "# dessa maneira eu consigo declarar as novas features \n",
    "# as transformers and pipeline it, thus saving me the hassle of applying each feature to both train and test.\n",
    "# although this library applies the new features on the fly (pipeline) it has a attribute that returns feature names\n",
    "# making it easy to do feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc : 0.49\n",
      "DT_1   HP2 Done. Model is Fitted and Scored. Results in Evaluations_all.\n"
     ]
    }
   ],
   "source": [
    "# DATAFRAME MAPPER para calcular feat importances das new features\n",
    "# \n",
    "\n",
    "param['DT_1'] = {\"DT__criterion\" :'gini'}\n",
    "\n",
    "map_prep = DataFrameMapper([\n",
    "    (['review'], Preprocessor())], input_df=True, df_out=True)\n",
    "\n",
    "map_tfidf = DataFrameMapper([\n",
    "    ('review', [To_array(), TfidfVectorizer()])], input_df = True)\n",
    "\n",
    "mapper_super_feat_eng = DataFrameMapper([\n",
    "    (['review'], num_stop_words(), {'alias': 'n_stop_w'}),\n",
    "    (['review'], num_uni_words(), {'alias': 'n_uni_w'}),\n",
    "    (['review'], num_words_title(), {'alias': 'n_w_title'}),\n",
    "    (['review'], mean_word_len(), {'alias': 'm_w_len'})], input_df=True)\n",
    "\n",
    "\n",
    "# Feature_Importances - todos os transformers dentro de um mesmo mapper. \n",
    "pipe = Pipeline([\n",
    "    ('prep', map_prep),\n",
    "    ('f1', FeatureUnion([\n",
    "#         ('tfidf', map_tfidf),\n",
    "        ('new_features', mapper_super_feat_eng)\n",
    "    ])),\n",
    "    ('DT', clf['DT'])])\n",
    "\n",
    "md_DT_1 = Analytica_Bolada(clf['DT'], param['DT_1'], 'DT_1')\n",
    "md_DT_1.evaluate_HP2(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAD3CAYAAADlnNj/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAEPpJREFUeJzt3X1M1XX/x/HXQUCXYOliSSPzZhm6ZqKSbiqW6OnStaswFLVIt7yrNC7Imy3LmKmrqXPXsPBeUlPJ7WSl01bOCdky04p5l4p3UZsJXomggMj3+uP3G+Ulcnhz9wV5Pv6S8/1+z3mfz8AnHw4ePY7jOAIAwCDA7QEAAM0P8QAAmBEPAIAZ8QAAmBEPAIBZoNsDNIby8pv6z3+uuT1Gk9e+/T2skx+sUc2wTv41hzUKCwu947EWsfMIDGzl9gjNAuvkH2tUM6yTf819jVpEPAAA9Yt4AADMiAcAwIx4AADMWsRvW42f/bHbIwDw49+z/un2CDBg5wEAMCMeAAAz4gEAMCMeAAAz4gEAMCMeAAAz4gEAMCMeAAAz4gEAMCMeAAAz4gEAMCMeAAAz4gEAMCMeAAAz4gEAMCMeAAAz4gEAMCMeAACzBo/HV199pYsXLzb0wwAAGlGDx2PDhg0qKipq6IcBADSiQH8n+Hw+7du3TyUlJbpw4YImT56sUaNG3XZeaWmpkpKSVFRUpJKSEs2aNUvXr1/X8ePHNWfOHG3evFmbNm3Szp07FRgYqH79+mnWrFlKS0vTmTNnVFBQoMLCQr311lvq169flbPExcVpzZo1ateunfr3769NmzapZ8+eiouLU2ZmpoKDg+u+IgAAv/zGQ5KKioq0du1anTt3TtOmTasyHhcuXFB+fr4yMjJUUFCgc+fO6cknn1SPHj2Umpqqs2fPateuXdq6dasCAwM1Y8YM7d27V5LUpk0bbdiwQadOndIbb7yhzz//vMo5YmNjlZ2drY4dOyoiIkL79+9XcHCwOnfuTDgAoBHVKB6RkZGSpPDwcJWVlVV5ziOPPKIXXnhBKSkpKi8vV2Ji4i3Hz5w5o8cff1xBQUGSpH79+unUqVOSpAEDBlTeR35+/h3n8Hq9WrFihcLDw5WcnKyNGzfKcRx5vd6aPA0AQD2p0WseHo/H7zm//PKLiouLtWrVKr333nt69913K691HEddu3ZVTk6OysvL5TiODh48qC5dukiSjh49Kkk6efKkHnjggTs+Rvfu3ZWXl6ecnBwNGTJE165d0549exQTE1OTpwEAqCc12nnUROfOnfXBBx9o+/btCgoK0uuvvy5JioqK0uzZs7Vu3TqNGDFC48aNU0VFhfr27athw4bpxIkTOn78uCZMmKDr169XRudOoqOjlZeXp4CAAEVHR+v06dNq27ZtfT0NAEANeBzHcdwcIC0tTffff7/GjRvXYI8xfvbHDXbfAOrHv2f90+0RGlVYWKguXbrq9hjVCgsLveMx884jMzNTO3bsuO32lJQURUVFWe+uSqmpqcrNzb3t9tWrV6tNmzb18hgAgNpzfefRGNh5AE0fO4+mp7qdB29PAgAwIx4AADPiAQAwIx4AADPiAQAwIx4AADPiAQAwIx4AADPiAQAwIx4AADPiAQAwIx4AADPiAQAwIx4AALMW8Zbskpr8Wx83Bc3hLaLdxhrVDOvkX3NYI96SHQBQr4gHAMCMeAAAzIgHAMCMeAAAzIgHAMCMeAAAzIgHAMCMeAAAzIgHAMAs0O0BGsPE9UlujwA0iMXPLHB7BLRQ7DwAAGbEAwBgRjwAAGbEAwBgRjwAAGbEAwBgRjwAAGbEAwBgRjwAAGbEAwBgRjwAAGbEAwBgRjwAAGbEAwBgRjwAAGbEAwBgRjwAAGbEAwBgRjwAAGZNKh7JyckqKytzewwAgB+Bbg/wd8uWLXN7BABADdRq5+Hz+ZSUlKSpU6dqxIgR8vl8VZ6Xl5enMWPGVH48ZswY5eXlKS0tTXPmzNGkSZM0cuRIZWdnS5KGDh2q0tLSKu8rIyNDa9eulSTNmzdPCxYskCR9+OGH+uKLL2rzNAAAtVTrH1sVFRVp5cqVSk9P16pVq8zXBwcHa82aNZo7d64yMjL8nu/1eisjc/bsWf3888+SpG+++UZPPfWU+fEBALVX63hERkZKksLDw2v8OoXjOJV/7tGjhySpY8eONbr+wQcfVElJiXJyctStWze1b99eOTk5Cg0NVUhISC2eAQCgtmodD4/H4/ec1q1bq6CgQDdv3lRhYaHy8vJM1/+vIUOGaPHixRo0aJAGDRqkBQsWaNiwYeb7AQDUTYP+tlVYWJgGDhyo+Ph4vf3223r44YfrdH9er1eHDx/WgAEDNGjQIB05ckSxsbH1NC0AoKY8zt9/lnSXmrg+ye0RgAax+JkFbo9QpbCwUF26dNXtMZq05rBGYWGhdzxWL7+qm5mZqR07dtx2e0pKiqKiokz3tWfPnipfQH/ppZc0fPjw2o4IAKhH7DyAZoydR/PVHNaoup1Hk/oX5gCA5oF4AADMiAcAwIx4AADMiAcAwIx4AADMiAcAwIx4AADMiAcAwIx4AADMiAcAwIx4AADMiAcAwIx4AADMWsRbsktq8m993BQ0h7eIdhtrVDOsk3/NYY14S3YAQL0iHgAAM+IBADAjHgAAM+IBADAjHgAAM+IBADAjHgAAM+IBADAjHgAAM+IBADAjHgAAM+IBADAjHgAAM+IBADAjHgAAM+IBADAjHgAAM+IBADAjHgAAM+IBADAjHgAAM+IBADAjHgAAM+IBADAjHgAAM+IBADAjHgAAM+IBADBrUvHYtGmTJCkrK0uZmZmSpMzMTN24cUMHDhxQcnKym+MBAP5fk4pHenq6JCkmJkYJCQmSpJUrV6qiosLNsQAA/8MUD5/Pp6SkJE2dOlUjRoyQz+er8ryFCxdq9+7dkqSXX35ZGRkZkqS5c+fq8OHDVV6Tnp6uK1euKDU1VT6fT0uWLNG2bdt06dKl23Ycu3btUkJCgsaNG6clS5ZYngIAoB6Ydx5FRUVauXKl0tPTtWrVqirP8Xq9ysrKUklJiQoLC/Xtt9/KcRwdO3ZMUVFRVV7zyiuv6N5771VqamrlbaNHj1ZYWJiWLVtWeduff/6ptLQ0ZWRkaMuWLbp48aL2799vfRoAgDowxyMyMlKSFB4errKysirP6du3r44dO6YDBw7I6/Xq8uXL+uGHH9S7d295PJ46DXzhwgVdvnxZU6ZMUWJionJzc/Xrr7/W6T4BADaB1gtq8pd/QECAHnvsMa1Zs0Zvvvmm8vPztXjxYr8veDuOU+Xj/f01j4iICIWHh2vdunUKCgqSz+dTjx49rE8DAFAHDfaC+fDhw5Wbm6vIyEgNGjRI58+fV3R0dLXXdOvWTTNnzrzltn79+mnKlCmVYenQoYMmTpyoxMREjR49WllZWercuXNDPQ0AQBU8TlXf7t+FLl266vYITV5YWCjr5AdrVDOsk3/NYY3CwkLveMz8Y6u/y8zM1I4dO267PSUl5Y4vjC9fvlwHDhy47fZFixbpoYceqss4AIBGws4DlZrDd0JuY41qhnXyrzmsUXU7jyb1jwQBAM0D8QAAmBEPAIAZ8QAAmBEPAIAZ8QAAmBEPAIAZ8QAAmBEPAIAZ8QAAmBEPAIAZ8QAAmBEPAIAZ8QAAmBEPAIAZ8QAAmBEPAIAZ8QAAmBEPAIAZ8QAAmBEPAIAZ8QAAmBEPAIAZ8QAAmBEPAIBZoNsDNIZFc7e5PQIANLrJ//pHg903Ow8AgBnxAACYEQ8AgBnxAACYEQ8AgBnxAACYEQ8AgBnxAACYEQ8AgBnxAACYEQ8AgBnxAACYEQ8AgBnxAACYEQ8AgBnxAACYEQ8AgBnxAACYEQ8AgFmTjEdaWpq2bNni9hgAgDtokvEAADRtpnj4fD7NmDFDkydP1nPPPSefz6fXXntNXq9XX3/9dZXXxMXFqaCgQDdu3FCfPn107NixytvLysr8PubSpUs1duxYJSQkaNeuXZKkxMRELVy4UBMnTlR8fLx+++03y9MAANSReedRXFys1atXa/LkydqyZYuWL1+u+fPny+fzVXl+bGyssrOzdejQIUVERGj//v06ffq0OnfurODg4Gofa9++fcrLy9PWrVu1YcMGrVixQoWFhZKkXr16KSMjQwMHDtTOnTutTwMAUAeB1gt69OghSQoNDVW3bt3k8Xh07733qrS0tMrzvV6vVqxYofDwcCUnJ2vjxo1yHEder9fvY508eVJHjx5VYmKiJKm8vFy///67JKlnz56SpI4dOyo/P9/6NAAAdWDeeXg8HtP53bt3V15ennJycjRkyBBdu3ZNe/bsUUxMjN9ru3btqv79+2vjxo366KOPNGLECEVERFhHBgDUs0Z5wTw6OlodOnRQQEBA5Z/btm3r97qhQ4fqnnvu0fjx4zVq1ChJUkhISEOPCwDww+M4juP2EA1t0dxtbo8AAI1u8r/+Uafrw8JC73jM/JrHnaSmpio3N/e221evXq02bdpUec306dN15cqVW24LCQlRenp6fY0FAGgA7DwA4C7VkDsP/pEgAMCMeAAAzIgHAMCMeAAAzIgHAMCMeAAAzIgHAMCMeAAAzIgHAMCMeAAAzIgHAMCMeAAAzIgHAMCsRbyrriRdunTV7RGavLCwUNbJD9aoZlgn/5rDGvGuugCAekU8AABmxAMAYEY8AABmxAMAYNZiftsKAFB/2HkAAMyIBwDAjHgAAMyIBwDAjHgAAMyIBwDAjHgAAMzuqnhUVFRo3rx5SkhIUGJios6fP3/L8U8++USjRo3SmDFjtHfvXpemdJe/NZKky5cvy+v1qrS01IUJmwZ/65SRkaHRo0dr9OjRWr58uUtTusvfGn388cd6/vnnFR8f32K/3qSafc1VVFRo0qRJ2rJliwsT1pJzF/nyyy+dOXPmOI7jOD/++KMzbdq0ymN//PGH88wzzzilpaVOYWFh5Z9bmurWyHEcJysry3n22WedqKgop6SkxI0Rm4Tq1unChQtOXFycU15e7ty8edNJSEhwjh8/7taorqlujQoKCpyRI0c6ZWVlztWrV52YmBinoqLCrVFd5e9rznEcZ+nSpU58fLyzefPmxh6v1u6qncehQ4c0ePBgSVLv3r115MiRymM5OTmKiopScHCwQkND1alTJ504ccKtUV1T3RpJUkBAgNavX6/77rvPjfGajOrWqWPHjlqzZo1atWqlgIAAlZeXq3Xr1m6N6prq1qhDhw767LPPFBQUpPz8fLVr104ej8etUV3l72tu9+7d8ng8iomJcWO8Wrur4lFUVKSQkJDKj1u1aqXy8vLKY6Ghf/3HJm3btlVRUVGjz+i26tZIkgYOHKj27du7MVqTUt06BQUFqUOHDnIcR++//7569uypLl26uDWqa/x9LgUGBmrTpk1KSEjQ008/7caITUJ163Ty5Ent2LFDSUlJbo1Xa3dVPEJCQlRcXFz5cUVFhQIDA6s8VlxcfEtMWorq1gh/8bdOpaWlmjlzpoqLi/XOO++4MaLravK59OKLLyo7O1sHDx7Ud99919gjNgnVrdP27dt18eJFTZgwQZ9++qkyMjKUlZXl1qgmd1U8+vTpU7nwP/30k7p37155rFevXjp06JBKS0t19epV5ebm3nK8pahujfCX6tbJcRy9+uqrevTRRzV//ny1atXKrTFdVd0anTlzRtOnT5fjOAoKClJwcLACAu6qv25qrLp1mj17trZt26aNGzcqLi5OEydObDY/vrqrvuUcPny49u/fr7Fjx8pxHC1atEjr169Xp06dFBsbq8TERI0fP16O4yg5OblF/pza3xrh/1S3ThUVFfr+++9VVlam7OxsSVJKSoqioqJcnrpx+ftcioyMVEJCgjwejwYPHqwnnnjC7ZFdcbd+zfGW7AAAs5a5jwQA1AnxAACYEQ8AgBnxAACYEQ8AgBnxAACYEQ8AgNl/ASR4D9gZMQv3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "master.plot_feature_importance_mapper(pipe,mapper_super_feat_eng, 'DT' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# INICIAL ROUND"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this section we gonna evaluate the estimators with its default parameter.\n",
    "All models in this section share the same pipeline structure, except fot the final element.\n",
    "Couldn`t make use of all dataset due to memory capabilities of my mac pro. Used 8000 samples for training and another 8000 samples for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LINEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LinearSVC', 'LGR', 'LDA']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGR_1   Cross Validation is Done\n",
      "LGR_1   pickled to disk\n",
      "CPU times: user 1.19 s, sys: 891 ms, total: 2.08 s\n",
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "    ('LGR', clf['LGR'])])\n",
    "\n",
    "md_LGR_1 = Analytica_Bolada(clf['LGR'], None, 'LGR_1')\n",
    "md_LGR_1.evaluate_CV(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGR_1_2   Cross Validation is Done\n",
      "LGR_1_2   pickled to disk\n",
      "CPU times: user 1.26 s, sys: 988 ms, total: 2.25 s\n",
      "Wall time: 2min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "    ('Scalar', StandardScaler(with_mean=False)),\n",
    "    ('LGR', clf['LGR'])])\n",
    "\n",
    "md_LGR_1_2 = Analytica_Bolada(clf['LGR'], None, 'LGR_1_2')\n",
    "md_LGR_1_2.evaluate_CV(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC_1   Cross Validation is Done\n",
      "LinearSVC_1   pickled to disk\n",
      "CPU times: user 1.26 s, sys: 981 ms, total: 2.24 s\n",
      "Wall time: 2min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "    ('LinearSVC', clf['LinearSVC'])])\n",
    "\n",
    "md_LinearSVC_1 = Analytica_Bolada(clf['LinearSVC'], None, 'LinearSVC_1')\n",
    "md_LinearSVC_1.evaluate_CV(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## TREES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DT', 'ADA', 'RF', 'XT', 'GB']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT_1   Cross Validation is Done\n",
      "DT_1   pickled to disk\n",
      "CPU times: user 1.28 s, sys: 990 ms, total: 2.27 s\n",
      "Wall time: 3min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "#     ('Dense', DenseTransformer()),\n",
    "    ('DT', clf['DT'])])\n",
    "\n",
    "md_DT_1 = Analytica_Bolada(clf['DT'], None, 'DT_1')\n",
    "md_DT_1.evaluate_CV(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADA_1   Cross Validation is Done\n",
      "ADA_1   pickled to disk\n",
      "CPU times: user 1.32 s, sys: 1.02 s, total: 2.35 s\n",
      "Wall time: 3min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "#     ('Dense', DenseTransformer()),\n",
    "    ('ADA', clf['ADA'])])\n",
    "\n",
    "md_ADA_1 = Analytica_Bolada(clf['ADA'], None, 'ADA_1')\n",
    "md_ADA_1.evaluate_CV(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF_1   Cross Validation is Done\n",
      "RF_1   pickled to disk\n",
      "CPU times: user 1.27 s, sys: 966 ms, total: 2.23 s\n",
      "Wall time: 2min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "#     ('Dense', DenseTransformer()),\n",
    "    ('RF', clf['RF'])])\n",
    "\n",
    "md_RF_1 = Analytica_Bolada(clf['RF'], None, 'RF_1')\n",
    "md_RF_1.evaluate_CV(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XT_1   Cross Validation is Done\n",
      "XT_1   pickled to disk\n",
      "CPU times: user 1.28 s, sys: 983 ms, total: 2.26 s\n",
      "Wall time: 2min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "#     ('Dense', DenseTransformer()),\n",
    "    ('XT', clf['XT'])])\n",
    "\n",
    "md_XT_1 = Analytica_Bolada(clf['XT'], None, 'XT_1')\n",
    "md_XT_1.evaluate_CV(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB_1   Cross Validation is Done\n",
      "GB_1   pickled to disk\n",
      "CPU times: user 1.36 s, sys: 1.01 s, total: 2.37 s\n",
      "Wall time: 5min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "#     ('Dense', DenseTransformer()),\n",
    "    ('GB', clf['GB'])])\n",
    "\n",
    "md_GB_1 = Analytica_Bolada(clf['GB'], None, 'GB_1')\n",
    "md_GB_1.evaluate_CV(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## SVC,  NB,  KNN,  SGDC,  M_NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SVC', 'NB', 'KNN', 'SGDC', 'M_NB']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# pipe = Pipeline([\n",
    "#     ('col', Col_Extractor(['review'])),\n",
    "#     ('prep', Preprocessor()),\n",
    "\n",
    "#     ('feats', FeatureUnion([\n",
    "#         ('ngram_tf_idf', Pipeline([\n",
    "#             ('to_array', To_array()),\n",
    "#             ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "#             ('tf_idf', TfidfTransformer())])),\n",
    "#         ('mean_word_len', mean_word_len()),\n",
    "#     ])),\n",
    "#     ('SVC', clf['SVC'])])\n",
    "\n",
    "# md_SVC_1 = Analytica_Bolada(clf['SVC'], None, 'SVC_1')\n",
    "# md_SVC_1.evaluate_CV(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB_1   Cross Validation is Done\n",
      "NB_1   pickled to disk\n",
      "CPU times: user 1.42 s, sys: 1.52 s, total: 2.94 s\n",
      "Wall time: 3min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "    ('Dense', DenseTransformer()),\n",
    "    ('NB', clf['NB'])])\n",
    "\n",
    "md_NB_1 = Analytica_Bolada(clf['NB'], None, 'NB_1')\n",
    "md_NB_1.evaluate_CV(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_NB_1   Cross Validation is Done\n",
      "M_NB_1   pickled to disk\n",
      "CPU times: user 1.29 s, sys: 1.03 s, total: 2.33 s\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "    ('M_NB', clf['M_NB'])])\n",
    "\n",
    "md_M_NB_1 = Analytica_Bolada(clf['M_NB'], None, 'M_NB_1')\n",
    "md_M_NB_1.evaluate_CV(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN_1   Cross Validation is Done\n",
      "KNN_1   pickled to disk\n",
      "CPU times: user 1.32 s, sys: 1.05 s, total: 2.37 s\n",
      "Wall time: 2min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# tirei o dense pra ver se agora vai\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "#     ('Dense', DenseTransformer()),\n",
    "    ('KNN', clf['KNN'])])\n",
    "\n",
    "md_KNN_1 = Analytica_Bolada(clf['KNN'], None, 'KNN_1')\n",
    "md_KNN_1.evaluate_CV(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDC_1   Cross Validation is Done\n",
      "SGDC_1   pickled to disk\n",
      "CPU times: user 1.26 s, sys: 876 ms, total: 2.14 s\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "#     ('Dense', DenseTransformer()),\n",
    "    ('SGDC', clf['SGDC'])])\n",
    "\n",
    "md_SGDC_1 = Analytica_Bolada(clf['SGDC'], None, 'SGDC_1')\n",
    "md_SGDC_1.evaluate_CV(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Round 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc : 0.76712\n",
      "LGR_2   pickled to disk\n",
      "LGR_2   HP2 Done. Model is Fitted and Scored. Results in Evaluations_all.\n",
      "CPU times: user 2min 26s, sys: 18.9 s, total: 2min 45s\n",
      "Wall time: 2h 39min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param['LGR_2'] = {\n",
    "    'feats__ngram_tf_idf__counts__min_df': hp.choice('zz_min_df', [2, 3, 4, 5]),\n",
    "    'feats__ngram_tf_idf__counts__ngram_range': hp.choice('ngram_range', [(1, 2), (1, 3)]),\n",
    "#     'feats__ngram_tf_idf__counts__analyzer': hp.choice('analyzer', ['word', 'char', 'char_wb']),\n",
    "    'feats__ngram_tf_idf__counts__analyzer': hp.choice('analyzer', ['char_wb', 'char']),\n",
    "#     'feats__ngram_tf_idf__counts__stop_words': hp.choice('stop_words', [stop_words, None]),\n",
    "#     'feats__ngram_tf_idf__counts__tokenizer': hp.choice('tokenizer', [tokenizer_split, tokenizer_porter]),\n",
    "    'LGR__penalty': hp.choice('LGR__penalty', ['l1', 'l2']),\n",
    "    'LGR__C': hp.uniform('LGR__C',1, 1000)\n",
    "}\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "    ('LGR', clf['LGR']) ])\n",
    "\n",
    "md_LGR_21 = Analytica_Bolada(clf['LGR'], param['LGR_2'], 'LGR_2')\n",
    "md_LGR_21.evaluate_HP2(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc : 0.83452\n",
      "GB_2   pickled to disk\n",
      "GB_2   HP2 Done. Model is Fitted and Scored. Results in Evaluations_all.\n",
      "CPU times: user 7min 19s, sys: 20.4 s, total: 7min 40s\n",
      "Wall time: 5h 28min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param['GB_2'] = {\n",
    "    'feats__ngram_tf_idf__counts__min_df': hp.choice('min_df', [2, 3, 4]),\n",
    "    'feats__ngram_tf_idf__counts__ngram_range': hp.choice('mngram_range', [(1, 2), (1, 3)]),\n",
    "    'feats__ngram_tf_idf__counts__analyzer': hp.choice('analyzer', ['word', 'char', 'char_wb']),\n",
    "    'feats__ngram_tf_idf__counts__stop_words': hp.choice('stop_words', [stop_words, None]),\n",
    "    'feats__ngram_tf_idf__counts__tokenizer': hp.choice('tokenizer', [tokenizer_split, tokenizer_porter]),\n",
    "    'GB__max_depth'        : hp.choice(\"max_depth\",        np.arange(4, 7,    dtype=int)), \n",
    "    'GB__learning_rate'    : hp.loguniform('learning_rate', -6.9, -2.3),\n",
    "#     'GB__n_estimators'     : hp.choice('n_estimators', 100, 500, 1000),\n",
    "    'GB__random_state'    : hp.randint('random_state',20)\n",
    "   }\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "    ('GB', clf['GB'])])\n",
    "\n",
    "# pipe.fit(X_train, y_train)\n",
    "md_GB_2 = Analytica_Bolada(clf['GB'], param['GB_2'], 'GB_2')\n",
    "md_GB_2.evaluate_HP2(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc : 0.85504\n",
      "RF_2   pickled to disk\n",
      "RF_2   HP2 Done. Model is Fitted and Scored. Results in Evaluations_all.\n",
      "CPU times: user 10min 58s, sys: 21 s, total: 11min 19s\n",
      "Wall time: 2h 56min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# RF\n",
    "start = timer()\n",
    "param['RF_2'] = {\n",
    "    'feats__ngram_tf_idf__counts__min_df': hp.choice('zz_min_df', [2, 3, 4]),\n",
    "    'feats__ngram_tf_idf__counts__ngram_range': hp.choice('zz_ngram_range', [(1, 2), (1, 3)]),\n",
    "    'feats__ngram_tf_idf__counts__analyzer': hp.choice('analyzer', ['word', 'char', 'char_wb']),\n",
    "    'feats__ngram_tf_idf__counts__stop_words': hp.choice('stop_words', [stop_words, None]),\n",
    "    'feats__ngram_tf_idf__counts__tokenizer': hp.choice('tokenizer', [tokenizer_split, tokenizer_porter]),\n",
    "    'RF__n_estimators': hp.choice('zz_RF__n_estimators',         np.arange(20, 1001, 50, dtype=int)),\n",
    "    'RF__max_depth': hp.choice(\"zz_RF__max_depth\",            np.arange(5, 100, 10,    dtype=int)),\n",
    "    'RF__min_samples_split': hp.choice(\"zz_RF__min_samples_split\",    np.arange(2, 30,    dtype=int)),\n",
    "    'RF__min_samples_leaf': hp.uniform(\"RF__min_samples_leaf\", 0, 0.5),\n",
    "    'RF__criterion': hp.choice('RF__criterion', [\"gini\", \"entropy\"]),\n",
    "    'RF__max_features': hp.choice('RF__max_features', ['auto', 'sqrt']),\n",
    "    'RF__n_jobs': -1,\n",
    "    'RF__oob_score': True,\n",
    "#     'RF__verbose': 1,\n",
    "    'RF__random_state': hp.randint('random_state', 20)\n",
    "}\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "    ('RF', clf['RF'])])\n",
    "\n",
    "# pipe.fit(X_train, y_train)\n",
    "md_RF_2 = Analytica_Bolada(clf['RF'], param['RF_2'], 'RF_2')\n",
    "md_RF_2.evaluate_HP2(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc : 0.86124\n",
      "XT_2   pickled to disk\n",
      "XT_2   HP2 Done. Model is Fitted and Scored. Results in Evaluations_all.\n",
      "CPU times: user 7min 11s, sys: 23.4 s, total: 7min 34s\n",
      "Wall time: 3h 14min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# XT\n",
    "start = timer()\n",
    "param['XT_2'] = {\n",
    "    'feats__ngram_tf_idf__counts__min_df': hp.choice('zz_min_df', [2, 3, 4]),\n",
    "    'feats__ngram_tf_idf__counts__ngram_range': hp.choice('mngram_range', [(1, 2), (1, 3)]),\n",
    "    'feats__ngram_tf_idf__counts__analyzer': hp.choice('analyzer', ['word', 'char', 'char_wb']),\n",
    "    'feats__ngram_tf_idf__counts__stop_words': hp.choice('stop_words', [stop_words, None]),\n",
    "    'feats__ngram_tf_idf__counts__tokenizer': hp.choice('tokenizer', [tokenizer_split, tokenizer_porter]),\n",
    "    'XT__n_estimators': hp.choice('zz_XT__n_estimators',         np.arange(20, 1001, 50, dtype=int)),\n",
    "    'XT__max_depth': hp.choice(\"zz_XT__max_depth\",            np.arange(5, 100, 10,    dtype=int)),\n",
    "    'XT__min_samples_split': hp.choice(\"zz_XT__min_samples_split\",    np.arange(2, 30,    dtype=int)),\n",
    "    'XT__min_samples_leaf': hp.uniform(\"XT__min_samples_leaf\", 0, 0.5),\n",
    "    'XT__criterion': hp.choice('RF__criterion', [\"gini\", \"entropy\"]),\n",
    "    'XT__max_features': hp.choice('RF__max_features', ['auto', 'sqrt']),\n",
    "    'XT__n_jobs': -1,\n",
    "    'XT__oob_score': True,\n",
    "    'XT__bootstrap': True,\n",
    "#     'XT__verbose': 1,\n",
    "    'XT__random_state': hp.randint('random_state', 20)\n",
    "}\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "    ('XT', clf['XT'])])\n",
    "\n",
    "# pipe.fit(X_train, y_train)\n",
    "md_XT_2 = Analytica_Bolada(clf['XT'], param['XT_2'], 'XT_2')\n",
    "md_XT_2.evaluate_HP2(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['LGR_1', 'LGR_1_2', 'LinearSVC_1', 'DT_1', 'ADA_1', 'RF_1', 'XT_1', 'GB_1', 'NB_1', 'M_NB_1', 'KNN_1', 'SGDC_1', 'LGR_2', 'GB_2', 'RF_2', 'XT_2'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.get_members_evaluations_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving l_curve_ image for  LGR_1\n",
      "saving l_curve_ image for  LGR_1_2\n",
      "saving l_curve_ image for  LinearSVC_1\n",
      "saving l_curve_ image for  DT_1\n",
      "saving l_curve_ image for  ADA_1\n",
      "saving l_curve_ image for  RF_1\n",
      "saving l_curve_ image for  XT_1\n",
      "saving l_curve_ image for  GB_1\n",
      "saving l_curve_ image for  NB_1\n",
      "saving l_curve_ image for  M_NB_1\n",
      "saving l_curve_ image for  KNN_1\n",
      "saving l_curve_ image for  SGDC_1\n",
      "saving l_curve_ image for  LGR_2\n",
      "saving l_curve_ image for  GB_2\n",
      "saving l_curve_ image for  RF_2\n",
      "saving l_curve_ image for  XT_2\n",
      "saving c_reprt_ image for LGR_1\n",
      "saving c_reprt_ image for LGR_1_2\n",
      "saving c_reprt_ image for LinearSVC_1\n",
      "saving c_reprt_ image for DT_1\n",
      "saving c_reprt_ image for ADA_1\n",
      "saving c_reprt_ image for RF_1\n",
      "saving c_reprt_ image for XT_1\n",
      "saving c_reprt_ image for GB_1\n",
      "saving c_reprt_ image for NB_1\n",
      "saving c_reprt_ image for M_NB_1\n",
      "saving c_reprt_ image for KNN_1\n",
      "saving c_reprt_ image for SGDC_1\n",
      "saving c_reprt_ image for LGR_2\n",
      "saving c_reprt_ image for GB_2\n",
      "saving c_reprt_ image for RF_2\n",
      "saving c_reprt_ image for XT_2\n",
      "saving c_matrx_ image for LGR_1\n",
      "saving c_matrx_ image for LGR_1_2\n",
      "saving c_matrx_ image for LinearSVC_1\n",
      "saving c_matrx_ image for DT_1\n",
      "saving c_matrx_ image for ADA_1\n",
      "saving c_matrx_ image for RF_1\n",
      "saving c_matrx_ image for XT_1\n",
      "saving c_matrx_ image for GB_1\n",
      "saving c_matrx_ image for NB_1\n",
      "saving c_matrx_ image for M_NB_1\n",
      "saving c_matrx_ image for KNN_1\n",
      "saving c_matrx_ image for SGDC_1\n",
      "saving c_matrx_ image for LGR_2\n",
      "saving c_matrx_ image for GB_2\n",
      "saving c_matrx_ image for RF_2\n",
      "saving c_matrx_ image for XT_2\n",
      "CPU times: user 1h 6min 58s, sys: 2min 18s, total: 1h 9min 17s\n",
      "Wall time: 3h 45min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "master.plot_learning_curve(load_saved=False)\n",
    "master.plot_Classification_Report(load_saved=False)\n",
    "master.plot_Confusion_Matrix(load_saved=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-caa0e9a72533>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmaster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_ROC_AUC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_saved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-e0b2414dfcbf>\u001b[0m in \u001b[0;36mplot_ROC_AUC\u001b[0;34m(self, load_saved, chosen)\u001b[0m\n\u001b[1;32m    241\u001b[0m                 \u001b[0mvisualizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mROCAUC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0mvisualizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m                 \u001b[0mvisualizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m                 \u001b[0mvisualizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../pkl/roc_auc_'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/yellowbrick/classifier/rocauc.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Compute the predictions for the test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_y_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;31m# # Classes may be label encoded so only use what's in y to compute.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/yellowbrick/classifier/rocauc.py\u001b[0m in \u001b[0;36m_get_y_scores\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    297\u001b[0m                 \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                 \u001b[0;31m# Some Scikit-Learn estimators have both probability and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-ec0dfb24273e>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, **transform_params)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<[^>]*>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m     \u001b[0;31m# applying elementwise to a DF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0memoticons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'(?::|;|=)(?:-)?(?:\\)|\\(|D|P)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[\\W]+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m             \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memoticons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapplymap\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m   6060\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6062\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6064\u001b[0m     \u001b[0;31m# ----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6002\u001b[0m                          \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6003\u001b[0m                          kwds=kwds)\n\u001b[0;32m-> 6004\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m                                       *self.args, **self.kwds)\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFrameRowApply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    240\u001b[0m                                           \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                                           \u001b[0mdummy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdummy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m                                           labels=labels)\n\u001b[0m\u001b[1;32m    243\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.reduce\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.Reducer.get_result\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   6058\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6059\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6060\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6062\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-ec0dfb24273e>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<[^>]*>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m     \u001b[0;31m# applying elementwise to a DF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0memoticons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'(?::|;|=)(?:-)?(?:\\)|\\(|D|P)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[\\W]+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m             \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memoticons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1491\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m         \u001b[0;34m\"\"\"Iterate over infor axis\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1493\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m     \u001b[0;31m# can we get a better explanation of this?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    918\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;32mfor\u001b[0m \u001b[0mTimestamp\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mTimedelta\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mInterval\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mPeriod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m         \"\"\"\n\u001b[0;32m--> 920\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36mtolist\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \"\"\"\n\u001b[0;32m--> 905\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mis_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_box_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_datetimelike\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mis_timedelta64_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m             \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCPeriodIndex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m             is_datetimetz(arr))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_datetimetz\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# It seems like a repeat of is_datetime64tz_dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m     return ((isinstance(arr, ABCDatetimeIndex) and\n\u001b[0m\u001b[1;32m    269\u001b[0m              getattr(arr, 'tz', None) is not None) or\n\u001b[1;32m    270\u001b[0m             is_datetime64tz_dtype(arr))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "master.plot_ROC_AUC(load_saved=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "392px",
    "left": "1011px",
    "top": "93px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
