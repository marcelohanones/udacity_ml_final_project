{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Load Libraries / Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ../modules/library_to_import.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../modules/Class_imdb.ipynb\n",
    "%run ../modules/transformers_imdb.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg\n",
    "# import seaborn as sns\n",
    "\n",
    "# # %matplotlib inline\n",
    "# # sns.set(style='white', context='notebook', palette='deep')\n",
    "# sns.set()\n",
    "# sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# from sklearn.exceptions import DataConversionWarning\n",
    "# warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "evaluations_all -  it is a dictionary where all the information regarding models performance scores gets recorded. It`s the 'cloud'.\n",
    "\n",
    "By acessing the 'cloud' the Class Super_Analtica will work in groups.\n",
    "Analytica_bolada is lower level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's hard to put your finger on this one. Basi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I mean, nothing happens, 5 dumb kids go to Okl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Så som in himmelen\" was probably one of the 3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This noir may not be the best remembered film ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'll be honest with yall, I was a junior in hi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  It's hard to put your finger on this one. Basi...          1\n",
       "1  I mean, nothing happens, 5 dumb kids go to Okl...          0\n",
       "2  \"Så som in himmelen\" was probably one of the 3...          1\n",
       "3  This noir may not be the best remembered film ...          1\n",
       "4  I'll be honest with yall, I was a junior in hi...          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/movie_data.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['review'].values\n",
    "y = df['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./params_imdb.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's hard to put your finger on this one. Basi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I mean, nothing happens, 5 dumb kids go to Okl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Så som in himmelen\" was probably one of the 3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This noir may not be the best remembered film ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'll be honest with yall, I was a junior in hi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  It's hard to put your finger on this one. Basi...          1\n",
       "1  I mean, nothing happens, 5 dumb kids go to Okl...          0\n",
       "2  \"Så som in himmelen\" was probably one of the 3...          1\n",
       "3  This noir may not be the best remembered film ...          1\n",
       "4  I'll be honest with yall, I was a junior in hi...          1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      "review       50000 non-null object\n",
      "sentiment    50000 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 781.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.head()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.5\n",
       "0    0.5\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "feature union is for applying different vectorizers for different columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X  y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "\n",
    "# # DATAFRAMES USED ONLY WHEN NEED MORE THAN 1 COLUMN\n",
    "# WORKS with sklearn-pandas to drive dataframes in sklearn or column extractor e To_Matrix\n",
    "# X_train = df.loc[:500, ['review']].reset_index(drop=True)\n",
    "# y_train = df.loc[:500, ['sentiment']].reset_index(drop=True)\n",
    "# X_test = df.loc[49950:, ['review']].reset_index(drop=True)\n",
    "# y_test = df.loc[49950:, ['sentiment']].reset_index(drop=True)\n",
    "\n",
    "X_train = df.loc[:25000, ['review']].reset_index(drop=True)\n",
    "y_train = df.loc[:25000, ['sentiment']].reset_index(drop=True)\n",
    "X_test = df.loc[25000:, ['review']].reset_index(drop=True)\n",
    "y_test = df.loc[25000:, ['sentiment']].reset_index(drop=True)\n",
    "\n",
    "# X_train = df.loc[:100, ['review']].reset_index(drop=True)\n",
    "# y_train = df.loc[:100, ['sentiment']].reset_index(drop=True)\n",
    "# X_test = df.loc[49900:, ['review']].reset_index(drop=True)\n",
    "# y_test = df.loc[49900:, ['sentiment']].reset_index(drop=True)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=random_state)\n",
    "# kfold = 5\n",
    "# kfold = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_style": "split",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's hard to put your finger on this one. Basi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I mean, nothing happens, 5 dumb kids go to Okl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Så som in himmelen\" was probably one of the 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This noir may not be the best remembered film ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'll be honest with yall, I was a junior in hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Damon Runyon's world of Times Square, in New Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>After a group of young friends experience car ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What makes for Best Picture material? The Osca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I found this film extremely disturbing. Treadw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This DVD set is the complete widescreen 15-epi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kevin Kline and Meg Ryan are among that class ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Well...there were some great, creamy-smooth fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>If I had not read Pat Barker's 'Union Street' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>This movie is fun to watch. If you liked \"Dave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A charming, funny film that gets a solid grade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The movie is about a day in the life of a woma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I just rented this movie from the video store ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I suppose I always felt that Hotel du Nord was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I saw this on cable. Someone had to lose their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>I was one of quite a few extras in this big bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Raising Victor Vargas is a movie you definitel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>First of all, I believe that this movie is muc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Jörg Buttgereit goes a bit too far with his mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>I had the opportunity to see this last evening...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Certainly not horrible, but definitely not goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Before watching this movie from beginning to e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Outrageously trashy karate/horror thriller wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\"Death Promise\" is a lost 70's exploitation ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Of the Korean movies I've seen, only three had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Of course I have disappeared into the movies. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24971</th>\n",
       "      <td>William Shatner in small doses is tolerable. U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24972</th>\n",
       "      <td>My mother worked with Dennis L. Raider for ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24973</th>\n",
       "      <td>First of all, as a long time student of the Ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24974</th>\n",
       "      <td>Kids - of whatever age - do not want to know a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24975</th>\n",
       "      <td>It is a superb Swedish film .. it was the firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24976</th>\n",
       "      <td>...about the importance of being young, having...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24977</th>\n",
       "      <td>Ironically the most talked-about American film...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24978</th>\n",
       "      <td>Stupid! Stupid! Stupid! I can not stand Ben st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24979</th>\n",
       "      <td>This is an excellent James Bond movie. Althoug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24980</th>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt;When I first started watching this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24981</th>\n",
       "      <td>Let's not fool ourselves, okay? We all know th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24982</th>\n",
       "      <td>Strange but acceptable mob comedy that has an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24983</th>\n",
       "      <td>Are you kidding me?! A show highlighting someo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24984</th>\n",
       "      <td>A mediocre Sci-Fi Channel original picture. A ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24985</th>\n",
       "      <td>Did this gem go direct to video? Fabulous art ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24986</th>\n",
       "      <td>Flynn, known mostly for his swashbuckling role...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24987</th>\n",
       "      <td>I just came back from the Late-night cinema an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24988</th>\n",
       "      <td>I think Purvis starts out to do a gay \"Gone Wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24989</th>\n",
       "      <td>Along with virtually every Republic Picture ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24990</th>\n",
       "      <td>This movie is a crappy and forgettable Sean Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24991</th>\n",
       "      <td>This film is totally mindblowing. It manages t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24992</th>\n",
       "      <td>How amazing this film is! I've seen it over an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24993</th>\n",
       "      <td>Jimmy Cagney races by your eyes constantly in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>I was entranced by this touching and hilarious...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>This is a very beautiful and almost meditative...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>If you were ever sad for not being able to get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>I am sitting here watching the film, Tango and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>It's really just terrible. Quaid overacts more...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>Almost no information is available about this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25000</th>\n",
       "      <td>This movie is just like every other dutch movi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25001 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review\n",
       "0      It's hard to put your finger on this one. Basi...\n",
       "1      I mean, nothing happens, 5 dumb kids go to Okl...\n",
       "2      \"Så som in himmelen\" was probably one of the 3...\n",
       "3      This noir may not be the best remembered film ...\n",
       "4      I'll be honest with yall, I was a junior in hi...\n",
       "5      Damon Runyon's world of Times Square, in New Y...\n",
       "6      After a group of young friends experience car ...\n",
       "7      What makes for Best Picture material? The Osca...\n",
       "8      I found this film extremely disturbing. Treadw...\n",
       "9      This DVD set is the complete widescreen 15-epi...\n",
       "10     Kevin Kline and Meg Ryan are among that class ...\n",
       "11     Well...there were some great, creamy-smooth fa...\n",
       "12     If I had not read Pat Barker's 'Union Street' ...\n",
       "13     This movie is fun to watch. If you liked \"Dave...\n",
       "14     A charming, funny film that gets a solid grade...\n",
       "15     The movie is about a day in the life of a woma...\n",
       "16     I just rented this movie from the video store ...\n",
       "17     I suppose I always felt that Hotel du Nord was...\n",
       "18     I saw this on cable. Someone had to lose their...\n",
       "19     I was one of quite a few extras in this big bo...\n",
       "20     Raising Victor Vargas is a movie you definitel...\n",
       "21     First of all, I believe that this movie is muc...\n",
       "22     Jörg Buttgereit goes a bit too far with his mo...\n",
       "23     I had the opportunity to see this last evening...\n",
       "24     Certainly not horrible, but definitely not goo...\n",
       "25     Before watching this movie from beginning to e...\n",
       "26     Outrageously trashy karate/horror thriller wit...\n",
       "27     \"Death Promise\" is a lost 70's exploitation ge...\n",
       "28     Of the Korean movies I've seen, only three had...\n",
       "29     Of course I have disappeared into the movies. ...\n",
       "...                                                  ...\n",
       "24971  William Shatner in small doses is tolerable. U...\n",
       "24972  My mother worked with Dennis L. Raider for ele...\n",
       "24973  First of all, as a long time student of the Ti...\n",
       "24974  Kids - of whatever age - do not want to know a...\n",
       "24975  It is a superb Swedish film .. it was the firs...\n",
       "24976  ...about the importance of being young, having...\n",
       "24977  Ironically the most talked-about American film...\n",
       "24978  Stupid! Stupid! Stupid! I can not stand Ben st...\n",
       "24979  This is an excellent James Bond movie. Althoug...\n",
       "24980  <br /><br />When I first started watching this...\n",
       "24981  Let's not fool ourselves, okay? We all know th...\n",
       "24982  Strange but acceptable mob comedy that has an ...\n",
       "24983  Are you kidding me?! A show highlighting someo...\n",
       "24984  A mediocre Sci-Fi Channel original picture. A ...\n",
       "24985  Did this gem go direct to video? Fabulous art ...\n",
       "24986  Flynn, known mostly for his swashbuckling role...\n",
       "24987  I just came back from the Late-night cinema an...\n",
       "24988  I think Purvis starts out to do a gay \"Gone Wi...\n",
       "24989  Along with virtually every Republic Picture ev...\n",
       "24990  This movie is a crappy and forgettable Sean Co...\n",
       "24991  This film is totally mindblowing. It manages t...\n",
       "24992  How amazing this film is! I've seen it over an...\n",
       "24993  Jimmy Cagney races by your eyes constantly in ...\n",
       "24994  I was entranced by this touching and hilarious...\n",
       "24995  This is a very beautiful and almost meditative...\n",
       "24996  If you were ever sad for not being able to get...\n",
       "24997  I am sitting here watching the film, Tango and...\n",
       "24998  It's really just terrible. Quaid overacts more...\n",
       "24999  Almost no information is available about this ...\n",
       "25000  This movie is just like every other dutch movi...\n",
       "\n",
       "[25001 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_style": "split",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This movie is just like every other dutch movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I just recently viewed Shame which is directed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Larry Bishop is 60-years old, dirty and not go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pretentious storytelling such as this always u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>... and how they bore you right out of your mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I remember flipping through channels on HBO an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I felt compelled to write about this movie aft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Make no mistake, Maureen O'Sullivan is easily ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Looking for a REAL super bad movie? If you wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>One of the worst movies ever made... If you ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>After viewing this film, I felt the compelling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>It's difficult to make it through this movie w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>There is no possible reason I can fathom why t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>This is a excellent series. You will laugh, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The comparison is perhaps unfair, but inevitab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I saw this movie twice. I can't believe Pintil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>This is a disappointing adaptation of the Jame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Who could possibly have wished for a sequel to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Despite a tight narrative, Johnnie To's Electi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>This film is about a deadly poison that is con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>What a wonderful documentary - I sat down thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Iberia is nice to see on TV. But why see this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Featuring a few of Hammer's all-stars, this hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The superb star quality of Gerard Philipe, who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>I have never read the book\"A wrinkle in time\"....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>This is by far the worst horror/thriller I've ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>When I saw the poster at the theater, I though...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>I think it was a pretty good film. It shows ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>The only reason I'm giving this a 9 is that th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>I usually enjoy underground movies and antiher...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24970</th>\n",
       "      <td>I understand what this movie was trying to por...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24971</th>\n",
       "      <td>There is part of one sequence where some water...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24972</th>\n",
       "      <td>I think we all begin a lot of reviews with, \"T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24973</th>\n",
       "      <td>My daughter liked it but I was aghast, that a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24974</th>\n",
       "      <td>I just saw this film again, I believe for the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24975</th>\n",
       "      <td>It utterly defeats me why Godard is taken so s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24976</th>\n",
       "      <td>Jimmy (Heath Ledger) is given a simple job by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24977</th>\n",
       "      <td>I attempted to watch this film without being a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24978</th>\n",
       "      <td>Bloody Birthday plays on the assumed innocence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24979</th>\n",
       "      <td>Disappointing film. Performance of actors is w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24980</th>\n",
       "      <td>One of Warner Brothers best and highest grossi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24981</th>\n",
       "      <td>How this has not become a cult film I do not k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24982</th>\n",
       "      <td>The laughs are few and far between in this dul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24983</th>\n",
       "      <td>I wouldn't call \"We're Back! A Dinosaur's Stor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24984</th>\n",
       "      <td>I contend that whoever is ultimately responsib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24985</th>\n",
       "      <td>This was a well written tale of the Making of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24986</th>\n",
       "      <td>Even if you know absolutely nothing about Irel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24987</th>\n",
       "      <td>`Rock star' is not on its way to any `stairway...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24988</th>\n",
       "      <td>I bought this game on an impulse buy from walm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24989</th>\n",
       "      <td>A poorly-paced sf/horror venture that takes it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24990</th>\n",
       "      <td>I don't understand how this garbage got on the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24991</th>\n",
       "      <td>What seemed as a good premise for a movie...un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24992</th>\n",
       "      <td>Although compared with \"Mad Max\", this film is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24993</th>\n",
       "      <td>This show is a show that is great for adults a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>(No spoilers, just plot details) I can't under...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>I'd heard this Japanese flick is edgy, creativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>The director does not know what to do with a c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>I've seen this movie after watching Paltrow's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>I could never stand watching Happy Days after ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>Stephen Hawkings is a genius. He is the king o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review\n",
       "0      This movie is just like every other dutch movi...\n",
       "1      I just recently viewed Shame which is directed...\n",
       "2      Larry Bishop is 60-years old, dirty and not go...\n",
       "3      Pretentious storytelling such as this always u...\n",
       "4      ... and how they bore you right out of your mi...\n",
       "5      I remember flipping through channels on HBO an...\n",
       "6      I felt compelled to write about this movie aft...\n",
       "7      Make no mistake, Maureen O'Sullivan is easily ...\n",
       "8      Looking for a REAL super bad movie? If you wan...\n",
       "9      One of the worst movies ever made... If you ca...\n",
       "10     After viewing this film, I felt the compelling...\n",
       "11     It's difficult to make it through this movie w...\n",
       "12     There is no possible reason I can fathom why t...\n",
       "13     This is a excellent series. You will laugh, yo...\n",
       "14     The comparison is perhaps unfair, but inevitab...\n",
       "15     I saw this movie twice. I can't believe Pintil...\n",
       "16     This is a disappointing adaptation of the Jame...\n",
       "17     Who could possibly have wished for a sequel to...\n",
       "18     Despite a tight narrative, Johnnie To's Electi...\n",
       "19     This film is about a deadly poison that is con...\n",
       "20     What a wonderful documentary - I sat down thin...\n",
       "21     Iberia is nice to see on TV. But why see this ...\n",
       "22     Featuring a few of Hammer's all-stars, this hi...\n",
       "23     The superb star quality of Gerard Philipe, who...\n",
       "24     I have never read the book\"A wrinkle in time\"....\n",
       "25     This is by far the worst horror/thriller I've ...\n",
       "26     When I saw the poster at the theater, I though...\n",
       "27     I think it was a pretty good film. It shows ho...\n",
       "28     The only reason I'm giving this a 9 is that th...\n",
       "29     I usually enjoy underground movies and antiher...\n",
       "...                                                  ...\n",
       "24970  I understand what this movie was trying to por...\n",
       "24971  There is part of one sequence where some water...\n",
       "24972  I think we all begin a lot of reviews with, \"T...\n",
       "24973  My daughter liked it but I was aghast, that a ...\n",
       "24974  I just saw this film again, I believe for the ...\n",
       "24975  It utterly defeats me why Godard is taken so s...\n",
       "24976  Jimmy (Heath Ledger) is given a simple job by ...\n",
       "24977  I attempted to watch this film without being a...\n",
       "24978  Bloody Birthday plays on the assumed innocence...\n",
       "24979  Disappointing film. Performance of actors is w...\n",
       "24980  One of Warner Brothers best and highest grossi...\n",
       "24981  How this has not become a cult film I do not k...\n",
       "24982  The laughs are few and far between in this dul...\n",
       "24983  I wouldn't call \"We're Back! A Dinosaur's Stor...\n",
       "24984  I contend that whoever is ultimately responsib...\n",
       "24985  This was a well written tale of the Making of ...\n",
       "24986  Even if you know absolutely nothing about Irel...\n",
       "24987  `Rock star' is not on its way to any `stairway...\n",
       "24988  I bought this game on an impulse buy from walm...\n",
       "24989  A poorly-paced sf/horror venture that takes it...\n",
       "24990  I don't understand how this garbage got on the...\n",
       "24991  What seemed as a good premise for a movie...un...\n",
       "24992  Although compared with \"Mad Max\", this film is...\n",
       "24993  This show is a show that is great for adults a...\n",
       "24994  (No spoilers, just plot details) I can't under...\n",
       "24995  I'd heard this Japanese flick is edgy, creativ...\n",
       "24996  The director does not know what to do with a c...\n",
       "24997  I've seen this movie after watching Paltrow's ...\n",
       "24998  I could never stand watching Happy Days after ...\n",
       "24999  Stephen Hawkings is a genius. He is the king o...\n",
       "\n",
       "[25000 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_style": "split",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24971</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24972</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24973</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24974</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24975</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24976</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24977</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24978</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24979</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24980</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24981</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24982</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24983</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24984</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24985</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24986</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24987</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24988</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24989</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24990</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24991</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24992</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24993</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25000</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25001 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment\n",
       "0              1\n",
       "1              0\n",
       "2              1\n",
       "3              1\n",
       "4              1\n",
       "5              1\n",
       "6              1\n",
       "7              1\n",
       "8              0\n",
       "9              1\n",
       "10             0\n",
       "11             0\n",
       "12             0\n",
       "13             1\n",
       "14             1\n",
       "15             0\n",
       "16             1\n",
       "17             1\n",
       "18             0\n",
       "19             0\n",
       "20             1\n",
       "21             1\n",
       "22             1\n",
       "23             1\n",
       "24             0\n",
       "25             1\n",
       "26             0\n",
       "27             1\n",
       "28             1\n",
       "29             0\n",
       "...          ...\n",
       "24971          0\n",
       "24972          0\n",
       "24973          0\n",
       "24974          1\n",
       "24975          1\n",
       "24976          1\n",
       "24977          1\n",
       "24978          0\n",
       "24979          1\n",
       "24980          0\n",
       "24981          0\n",
       "24982          1\n",
       "24983          0\n",
       "24984          0\n",
       "24985          1\n",
       "24986          1\n",
       "24987          1\n",
       "24988          0\n",
       "24989          1\n",
       "24990          0\n",
       "24991          1\n",
       "24992          1\n",
       "24993          1\n",
       "24994          1\n",
       "24995          1\n",
       "24996          1\n",
       "24997          0\n",
       "24998          0\n",
       "24999          1\n",
       "25000          0\n",
       "\n",
       "[25001 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_style": "split",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24970</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24971</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24972</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24973</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24974</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24975</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24976</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24977</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24978</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24979</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24980</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24981</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24982</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24983</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24984</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24985</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24986</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24987</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24988</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24989</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24990</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24991</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24992</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24993</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment\n",
       "0              0\n",
       "1              0\n",
       "2              0\n",
       "3              0\n",
       "4              0\n",
       "5              0\n",
       "6              0\n",
       "7              1\n",
       "8              0\n",
       "9              0\n",
       "10             0\n",
       "11             0\n",
       "12             0\n",
       "13             1\n",
       "14             0\n",
       "15             0\n",
       "16             0\n",
       "17             0\n",
       "18             1\n",
       "19             1\n",
       "20             1\n",
       "21             0\n",
       "22             1\n",
       "23             1\n",
       "24             0\n",
       "25             0\n",
       "26             0\n",
       "27             1\n",
       "28             1\n",
       "29             0\n",
       "...          ...\n",
       "24970          0\n",
       "24971          0\n",
       "24972          0\n",
       "24973          0\n",
       "24974          1\n",
       "24975          0\n",
       "24976          1\n",
       "24977          0\n",
       "24978          1\n",
       "24979          0\n",
       "24980          1\n",
       "24981          1\n",
       "24982          0\n",
       "24983          1\n",
       "24984          1\n",
       "24985          1\n",
       "24986          1\n",
       "24987          1\n",
       "24988          1\n",
       "24989          0\n",
       "24990          0\n",
       "24991          0\n",
       "24992          1\n",
       "24993          1\n",
       "24994          1\n",
       "24995          0\n",
       "24996          0\n",
       "24997          1\n",
       "24998          0\n",
       "24999          1\n",
       "\n",
       "[25000 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_style": "split",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25001, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "# X_train.info()\n",
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_style": "split",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25001, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n",
    "# y_train.info()\n",
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n",
    "# X_test.info()\n",
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape\n",
    "# y_train.info()\n",
    "type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_split(text):\n",
    "    return [porter.stem(w) for w in text.split(' ')]\n",
    "\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(w) for w in text.split(' ') if not w in stop_words ]\n",
    "\n",
    "tfidf = TfidfVectorizer(strip_accents=None, lowercase=False, preprocessor=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = Super_Analytica('master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../modules/params_imdb.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = ['num_words', 'num_unique_words' ,'num_chars', 'num_stopwords' ,'num_words_upper' ,'num_words_title', 'mean_word_len']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Pipeline standard \n",
    "explicar o prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "    ('to_array', To_array()),\n",
    "    ('counts', CountVectorizer(analyzer=\"word\",\n",
    "                               tokenizer=tokenizer_porter,\n",
    "                               stop_words=stop_words,\n",
    "                               max_features=5000))\n",
    "])\n",
    "\n",
    "train_features_matrix = pipe.fit_transform(X_train)\n",
    "vocab = pipe.named_steps['counts'].get_feature_names()\n",
    "\n",
    "train_features_matrix\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'vocabulary_5k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving vocabulary with pickle\n",
    "# joblib.dump(vocab, '../pkl/'+ filename + '.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading vocabulary\n",
    "vocab = joblib.load('../pkl/'+ filename + '.pkl') \n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# FEATURE IMPORTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# in order to measure feature importance for the new engineered features \n",
    "# we gonna use DataFrame Mapper from sklearn-pandas. \n",
    "# dessa maneira eu consigo declarar as novas features \n",
    "# as transformers and pipeline it, thus saving me the hassle of applying each feature to both train and test.\n",
    "# although this library applies the new features on the fly (pipeline) it has a attribute that returns feature names\n",
    "# making it easy to do feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc : 0.49\n",
      "DT_1   HP2 Done. Model is Fitted and Scored. Results in Evaluations_all.\n"
     ]
    }
   ],
   "source": [
    "# DATAFRAME MAPPER para calcular feat importances das new features\n",
    "# \n",
    "\n",
    "param['DT_1'] = {\"DT__criterion\" :'gini'}\n",
    "\n",
    "map_prep = DataFrameMapper([\n",
    "    (['review'], Preprocessor())], input_df=True, df_out=True)\n",
    "\n",
    "map_tfidf = DataFrameMapper([\n",
    "    ('review', [To_array(), TfidfVectorizer()])], input_df = True)\n",
    "\n",
    "mapper_super_feat_eng = DataFrameMapper([\n",
    "    (['review'], num_stop_words(), {'alias': 'n_stop_w'}),\n",
    "    (['review'], num_uni_words(), {'alias': 'n_uni_w'}),\n",
    "    (['review'], num_words_title(), {'alias': 'n_w_title'}),\n",
    "    (['review'], mean_word_len(), {'alias': 'm_w_len'})], input_df=True)\n",
    "\n",
    "\n",
    "# Feature_Importances - todos os transformers dentro de um mesmo mapper. \n",
    "pipe = Pipeline([\n",
    "    ('prep', map_prep),\n",
    "    ('f1', FeatureUnion([\n",
    "#         ('tfidf', map_tfidf),\n",
    "        ('new_features', mapper_super_feat_eng)\n",
    "    ])),\n",
    "    ('DT', clf['DT'])])\n",
    "\n",
    "md_DT_1 = Analytica_Bolada(clf['DT'], param['DT_1'], 'DT_1')\n",
    "md_DT_1.evaluate_HP2(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "master.plot_feature_importance_mapper(pipe,mapper_super_feat_eng, 'DT' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# INICIAL ROUND"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this section we gonna evaluate the estimators with its default parameter.\n",
    "All models in this section share the same pipeline structure, except fot the final element.\n",
    "Couldn`t make use of all dataset due to memory capabilities of my mac pro. Used 8000 samples for training and another 8000 samples for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LINEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.get_members_evaluations_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LinearSVC', 'LGR', 'LDA']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGR_1   Cross Validation Done in  2.0  minutes\n",
      "LGR_1   pickled to disk\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "    ('LGR', clf['LGR'])])\n",
    "\n",
    "md_LGR_1 = Analytica_Bolada(clf['LGR'], None, 'LGR_1') \n",
    "md_LGR_1.evaluate_CV(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC_1   Cross Validation Done in  2.0  minutes\n",
      "LinearSVC_1   pickled to disk\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "    ('LinearSVC', clf['LinearSVC'])])\n",
    "\n",
    "md_LinearSVC_1 = Analytica_Bolada(clf['LinearSVC'], None, 'LinearSVC_1')\n",
    "md_LinearSVC_1.evaluate_CV(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# mesmo com vocab 5k demora muito\n",
    "# pipe = Pipeline([\n",
    "#     ('col', Col_Extractor(['review'])),\n",
    "#     ('prep', Preprocessor()),\n",
    "\n",
    "#     ('feats', FeatureUnion([\n",
    "#         ('ngram_tf_idf', Pipeline([\n",
    "#             ('to_array', To_array()),\n",
    "#             ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "#             ('tf_idf', TfidfTransformer())])),\n",
    "#         ('mean_word_len', mean_word_len()),\n",
    "#     ])),\n",
    "#     ('To_dense', DenseTransformer()),\n",
    "#     ('LDA', clf['LDA'])])\n",
    "\n",
    "# md_LDA_1 = Analytica_Bolada(clf['LDA'], None, 'LDA_1')\n",
    "# md_LDA_1.evaluate_CV(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## TREES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DT', 'ADA', 'RF', 'XT', 'GB']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT_1   Cross Validation Done in  3.0  minutes\n",
      "DT_1   pickled to disk\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "#     ('Dense', DenseTransformer()),\n",
    "    ('DT', clf['DT'])])\n",
    "\n",
    "md_DT_1 = Analytica_Bolada(clf['DT'], None, 'DT_1')\n",
    "md_DT_1.evaluate_CV(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADA_1   Cross Validation Done in  3.0  minutes\n",
      "ADA_1   pickled to disk\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "#     ('Dense', DenseTransformer()),\n",
    "    ('ADA', clf['ADA'])])\n",
    "\n",
    "md_ADA_1 = Analytica_Bolada(clf['ADA'], None, 'ADA_1')\n",
    "md_ADA_1.evaluate_CV(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF_1   Cross Validation Done in  2.0  minutes\n",
      "RF_1   pickled to disk\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "#     ('Dense', DenseTransformer()),\n",
    "    ('RF', clf['RF'])])\n",
    "\n",
    "md_RF_1 = Analytica_Bolada(clf['RF'], None, 'RF_1')\n",
    "md_RF_1.evaluate_CV(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XT_1   Cross Validation Done in  2.0  minutes\n",
      "XT_1   pickled to disk\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "#     ('Dense', DenseTransformer()),\n",
    "    ('XT', clf['XT'])])\n",
    "\n",
    "md_XT_1 = Analytica_Bolada(clf['XT'], None, 'XT_1')\n",
    "md_XT_1.evaluate_CV(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB_1   Cross Validation Done in  5.0  minutes\n",
      "GB_1   pickled to disk\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "#     ('Dense', DenseTransformer()),\n",
    "    ('GB', clf['GB'])])\n",
    "\n",
    "md_GB_1 = Analytica_Bolada(clf['GB'], None, 'GB_1')\n",
    "md_GB_1.evaluate_CV(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## SVC,  NB,  KNN,  SGDC,  M_NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SVC', 'NB', 'KNN', 'SGDC', 'M_NB']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# pipe = Pipeline([\n",
    "#     ('col', Col_Extractor(['review'])),\n",
    "#     ('prep', Preprocessor()),\n",
    "\n",
    "#     ('feats', FeatureUnion([\n",
    "#         ('ngram_tf_idf', Pipeline([\n",
    "#             ('to_array', To_array()),\n",
    "#             ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "#             ('tf_idf', TfidfTransformer())])),\n",
    "#         ('mean_word_len', mean_word_len()),\n",
    "#     ])),\n",
    "#     ('SVC', clf['SVC'])])\n",
    "\n",
    "# md_SVC_1 = Analytica_Bolada(clf['SVC'], None, 'SVC_1')\n",
    "# md_SVC_1.evaluate_CV(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB_1   Cross Validation Done in  3.0  minutes\n",
      "NB_1   pickled to disk\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "    ('Dense', DenseTransformer()),\n",
    "    ('NB', clf['NB'])])\n",
    "\n",
    "md_NB_1 = Analytica_Bolada(clf['NB'], None, 'NB_1')\n",
    "md_NB_1.evaluate_CV(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_NB_1   Cross Validation Done in  1.0  minutes\n",
      "M_NB_1   pickled to disk\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "    ('M_NB', clf['M_NB'])])\n",
    "\n",
    "md_M_NB_1 = Analytica_Bolada(clf['M_NB'], None, 'M_NB_1')\n",
    "md_M_NB_1.evaluate_CV(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN_1   Cross Validation Done in  2.0  minutes\n",
      "KNN_1   pickled to disk\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "#     ('Dense', DenseTransformer()),\n",
    "    ('KNN', clf['KNN'])])\n",
    "\n",
    "md_KNN_1 = Analytica_Bolada(clf['KNN'], None, 'KNN_1')\n",
    "md_KNN_1.evaluate_CV(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDC_1   Cross Validation Done in  1.0  minutes\n",
      "SGDC_1   pickled to disk\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "#     ('Dense', DenseTransformer()),\n",
    "    ('SGDC', clf['SGDC'])])\n",
    "\n",
    "md_SGDC_1 = Analytica_Bolada(clf['SGDC'], None, 'SGDC_1')\n",
    "md_SGDC_1.evaluate_CV(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Round 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc : 0.76712\n",
      "LGR_2   pickled to disk\n",
      "LGR_2   HP2 done in  184.0  minutes\n"
     ]
    }
   ],
   "source": [
    "param['LGR_2'] = {\n",
    "    'feats__ngram_tf_idf__counts__min_df': hp.choice('zz_min_df', [2, 3, 4, 5]),\n",
    "    'feats__ngram_tf_idf__counts__ngram_range': hp.choice('ngram_range', [(1, 2), (1, 3)]),\n",
    "#     'feats__ngram_tf_idf__counts__analyzer': hp.choice('analyzer', ['word', 'char', 'char_wb']),\n",
    "    'feats__ngram_tf_idf__counts__analyzer': hp.choice('analyzer', ['char_wb', 'char']),\n",
    "    'LGR__penalty': hp.choice('LGR__penalty', ['l1', 'l2']),\n",
    "    'LGR__C': hp.uniform('LGR__C',1, 1000)\n",
    "}\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "    ('LGR', clf['LGR']) ])\n",
    "\n",
    "md_LGR_21 = Analytica_Bolada(clf['LGR'], param['LGR_2'], 'LGR_2')\n",
    "md_LGR_21.evaluate_HP2(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc : 0.83512\n",
      "GB_2   pickled to disk\n",
      "GB_2   HP2 done in  324.0  minutes\n"
     ]
    }
   ],
   "source": [
    "param['GB_2'] = {\n",
    "    'feats__ngram_tf_idf__counts__min_df': hp.choice('min_df', [2, 3, 4]),\n",
    "    'feats__ngram_tf_idf__counts__ngram_range': hp.choice('mngram_range', [(1, 2), (1, 3)]),\n",
    "    'feats__ngram_tf_idf__counts__analyzer': hp.choice('analyzer', ['word', 'char', 'char_wb']),\n",
    "    'feats__ngram_tf_idf__counts__stop_words': hp.choice('stop_words', [stop_words, None]),\n",
    "    'feats__ngram_tf_idf__counts__tokenizer': hp.choice('tokenizer', [tokenizer_split, tokenizer_porter]),\n",
    "    'GB__max_depth'        : hp.choice(\"max_depth\",        np.arange(4, 7,    dtype=int)), \n",
    "    'GB__learning_rate'    : hp.loguniform('learning_rate', -6.9, -2.3),\n",
    "#     'GB__n_estimators'     : hp.choice('n_estimators', 100, 500, 1000),\n",
    "    'GB__random_state'    : hp.randint('random_state',20)\n",
    "   }\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "    ('GB', clf['GB'])])\n",
    "\n",
    "# pipe.fit(X_train, y_train)\n",
    "md_GB_2 = Analytica_Bolada(clf['GB'], param['GB_2'], 'GB_2')\n",
    "md_GB_2.evaluate_HP2(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc : 0.82164\n",
      "RF_2   pickled to disk\n",
      "RF_2   HP2 done in  156.0  minutes\n"
     ]
    }
   ],
   "source": [
    "param['RF_2'] = {\n",
    "    'feats__ngram_tf_idf__counts__min_df': hp.choice('zz_min_df', [2, 3, 4]),\n",
    "    'feats__ngram_tf_idf__counts__ngram_range': hp.choice('zz_ngram_range', [(1, 2), (1, 3)]),\n",
    "    'feats__ngram_tf_idf__counts__analyzer': hp.choice('analyzer', ['word', 'char', 'char_wb']),\n",
    "    'feats__ngram_tf_idf__counts__stop_words': hp.choice('stop_words', [stop_words, None]),\n",
    "    'feats__ngram_tf_idf__counts__tokenizer': hp.choice('tokenizer', [tokenizer_split, tokenizer_porter]),\n",
    "    'RF__n_estimators': hp.choice('zz_RF__n_estimators',         np.arange(20, 1001, 50, dtype=int)),\n",
    "    'RF__max_depth': hp.choice(\"zz_RF__max_depth\",            np.arange(5, 100, 10,    dtype=int)),\n",
    "    'RF__min_samples_split': hp.choice(\"zz_RF__min_samples_split\",    np.arange(2, 30,    dtype=int)),\n",
    "    'RF__min_samples_leaf': hp.uniform(\"RF__min_samples_leaf\", 0, 0.5),\n",
    "    'RF__criterion': hp.choice('RF__criterion', [\"gini\", \"entropy\"]),\n",
    "    'RF__max_features': hp.choice('RF__max_features', ['auto', 'sqrt']),\n",
    "    'RF__n_jobs': -1,\n",
    "    'RF__oob_score': True,\n",
    "#     'RF__verbose': 1,\n",
    "    'RF__random_state': hp.randint('random_state', 20)\n",
    "}\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "    ('RF', clf['RF'])])\n",
    "\n",
    "# pipe.fit(X_train, y_train)\n",
    "md_RF_2 = Analytica_Bolada(clf['RF'], param['RF_2'], 'RF_2')\n",
    "md_RF_2.evaluate_HP2(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "Process ForkPoolWorker-1068:\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-32-4b61984864be>\", line 35, in <module>\n",
      "    md_XT_2.evaluate_HP2(pipe, pkl_W=True)\n",
      "  File \"<ipython-input-2-f3f465475882>\", line 116, in evaluate_HP2\n",
      "    best = fmin(objective, space, algo=tpe.suggest, max_evals=100, trials=T)  #  <---------------------------HERE<-----\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\", line 307, in fmin\n",
      "    return_argmin=return_argmin,\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/hyperopt/base.py\", line 635, in fmin\n",
      "    return_argmin=return_argmin)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\", line 320, in fmin\n",
      "    rval.exhaust()\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\", line 199, in exhaust\n",
      "    self.run(self.max_evals - n_done, block_until_done=self.async)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\", line 173, in run\n",
      "    self.serial_evaluate()\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\", line 92, in serial_evaluate\n",
      "    result = self.domain.evaluate(spec, ctrl)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/hyperopt/base.py\", line 840, in evaluate\n",
      "    rval = self.fn(pyll_rval)\n",
      "  File \"<ipython-input-2-f3f465475882>\", line 111, in objective\n",
      "    score = cross_val_score(pipe, X_train_internal, y_train, scoring='accuracy', cv=3, n_jobs=-1)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 342, in cross_val_score\n",
      "    pre_dispatch=pre_dispatch)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 206, in cross_validate\n",
      "    for train, test in cv.split(X, y, groups))\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 789, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 699, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 638, in get\n",
      "    self.wait(timeout)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 635, in wait\n",
      "    self._event.wait(timeout)\n",
      "  File \"/anaconda3/lib/python3.6/threading.py\", line 551, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/anaconda3/lib/python3.6/threading.py\", line 295, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/anaconda3/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/anaconda3/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/anaconda3/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/anaconda3/lib/python3.6/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/py/_vendored_packages/apipkg.py\", line 195, in __getattribute__\n",
      "    return getattr(getmod(), name)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/py/_vendored_packages/apipkg.py\", line 179, in getmod\n",
      "    x = importobj(modpath, None)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/py/_vendored_packages/apipkg.py\", line 69, in importobj\n",
      "    module = __import__(modpath, None, None, ['__doc__'])\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/pytest.py\", line 9, in <module>\n",
      "    from _pytest.config import (\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 674, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 779, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 487, in _compile_bytecode\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "param['XT_2'] = {\n",
    "    'feats__ngram_tf_idf__counts__min_df': hp.choice('zz_min_df', [2, 3, 4]),\n",
    "    'feats__ngram_tf_idf__counts__ngram_range': hp.choice('mngram_range', [(1, 2), (1, 3)]),\n",
    "    'feats__ngram_tf_idf__counts__analyzer': hp.choice('analyzer', ['word', 'char', 'char_wb']),\n",
    "    'feats__ngram_tf_idf__counts__stop_words': hp.choice('stop_words', [stop_words, None]),\n",
    "    'feats__ngram_tf_idf__counts__tokenizer': hp.choice('tokenizer', [tokenizer_split, tokenizer_porter]),\n",
    "    'XT__n_estimators': hp.choice('zz_XT__n_estimators',         np.arange(20, 1001, 50, dtype=int)),\n",
    "    'XT__max_depth': hp.choice(\"zz_XT__max_depth\",            np.arange(5, 100, 10,    dtype=int)),\n",
    "    'XT__min_samples_split': hp.choice(\"zz_XT__min_samples_split\",    np.arange(2, 30,    dtype=int)),\n",
    "    'XT__min_samples_leaf': hp.uniform(\"XT__min_samples_leaf\", 0, 0.5),\n",
    "    'XT__criterion': hp.choice('RF__criterion', [\"gini\", \"entropy\"]),\n",
    "    'XT__max_features': hp.choice('RF__max_features', ['auto', 'sqrt']),\n",
    "    'XT__n_jobs': -1,\n",
    "    'XT__oob_score': True,\n",
    "    'XT__bootstrap': True,\n",
    "#     'XT__verbose': 1,\n",
    "    'XT__random_state': hp.randint('random_state', 20)\n",
    "}\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "    ('XT', clf['XT'])])\n",
    "\n",
    "# pipe.fit(X_train, y_train)\n",
    "md_XT_2 = Analytica_Bolada(clf['XT'], param['XT_2'], 'XT_2')\n",
    "md_XT_2.evaluate_HP2(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# PLOTTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. clf_LGR_2 evaluation pickled from pisk\n"
     ]
    }
   ],
   "source": [
    "master.pkl_R('clf_LGR_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['GB_2', 'RF_2', 'LGR_2'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.get_members_evaluations_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving l_curve_ image for  GB_2\n",
      "saving l_curve_ image for  RF_2\n",
      "saving l_curve_ image for  LGR_2\n",
      "CPU times: user 6.85 s, sys: 5.1 s, total: 11.9 s\n",
      "Wall time: 1h 11min 19s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "master.plot_learning_curve(load_saved=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving c_reprt_ image for GB_2\n",
      "saving c_reprt_ image for RF_2\n",
      "saving c_reprt_ image for LGR_2\n",
      "CPU times: user 9min 59s, sys: 5.04 s, total: 10min 4s\n",
      "Wall time: 10min 6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "master.plot_Classification_Report(load_saved=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving c_matrx_ image for GB_2\n",
      "saving c_matrx_ image for RF_2\n",
      "saving c_matrx_ image for LGR_2\n",
      "CPU times: user 10min 6s, sys: 5.44 s, total: 10min 12s\n",
      "Wall time: 10min 19s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "master.plot_Confusion_Matrix(load_saved=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. clf_LGR_1 evaluation pickled from pisk\n",
      "Done. clf_DT_1 evaluation pickled from pisk\n",
      "Done. clf_ADA_1 evaluation pickled from pisk\n",
      "Done. clf_RF_1 evaluation pickled from pisk\n",
      "Done. clf_XT_1 evaluation pickled from pisk\n",
      "Done. clf_GB_1 evaluation pickled from pisk\n",
      "Done. clf_NB_1 evaluation pickled from pisk\n",
      "Done. clf_M_NB_1 evaluation pickled from pisk\n",
      "Done. clf_KNN_1 evaluation pickled from pisk\n",
      "Done. clf_LGR_2 evaluation pickled from pisk\n",
      " One or more evaluations were overwriten\n",
      "Done. clf_GB_2 evaluation pickled from pisk\n",
      " One or more evaluations were overwriten\n",
      "Done. clf_RF_2 evaluation pickled from pisk\n",
      " One or more evaluations were overwriten\n",
      "Done. clf_XT_2 evaluation pickled from pisk\n",
      "saving roc_auc_ image for LGR_1\n",
      "saving roc_auc_ image for DT_1\n",
      "saving roc_auc_ image for ADA_1\n",
      "saving roc_auc_ image for RF_1\n",
      "saving roc_auc_ image for XT_1\n",
      "saving roc_auc_ image for GB_1\n",
      "saving roc_auc_ image for NB_1\n",
      "saving roc_auc_ image for M_NB_1\n",
      "saving roc_auc_ image for KNN_1\n",
      "saving roc_auc_ image for LGR_2\n",
      "saving roc_auc_ image for GB_2\n",
      "saving roc_auc_ image for RF_2\n",
      "saving roc_auc_ image for XT_2\n",
      "CPU times: user 16min, sys: 1min 9s, total: 17min 9s\n",
      "Wall time: 22min 18s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "# com problemas: LinearSVC_1, SGDC_1\n",
    "L = ['LGR_1', 'DT_1', 'ADA_1', 'RF_1', 'XT_1', 'GB_1', 'NB_1', 'M_NB_1', 'KNN_1', 'LGR_2', 'GB_2', 'RF_2', 'XT_2']\n",
    "for i in L:\n",
    "    master.pkl_R('clf_'+ i)\n",
    "    \n",
    "master.plot_ROC_AUC(chosen=L, load_saved=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "345px",
    "left": "760px",
    "top": "122px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
