{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'timer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-30ccd18bf1f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# esse metodo retornou tempos muito maiores do que o metodo com datetime now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'timer' is not defined"
     ]
    }
   ],
   "source": [
    "# esse metodo retornou tempos muito maiores do que o metodo %%time\n",
    "start= timer()\n",
    "end = timer()\n",
    "end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementacao sem predict_proba\n",
    "class A2(object):\n",
    "\n",
    "    def __init__(self, instance, param_grid, my_name):\n",
    "        self.my_name = my_name\n",
    "        self.instance = instance\n",
    "        self.param_grid = param_grid\n",
    "        \n",
    "    def evaluate_HP_lGBM(self, pipe, pkl_W=False): \n",
    "        '''\n",
    "        aceita pipeline sem o step final. pipe.append()\n",
    "        '''\n",
    "        start= timer()\n",
    "        result_dict = {}\n",
    "\n",
    "    #         key = self.my_name.split('_')[0] # to use in pipe. From KNN_2 -> KNN. Must mach param_grid prefix\n",
    "        instance = self.instance\n",
    "        param_grid = self.param_grid\n",
    "\n",
    "        pipe_copy = None\n",
    "        pipe_copy = clone(pipe)\n",
    "        pipe_copy.steps.append([instance, clf[instance]])\n",
    "\n",
    "        def objective(params):\n",
    "            # Make sure parameters that need to be integers are integers\n",
    "            for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "                params[parameter_name] = int(params[parameter_name])\n",
    "\n",
    "\n",
    "            score = lgb.cv(params, data_train, nfold = 10, num_boost_round = 10000, \n",
    "                        early_stopping_rounds = 10, metrics = 'auc', seed = 50)\n",
    "            best_score = max(score['auc-mean'])\n",
    "            print(best_score)\n",
    "            return 1 - best_score\n",
    "\n",
    "        train_feature_matrix = pipe.fit_transform(X_train) # pipe descalco sem o ultimo\n",
    "        data_train = lgb.Dataset(train_feature_matrix, label=list(y_train.values.ravel()))\n",
    "\n",
    "        test_feature_matrix = pipe.fit_transform(X_test) # pipe descalco sem o ultimo\n",
    "        data_test = lgb.Dataset(test_feature_matrix, label=list(y_test.values.ravel()))\n",
    "\n",
    "\n",
    "        T = Trials()\n",
    "        space = param_grid\n",
    "        best = fmin(objective, space, algo=tpe.suggest, max_evals=5, trials=T)  #  <---------------------------HERE<-----\n",
    "        best_params = space_eval(space, best) # is the translation of best. Real Values, not steps.\n",
    "\n",
    "        for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "                best_params[parameter_name] = int(best_params[parameter_name])\n",
    "\n",
    "\n",
    "        best_model = lgb.train(best_params, data_train, valid_sets=[data_test], valid_names=['data_test'])   \n",
    "        print(best_model)\n",
    "#         y_pred = best_model.predict(test_feature_matrix)\n",
    "        y_pred = best_model.predict(test_feature_matrix)   # -------> AQUI o ERRO !!!!!!!\n",
    "        print(y_pred)\n",
    "        acc = accuracy_score(y_test, y_pred) \n",
    "        print('acc :', acc)\n",
    "        end = timer()\n",
    "        minutes_elapsed = (end - start)//60\n",
    "        Super_Analytica.evaluations_all[self.my_name] = {'score': acc, 'best_estimator': best_model, \\\n",
    "                                 'param_grid': param_grid, 'y_pred': y_pred, \\\n",
    "                                 'param_pipe': pipe_copy, 'instance':instance,\\\n",
    "                                 'best_params' : best_params, 'T': T, 'minutes': minutes_elapsed} \n",
    "\n",
    "\n",
    "        if  pkl_W:\n",
    "            D = {}\n",
    "            D[self.my_name]= Super_Analytica.evaluations_all[self.my_name]\n",
    "            joblib.dump(D, '../pkl/clf_'+ self.my_name + '.pkl') \n",
    "            print(self.my_name, ' HP_lightGBM and pickled to disk Done in',  minutes_elapsed, ' minutes' ) \n",
    "        else:\n",
    "            print(self.my_name, '  HP_lightGBM done in ', minutes_elapsed, ' minutes') \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Por alguma razao o metodo predict esta gerando probabilidades ao inves de previsoes binarias [0,1]. Por isso o erro em accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf['LGBM'] = lgb.LGBMClassifier(objective = 'binary', metric = ['auc'])\n",
    "md_LGBM = A2('LGBM', param['LGBM2'], '_1')\n",
    "md_LGBM.evaluate_HP_lGBM(pipe_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
