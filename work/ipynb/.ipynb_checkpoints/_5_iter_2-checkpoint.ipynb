{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Load Libraries / Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../modules/library_to_import.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../modules/Class_imdb.ipynb\n",
    "%run ../modules/transformers_imdb.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "\n",
    "# %matplotlib inline\n",
    "# sns.set(style='white', context='notebook', palette='deep')\n",
    "sns.set()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "evaluations_all -  it is a dictionary where all the information regarding models performance scores gets recorded. It`s the 'cloud'.\n",
    "\n",
    "By acessing the 'cloud' the Class Super_Analtica will work in groups.\n",
    "Analytica_bolada is lower level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's hard to put your finger on this one. Basi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I mean, nothing happens, 5 dumb kids go to Okl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Så som in himmelen\" was probably one of the 3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This noir may not be the best remembered film ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'll be honest with yall, I was a junior in hi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  It's hard to put your finger on this one. Basi...          1\n",
       "1  I mean, nothing happens, 5 dumb kids go to Okl...          0\n",
       "2  \"Så som in himmelen\" was probably one of the 3...          1\n",
       "3  This noir may not be the best remembered film ...          1\n",
       "4  I'll be honest with yall, I was a junior in hi...          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/movie_data.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['review'].values\n",
    "y = df['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./params_imdb.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's hard to put your finger on this one. Basi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I mean, nothing happens, 5 dumb kids go to Okl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Så som in himmelen\" was probably one of the 3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This noir may not be the best remembered film ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'll be honest with yall, I was a junior in hi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  It's hard to put your finger on this one. Basi...          1\n",
       "1  I mean, nothing happens, 5 dumb kids go to Okl...          0\n",
       "2  \"Så som in himmelen\" was probably one of the 3...          1\n",
       "3  This noir may not be the best remembered film ...          1\n",
       "4  I'll be honest with yall, I was a junior in hi...          1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      "review       50000 non-null object\n",
      "sentiment    50000 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 781.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.head()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.5\n",
       "0    0.5\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "feature union is for applying different vectorizers for different columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X  y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "\n",
    "# # DATAFRAMES USED ONLY WHEN NEED MORE THAN 1 COLUMN\n",
    "# WORKS with sklearn-pandas to drive dataframes in sklearn or column extractor e To_Matrix\n",
    "# X_train = df.loc[:500, ['review']].reset_index(drop=True)\n",
    "# y_train = df.loc[:500, ['sentiment']].reset_index(drop=True)\n",
    "# X_test = df.loc[49950:, ['review']].reset_index(drop=True)\n",
    "# y_test = df.loc[49950:, ['sentiment']].reset_index(drop=True)\n",
    "\n",
    "# X_train = df.loc[:25000, ['review']].reset_index(drop=True)\n",
    "# y_train = df.loc[:25000, ['sentiment']].reset_index(drop=True)\n",
    "# X_test = df.loc[25000:, ['review']].reset_index(drop=True)\n",
    "# y_test = df.loc[25000:, ['sentiment']].reset_index(drop=True)\n",
    "\n",
    "X_train = df.loc[:100, ['review']].reset_index(drop=True)\n",
    "y_train = df.loc[:100, ['sentiment']].reset_index(drop=True)\n",
    "X_test = df.loc[49900:, ['review']].reset_index(drop=True)\n",
    "y_test = df.loc[49900:, ['sentiment']].reset_index(drop=True)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=random_state)\n",
    "# kfold = 5\n",
    "# kfold = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_style": "split",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's hard to put your finger on this one. Basi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I mean, nothing happens, 5 dumb kids go to Okl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Så som in himmelen\" was probably one of the 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This noir may not be the best remembered film ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'll be honest with yall, I was a junior in hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Damon Runyon's world of Times Square, in New Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>After a group of young friends experience car ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What makes for Best Picture material? The Osca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I found this film extremely disturbing. Treadw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This DVD set is the complete widescreen 15-epi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kevin Kline and Meg Ryan are among that class ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Well...there were some great, creamy-smooth fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>If I had not read Pat Barker's 'Union Street' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>This movie is fun to watch. If you liked \"Dave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A charming, funny film that gets a solid grade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The movie is about a day in the life of a woma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I just rented this movie from the video store ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I suppose I always felt that Hotel du Nord was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I saw this on cable. Someone had to lose their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>I was one of quite a few extras in this big bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Raising Victor Vargas is a movie you definitel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>First of all, I believe that this movie is muc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Jörg Buttgereit goes a bit too far with his mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>I had the opportunity to see this last evening...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Certainly not horrible, but definitely not goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Before watching this movie from beginning to e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Outrageously trashy karate/horror thriller wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\"Death Promise\" is a lost 70's exploitation ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Of the Korean movies I've seen, only three had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Of course I have disappeared into the movies. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>well i don't know what people saw in this movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>So so special effects get in the way of recapt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Kirsten Dunst is terribly overrated as an actr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>The 3rd and in my view the best of the Blackad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>My one line summary should explain it all, but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>So ya think you've seen every Mafia movie ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>I enjoyed this film and after it finished it s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>I picked this film up based on the plot summar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>There are a number of reviews that comment on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>I've rented this gem several times! It's a sma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>First and foremost, I loved the novel by Ray B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>This movie is ridiculous. It's attempting to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Wow. I don't even really remember that much ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Well, I just ordered this on my pay-per-view a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>I was expecting a lot better from the Battlest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>i couldn't help but think of behind the mask: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Writers and directors, by the nature of their ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>The plot of this movie is as dumb as a bag of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>I can't believe that they took this off the ai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>It's very very funny. You know, just like a co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>It was all over with the slashers around 88 so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Jack Frost 2. THE worst \"horror film\" I have e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>This is what Disney Channel shows to kids who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>The acrobatics mixed with haunting music, make...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>While this is a faithful adaptation, it is muc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>War Inc. is a funny but strange film. The acto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>This is one of the best of the series, ranking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>My mother told me not to go to see \"Kadosh\" --...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>For those that were interested in knowing how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>That song keeps humming in my head. Not the gr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review\n",
       "0    It's hard to put your finger on this one. Basi...\n",
       "1    I mean, nothing happens, 5 dumb kids go to Okl...\n",
       "2    \"Så som in himmelen\" was probably one of the 3...\n",
       "3    This noir may not be the best remembered film ...\n",
       "4    I'll be honest with yall, I was a junior in hi...\n",
       "5    Damon Runyon's world of Times Square, in New Y...\n",
       "6    After a group of young friends experience car ...\n",
       "7    What makes for Best Picture material? The Osca...\n",
       "8    I found this film extremely disturbing. Treadw...\n",
       "9    This DVD set is the complete widescreen 15-epi...\n",
       "10   Kevin Kline and Meg Ryan are among that class ...\n",
       "11   Well...there were some great, creamy-smooth fa...\n",
       "12   If I had not read Pat Barker's 'Union Street' ...\n",
       "13   This movie is fun to watch. If you liked \"Dave...\n",
       "14   A charming, funny film that gets a solid grade...\n",
       "15   The movie is about a day in the life of a woma...\n",
       "16   I just rented this movie from the video store ...\n",
       "17   I suppose I always felt that Hotel du Nord was...\n",
       "18   I saw this on cable. Someone had to lose their...\n",
       "19   I was one of quite a few extras in this big bo...\n",
       "20   Raising Victor Vargas is a movie you definitel...\n",
       "21   First of all, I believe that this movie is muc...\n",
       "22   Jörg Buttgereit goes a bit too far with his mo...\n",
       "23   I had the opportunity to see this last evening...\n",
       "24   Certainly not horrible, but definitely not goo...\n",
       "25   Before watching this movie from beginning to e...\n",
       "26   Outrageously trashy karate/horror thriller wit...\n",
       "27   \"Death Promise\" is a lost 70's exploitation ge...\n",
       "28   Of the Korean movies I've seen, only three had...\n",
       "29   Of course I have disappeared into the movies. ...\n",
       "..                                                 ...\n",
       "71   well i don't know what people saw in this movi...\n",
       "72   So so special effects get in the way of recapt...\n",
       "73   Kirsten Dunst is terribly overrated as an actr...\n",
       "74   The 3rd and in my view the best of the Blackad...\n",
       "75   My one line summary should explain it all, but...\n",
       "76   So ya think you've seen every Mafia movie ever...\n",
       "77   I enjoyed this film and after it finished it s...\n",
       "78   I picked this film up based on the plot summar...\n",
       "79   There are a number of reviews that comment on ...\n",
       "80   I've rented this gem several times! It's a sma...\n",
       "81   First and foremost, I loved the novel by Ray B...\n",
       "82   This movie is ridiculous. It's attempting to b...\n",
       "83   Wow. I don't even really remember that much ab...\n",
       "84   Well, I just ordered this on my pay-per-view a...\n",
       "85   I was expecting a lot better from the Battlest...\n",
       "86   i couldn't help but think of behind the mask: ...\n",
       "87   Writers and directors, by the nature of their ...\n",
       "88   The plot of this movie is as dumb as a bag of ...\n",
       "89   I can't believe that they took this off the ai...\n",
       "90   It's very very funny. You know, just like a co...\n",
       "91   It was all over with the slashers around 88 so...\n",
       "92   Jack Frost 2. THE worst \"horror film\" I have e...\n",
       "93   This is what Disney Channel shows to kids who ...\n",
       "94   The acrobatics mixed with haunting music, make...\n",
       "95   While this is a faithful adaptation, it is muc...\n",
       "96   War Inc. is a funny but strange film. The acto...\n",
       "97   This is one of the best of the series, ranking...\n",
       "98   My mother told me not to go to see \"Kadosh\" --...\n",
       "99   For those that were interested in knowing how ...\n",
       "100  That song keeps humming in my head. Not the gr...\n",
       "\n",
       "[101 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_style": "split",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Visconti's masterpiece! I admit that I am unfa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Although this film has had a lot of praise, I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Did people expect \"Jurassic Park 3\" to be full...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One of the last great musicals of the 60s. I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I can't describe the feeling when I got this c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I really like this show. I can readily see how...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WOW! Pretty terrible stuff. The Richard Burton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OK, so this film is well acted. It has good di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>From the English accents to the so unnecessary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Now don't get me wrong, I love seeing half nak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I don't know about the rest of the viewers of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I watched this movie only because I was under ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Firstly, this movie works in the fact that it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I first saw BLOOD OF THE SAMURAI at its premie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>If I could i would give ZERO stars for this on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>This movie catches a lot of flak, but this is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>It is very hard to come up with new informatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I thought this movie was awful. I understand i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>To anyone who is interested, I have managed to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>I thought I was going to watch another Friday ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>I don't understand why this movie was released...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Seriously, what is THIS? Hooper has made such ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\"All men are guilty,\" says the chief of the po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The '80's were the best of times and worst of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>I just want to say that I am so glad somebody ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>A blaxploitation classic, this movie was terri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>The Blob is a classic 1950s B-movie sci-fi fli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>A lovely little film about the introduction of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt;I watched this movie just a little...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>I had high expectations following \"My Beautifu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>I understand what this movie was trying to por...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>There is part of one sequence where some water...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>I think we all begin a lot of reviews with, \"T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>My daughter liked it but I was aghast, that a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>I just saw this film again, I believe for the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>It utterly defeats me why Godard is taken so s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Jimmy (Heath Ledger) is given a simple job by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>I attempted to watch this film without being a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Bloody Birthday plays on the assumed innocence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Disappointing film. Performance of actors is w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>One of Warner Brothers best and highest grossi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>How this has not become a cult film I do not k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>The laughs are few and far between in this dul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>I wouldn't call \"We're Back! A Dinosaur's Stor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>I contend that whoever is ultimately responsib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>This was a well written tale of the Making of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Even if you know absolutely nothing about Irel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>`Rock star' is not on its way to any `stairway...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>I bought this game on an impulse buy from walm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>A poorly-paced sf/horror venture that takes it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>I don't understand how this garbage got on the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>What seemed as a good premise for a movie...un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Although compared with \"Mad Max\", this film is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>This show is a show that is great for adults a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>(No spoilers, just plot details) I can't under...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>I'd heard this Japanese flick is edgy, creativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>The director does not know what to do with a c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>I've seen this movie after watching Paltrow's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>I could never stand watching Happy Days after ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Stephen Hawkings is a genius. He is the king o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review\n",
       "0   Visconti's masterpiece! I admit that I am unfa...\n",
       "1   Although this film has had a lot of praise, I ...\n",
       "2   Did people expect \"Jurassic Park 3\" to be full...\n",
       "3   One of the last great musicals of the 60s. I w...\n",
       "4   I can't describe the feeling when I got this c...\n",
       "5   I really like this show. I can readily see how...\n",
       "6   WOW! Pretty terrible stuff. The Richard Burton...\n",
       "7   OK, so this film is well acted. It has good di...\n",
       "8   From the English accents to the so unnecessary...\n",
       "9   Now don't get me wrong, I love seeing half nak...\n",
       "10  I don't know about the rest of the viewers of ...\n",
       "11  I watched this movie only because I was under ...\n",
       "12  Firstly, this movie works in the fact that it ...\n",
       "13  I first saw BLOOD OF THE SAMURAI at its premie...\n",
       "14  If I could i would give ZERO stars for this on...\n",
       "15  This movie catches a lot of flak, but this is ...\n",
       "16  It is very hard to come up with new informatio...\n",
       "17  I thought this movie was awful. I understand i...\n",
       "18  To anyone who is interested, I have managed to...\n",
       "19  I thought I was going to watch another Friday ...\n",
       "20  I don't understand why this movie was released...\n",
       "21  Seriously, what is THIS? Hooper has made such ...\n",
       "22  \"All men are guilty,\" says the chief of the po...\n",
       "23  The '80's were the best of times and worst of ...\n",
       "24  I just want to say that I am so glad somebody ...\n",
       "25  A blaxploitation classic, this movie was terri...\n",
       "26  The Blob is a classic 1950s B-movie sci-fi fli...\n",
       "27  A lovely little film about the introduction of...\n",
       "28  <br /><br />I watched this movie just a little...\n",
       "29  I had high expectations following \"My Beautifu...\n",
       "..                                                ...\n",
       "70  I understand what this movie was trying to por...\n",
       "71  There is part of one sequence where some water...\n",
       "72  I think we all begin a lot of reviews with, \"T...\n",
       "73  My daughter liked it but I was aghast, that a ...\n",
       "74  I just saw this film again, I believe for the ...\n",
       "75  It utterly defeats me why Godard is taken so s...\n",
       "76  Jimmy (Heath Ledger) is given a simple job by ...\n",
       "77  I attempted to watch this film without being a...\n",
       "78  Bloody Birthday plays on the assumed innocence...\n",
       "79  Disappointing film. Performance of actors is w...\n",
       "80  One of Warner Brothers best and highest grossi...\n",
       "81  How this has not become a cult film I do not k...\n",
       "82  The laughs are few and far between in this dul...\n",
       "83  I wouldn't call \"We're Back! A Dinosaur's Stor...\n",
       "84  I contend that whoever is ultimately responsib...\n",
       "85  This was a well written tale of the Making of ...\n",
       "86  Even if you know absolutely nothing about Irel...\n",
       "87  `Rock star' is not on its way to any `stairway...\n",
       "88  I bought this game on an impulse buy from walm...\n",
       "89  A poorly-paced sf/horror venture that takes it...\n",
       "90  I don't understand how this garbage got on the...\n",
       "91  What seemed as a good premise for a movie...un...\n",
       "92  Although compared with \"Mad Max\", this film is...\n",
       "93  This show is a show that is great for adults a...\n",
       "94  (No spoilers, just plot details) I can't under...\n",
       "95  I'd heard this Japanese flick is edgy, creativ...\n",
       "96  The director does not know what to do with a c...\n",
       "97  I've seen this movie after watching Paltrow's ...\n",
       "98  I could never stand watching Happy Days after ...\n",
       "99  Stephen Hawkings is a genius. He is the king o...\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_style": "split",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentiment\n",
       "0            1\n",
       "1            0\n",
       "2            1\n",
       "3            1\n",
       "4            1\n",
       "5            1\n",
       "6            1\n",
       "7            1\n",
       "8            0\n",
       "9            1\n",
       "10           0\n",
       "11           0\n",
       "12           0\n",
       "13           1\n",
       "14           1\n",
       "15           0\n",
       "16           1\n",
       "17           1\n",
       "18           0\n",
       "19           0\n",
       "20           1\n",
       "21           1\n",
       "22           1\n",
       "23           1\n",
       "24           0\n",
       "25           1\n",
       "26           0\n",
       "27           1\n",
       "28           1\n",
       "29           0\n",
       "..         ...\n",
       "71           0\n",
       "72           0\n",
       "73           0\n",
       "74           1\n",
       "75           0\n",
       "76           1\n",
       "77           1\n",
       "78           1\n",
       "79           1\n",
       "80           1\n",
       "81           0\n",
       "82           0\n",
       "83           0\n",
       "84           0\n",
       "85           0\n",
       "86           0\n",
       "87           1\n",
       "88           1\n",
       "89           1\n",
       "90           1\n",
       "91           0\n",
       "92           0\n",
       "93           0\n",
       "94           1\n",
       "95           1\n",
       "96           1\n",
       "97           1\n",
       "98           0\n",
       "99           1\n",
       "100          0\n",
       "\n",
       "[101 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_style": "split",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment\n",
       "0           1\n",
       "1           0\n",
       "2           0\n",
       "3           1\n",
       "4           1\n",
       "5           1\n",
       "6           0\n",
       "7           0\n",
       "8           0\n",
       "9           0\n",
       "10          0\n",
       "11          0\n",
       "12          0\n",
       "13          1\n",
       "14          0\n",
       "15          1\n",
       "16          1\n",
       "17          0\n",
       "18          1\n",
       "19          1\n",
       "20          0\n",
       "21          0\n",
       "22          1\n",
       "23          0\n",
       "24          1\n",
       "25          1\n",
       "26          1\n",
       "27          1\n",
       "28          0\n",
       "29          0\n",
       "..        ...\n",
       "70          0\n",
       "71          0\n",
       "72          0\n",
       "73          0\n",
       "74          1\n",
       "75          0\n",
       "76          1\n",
       "77          0\n",
       "78          1\n",
       "79          0\n",
       "80          1\n",
       "81          1\n",
       "82          0\n",
       "83          1\n",
       "84          1\n",
       "85          1\n",
       "86          1\n",
       "87          1\n",
       "88          1\n",
       "89          0\n",
       "90          0\n",
       "91          0\n",
       "92          1\n",
       "93          1\n",
       "94          1\n",
       "95          0\n",
       "96          0\n",
       "97          1\n",
       "98          0\n",
       "99          1\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_style": "split",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "# X_train.info()\n",
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_style": "split",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n",
    "# y_train.info()\n",
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n",
    "# X_test.info()\n",
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape\n",
    "# y_train.info()\n",
    "type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_split(text):\n",
    "    return [porter.stem(w) for w in text.split(' ')]\n",
    "\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(w) for w in text.split(' ') if not w in stop_words ]\n",
    "\n",
    "tfidf = TfidfVectorizer(strip_accents=None, lowercase=False, preprocessor=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = Super_Analytica('master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../modules/params_imdb.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = ['num_words', 'num_unique_words' ,'num_chars', 'num_stopwords' ,'num_words_upper' ,'num_words_title', 'mean_word_len']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Vocabulary"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Pipeline standard \n",
    "explicar o prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 286 ms, sys: 3.02 ms, total: 289 ms\n",
      "Wall time: 293 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "    ('to_array', To_array()),\n",
    "    ('counts', CountVectorizer(analyzer=\"word\",\n",
    "                               tokenizer=tokenizer_porter,\n",
    "                               stop_words=stop_words,\n",
    "                               max_features=5000))\n",
    "])\n",
    "\n",
    "train_features_matrix = pipe.fit_transform(X_train)\n",
    "vocab = pipe.named_steps['counts'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<101x3420 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 8814 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3420"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_matrix\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# FEATURE IMPORTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# in order to measure feature importance for the new engineered features \n",
    "# we gonna use DataFrame Mapper from sklearn-pandas. \n",
    "# dessa maneira eu consigo declarar as novas features \n",
    "# as transformers and pipeline it, thus saving me the hassle of applying each feature to both train and test.\n",
    "# although this library applies the new features on the fly (pipeline) it has a attribute that returns feature names\n",
    "# making it easy to do feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc : 0.49\n",
      "DT_1   HP2 Done. Model is Fitted and Scored. Results in Evaluations_all.\n"
     ]
    }
   ],
   "source": [
    "# DATAFRAME MAPPER para calcular feat importances das new features\n",
    "# \n",
    "\n",
    "param['DT_1'] = {\"DT__criterion\" :'gini'}\n",
    "\n",
    "map_prep = DataFrameMapper([\n",
    "    (['review'], Preprocessor())], input_df=True, df_out=True)\n",
    "\n",
    "map_tfidf = DataFrameMapper([\n",
    "    ('review', [To_array(), TfidfVectorizer()])], input_df = True)\n",
    "\n",
    "mapper_super_feat_eng = DataFrameMapper([\n",
    "    (['review'], num_stop_words(), {'alias': 'n_stop_w'}),\n",
    "    (['review'], num_uni_words(), {'alias': 'n_uni_w'}),\n",
    "    (['review'], num_words_title(), {'alias': 'n_w_title'}),\n",
    "    (['review'], mean_word_len(), {'alias': 'm_w_len'})], input_df=True)\n",
    "\n",
    "\n",
    "# Feature_Importances - todos os transformers dentro de um mesmo mapper. \n",
    "pipe = Pipeline([\n",
    "    ('prep', map_prep),\n",
    "    ('f1', FeatureUnion([\n",
    "#         ('tfidf', map_tfidf),\n",
    "        ('new_features', mapper_super_feat_eng)\n",
    "    ])),\n",
    "    ('DT', clf['DT'])])\n",
    "\n",
    "md_DT_1 = Analytica_Bolada(clf['DT'], param['DT_1'], 'DT_1')\n",
    "md_DT_1.evaluate_HP2(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "master.plot_feature_importance_mapper(pipe,mapper_super_feat_eng, 'DT' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# INICIAL ROUND"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this section we gonna evaluate the estimators with its default parameter.\n",
    "All models in this section share the same pipeline structure, except fot the final element.\n",
    "Couldn`t make use of all dataset due to memory capabilities of my mac pro. Used 8000 samples for training and another 8000 samples for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APAGAR INICIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_1_2 = ['LGR_1_3', 'LGR_1_2_3', 'LinearSVC_1_3', 'DT_1_2', 'ADA_1_2', 'RF_1_2', 'XT_1_2',\\\n",
    "          'GB_1_2', 'NB_1_2', 'M_NB_1_2', 'KNN_1_2', 'SGDC_1_2', 'LGR_2_2', 'GB_2_2', 'RF_2_2', 'XT_2_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. clf_LGR_1_2 evaluation pickled from pisk\n",
      "Done. clf_LGR_1_2_2 evaluation pickled from pisk\n",
      "Done. clf_LinearSVC_1_2 evaluation pickled from pisk\n",
      "Done. clf_DT_1_2 evaluation pickled from pisk\n",
      "Done. clf_ADA_1_2 evaluation pickled from pisk\n",
      "Done. clf_RF_1_2 evaluation pickled from pisk\n",
      "Done. clf_XT_1_2 evaluation pickled from pisk\n",
      "Done. clf_GB_1_2 evaluation pickled from pisk\n",
      "Done. clf_NB_1_2 evaluation pickled from pisk\n",
      "Done. clf_M_NB_1_2 evaluation pickled from pisk\n",
      "Done. clf_KNN_1_2 evaluation pickled from pisk\n",
      "Done. clf_SGDC_1_2 evaluation pickled from pisk\n",
      "Done. clf_LGR_2_2 evaluation pickled from pisk\n",
      "Done. clf_GB_2_2 evaluation pickled from pisk\n",
      "Done. clf_RF_2_2 evaluation pickled from pisk\n",
      "Done. clf_XT_2_2 evaluation pickled from pisk\n"
     ]
    }
   ],
   "source": [
    "# APAGAR\n",
    "for m in md_1_2:\n",
    "    master.pkl_R('clf_'+ m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APAGAR FIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LINEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['LGR_1_2', 'LGR_1_2_2', 'LinearSVC_1_2', 'DT_1_2', 'ADA_1_2', 'RF_1_2', 'XT_1_2', 'GB_1_2', 'NB_1_2', 'M_NB_1_2', 'KNN_1_2', 'SGDC_1_2', 'LGR_2_2', 'GB_2_2', 'RF_2_2', 'XT_2_2'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.get_members_evaluations_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LinearSVC', 'LGR', 'LDA']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGR_1_3   Cross Validation is Done in  0.02 minutes\n",
      "LGR_1_3   pickled to disk\n",
      "CPU times: user 349 ms, sys: 80.8 ms, total: 429 ms\n",
      "Wall time: 1.36 s\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now() \n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "    ('LGR', clf['LGR'])])\n",
    "\n",
    "md_LGR_1 = Analytica_Bolada(clf['LGR'], None, 'LGR_1_2')\n",
    "md_LGR_1.evaluate_CV(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGR_1_2_2   Cross Validation is Done\n",
      "LGR_1_2_2   pickled to disk\n",
      "Function Time elapsed  (hh:mm:ss.ms) 0:02:05.375569\n",
      "Time elapsed (hh:mm:ss.ms) 0:02:05.401178\n",
      "CPU times: user 1.37 s, sys: 1.2 s, total: 2.57 s\n",
      "Wall time: 2min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "    ('Scalar', StandardScaler(with_mean=False)),\n",
    "    ('LGR', clf['LGR'])])\n",
    "\n",
    "md_LGR_1_2 = Analytica_Bolada(clf['LGR'], None, 'LGR_1_2_2')\n",
    "md_LGR_1_2.evaluate_CV(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC_1_2   Cross Validation is Done\n",
      "LinearSVC_1_2   pickled to disk\n",
      "Function Time elapsed  (hh:mm:ss.ms) 0:02:18.861785\n",
      "Time elapsed (hh:mm:ss.ms) 0:02:18.887405\n",
      "CPU times: user 1.37 s, sys: 1.26 s, total: 2.63 s\n",
      "Wall time: 2min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = datetime.now() \n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "    ('LinearSVC', clf['LinearSVC'])])\n",
    "\n",
    "md_LinearSVC_1 = Analytica_Bolada(clf['LinearSVC'], None, 'LinearSVC_1_2')\n",
    "md_LinearSVC_1.evaluate_CV(pipe, pkl_W=True)\n",
    "\n",
    "time_elapsed = datetime.now() - start_time \n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## TREES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DT', 'ADA', 'RF', 'XT', 'GB']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT_1_2   Cross Validation is Done\n",
      "DT_1_2   pickled to disk\n",
      "Function Time elapsed  (hh:mm:ss.ms) 0:03:24.705456\n",
      "Time elapsed (hh:mm:ss.ms) 0:03:24.734313\n",
      "CPU times: user 1.4 s, sys: 1.21 s, total: 2.61 s\n",
      "Wall time: 3min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = datetime.now() \n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "#     ('Dense', DenseTransformer()),\n",
    "    ('DT', clf['DT'])])\n",
    "\n",
    "md_DT_1 = Analytica_Bolada(clf['DT'], None, 'DT_1_2')\n",
    "md_DT_1.evaluate_CV(pipe, pkl_W=True)\n",
    "\n",
    "time_elapsed = datetime.now() - start_time \n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADA_1_2   Cross Validation is Done\n",
      "ADA_1_2   pickled to disk\n",
      "Function Time elapsed  (hh:mm:ss.ms) 0:03:26.247858\n",
      "Time elapsed (hh:mm:ss.ms) 0:03:26.273189\n",
      "CPU times: user 1.41 s, sys: 1.22 s, total: 2.62 s\n",
      "Wall time: 3min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = datetime.now() \n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "#     ('Dense', DenseTransformer()),\n",
    "    ('ADA', clf['ADA'])])\n",
    "\n",
    "md_ADA_1 = Analytica_Bolada(clf['ADA'], None, 'ADA_1_2')\n",
    "md_ADA_1.evaluate_CV(pipe, pkl_W=True)\n",
    "\n",
    "time_elapsed = datetime.now() - start_time \n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF_1_2   Cross Validation is Done\n",
      "RF_1_2   pickled to disk\n",
      "Function Time elapsed  (hh:mm:ss.ms) 0:02:23.416567\n",
      "Time elapsed (hh:mm:ss.ms) 0:02:23.442267\n",
      "CPU times: user 1.34 s, sys: 1.18 s, total: 2.52 s\n",
      "Wall time: 2min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = datetime.now() \n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "#     ('Dense', DenseTransformer()),\n",
    "    ('RF', clf['RF'])])\n",
    "\n",
    "md_RF_1 = Analytica_Bolada(clf['RF'], None, 'RF_1_2')\n",
    "md_RF_1.evaluate_CV(pipe, pkl_W=True)\n",
    "\n",
    "time_elapsed = datetime.now() - start_time \n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XT_1_2   Cross Validation is Done\n",
      "XT_1_2   pickled to disk\n",
      "Function Time elapsed  (hh:mm:ss.ms) 0:02:41.226757\n",
      "Time elapsed (hh:mm:ss.ms) 0:02:41.251782\n",
      "CPU times: user 1.34 s, sys: 1.19 s, total: 2.53 s\n",
      "Wall time: 2min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = datetime.now() \n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "#     ('Dense', DenseTransformer()),\n",
    "    ('XT', clf['XT'])])\n",
    "\n",
    "md_XT_1 = Analytica_Bolada(clf['XT'], None, 'XT_1_2')\n",
    "md_XT_1.evaluate_CV(pipe, pkl_W=True)\n",
    "\n",
    "time_elapsed = datetime.now() - start_time \n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB_1_2   Cross Validation is Done\n",
      "GB_1_2   pickled to disk\n",
      "Function Time elapsed  (hh:mm:ss.ms) 0:05:37.592767\n",
      "Time elapsed (hh:mm:ss.ms) 0:05:37.620549\n",
      "CPU times: user 1.47 s, sys: 1.25 s, total: 2.72 s\n",
      "Wall time: 5min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = datetime.now() \n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "#     ('Dense', DenseTransformer()),\n",
    "    ('GB', clf['GB'])])\n",
    "\n",
    "md_GB_1 = Analytica_Bolada(clf['GB'], None, 'GB_1_2')\n",
    "md_GB_1.evaluate_CV(pipe, pkl_W=True)\n",
    "\n",
    "time_elapsed = datetime.now() - start_time \n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## SVC,  NB,  KNN,  SGDC,  M_NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SVC', 'NB', 'KNN', 'SGDC', 'M_NB']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# pipe = Pipeline([\n",
    "#     ('col', Col_Extractor(['review'])),\n",
    "#     ('prep', Preprocessor()),\n",
    "\n",
    "#     ('feats', FeatureUnion([\n",
    "#         ('ngram_tf_idf', Pipeline([\n",
    "#             ('to_array', To_array()),\n",
    "#             ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "#             ('tf_idf', TfidfTransformer())])),\n",
    "#         ('mean_word_len', mean_word_len()),\n",
    "#     ])),\n",
    "#     ('SVC', clf['SVC'])])\n",
    "\n",
    "# md_SVC_1 = Analytica_Bolada(clf['SVC'], None, 'SVC_1')\n",
    "# md_SVC_1.evaluate_CV(pipe, pkl_W=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB_1_2   Cross Validation is Done\n",
      "NB_1_2   pickled to disk\n",
      "Function Time elapsed  (hh:mm:ss.ms) 0:03:09.625812\n",
      "Time elapsed (hh:mm:ss.ms) 0:03:09.665341\n",
      "CPU times: user 1.52 s, sys: 1.64 s, total: 3.16 s\n",
      "Wall time: 3min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = datetime.now() \n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "    ('Dense', DenseTransformer()),\n",
    "    ('NB', clf['NB'])])\n",
    "\n",
    "md_NB_1 = Analytica_Bolada(clf['NB'], None, 'NB_1_2')\n",
    "md_NB_1.evaluate_CV(pipe, pkl_W=True)\n",
    "\n",
    "time_elapsed = datetime.now() - start_time \n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_NB_1_2   Cross Validation is Done\n",
      "M_NB_1_2   pickled to disk\n",
      "Function Time elapsed  (hh:mm:ss.ms) 0:01:49.756894\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:49.787478\n",
      "CPU times: user 1.4 s, sys: 1.15 s, total: 2.54 s\n",
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = datetime.now() \n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "    ('M_NB', clf['M_NB'])])\n",
    "\n",
    "md_M_NB_1 = Analytica_Bolada(clf['M_NB'], None, 'M_NB_1_2')\n",
    "md_M_NB_1.evaluate_CV(pipe, pkl_W=True)\n",
    "\n",
    "time_elapsed = datetime.now() - start_time \n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN_1_2   Cross Validation is Done\n",
      "KNN_1_2   pickled to disk\n",
      "Function Time elapsed  (hh:mm:ss.ms) 0:02:24.527908\n",
      "Time elapsed (hh:mm:ss.ms) 0:02:24.555791\n",
      "CPU times: user 1.39 s, sys: 1.12 s, total: 2.51 s\n",
      "Wall time: 2min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# tirei o dense pra ver se agora vai\n",
    "start_time = datetime.now() \n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "#     ('Dense', DenseTransformer()),\n",
    "    ('KNN', clf['KNN'])])\n",
    "\n",
    "md_KNN_1 = Analytica_Bolada(clf['KNN'], None, 'KNN_1_2')\n",
    "md_KNN_1.evaluate_CV(pipe, pkl_W=True)\n",
    "\n",
    "time_elapsed = datetime.now() - start_time \n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDC_1_2   Cross Validation is Done\n",
      "SGDC_1_2   pickled to disk\n",
      "Function Time elapsed  (hh:mm:ss.ms) 0:01:49.561272\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:49.586501\n",
      "CPU times: user 1.37 s, sys: 1.03 s, total: 2.4 s\n",
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = datetime.now() \n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "#     ('Dense', DenseTransformer()),\n",
    "    ('SGDC', clf['SGDC'])])\n",
    "\n",
    "md_SGDC_1 = Analytica_Bolada(clf['SGDC'], None, 'SGDC_1_2')\n",
    "md_SGDC_1.evaluate_CV(pipe, pkl_W=True)\n",
    "\n",
    "time_elapsed = datetime.now() - start_time \n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Round 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc : 0.76692\n",
      "LGR_2_2   pickled to disk\n",
      "LGR_2_2   HP2 Done. Model is Fitted and Scored. Results in Evaluations_all.\n",
      "Time elapsed (hh:mm:ss.ms) 0:08:16.207972\n",
      "CPU times: user 4min 43s, sys: 1.13 s, total: 4min 44s\n",
      "Wall time: 8min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = datetime.now() \n",
    "param['LGR_2'] = {\n",
    "    'feats__ngram_tf_idf__counts__min_df': hp.choice('zz_min_df', [2, 3, 4, 5]),\n",
    "    'feats__ngram_tf_idf__counts__ngram_range': hp.choice('ngram_range', [(1, 2), (1, 3)]),\n",
    "#     'feats__ngram_tf_idf__counts__analyzer': hp.choice('analyzer', ['word', 'char', 'char_wb']),\n",
    "    'feats__ngram_tf_idf__counts__analyzer': hp.choice('analyzer', ['char_wb', 'char']),\n",
    "#     'feats__ngram_tf_idf__counts__stop_words': hp.choice('stop_words', [stop_words, None]),\n",
    "#     'feats__ngram_tf_idf__counts__tokenizer': hp.choice('tokenizer', [tokenizer_split, tokenizer_porter]),\n",
    "    'LGR__penalty': hp.choice('LGR__penalty', ['l1', 'l2']),\n",
    "    'LGR__C': hp.uniform('LGR__C',1, 1000)\n",
    "}\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "    ('LGR', clf['LGR']) ])\n",
    "\n",
    "md_LGR_21 = Analytica_Bolada(clf['LGR'], param['LGR_2'], 'LGR_2_2')\n",
    "md_LGR_21.evaluate_HP2(pipe, pkl_W=True)\n",
    "\n",
    "time_elapsed = datetime.now() - start_time \n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc : 0.61896\n",
      "GB_2_2   pickled to disk\n",
      "GB_2_2   HP2 Done. Model is Fitted and Scored. Results in Evaluations_all.\n",
      "Time elapsed (hh:mm:ss.ms) 0:05:03.840186\n",
      "CPU times: user 3min 1s, sys: 680 ms, total: 3min 2s\n",
      "Wall time: 5min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = datetime.now() \n",
    "param['GB_2'] = {\n",
    "    'feats__ngram_tf_idf__counts__min_df': hp.choice('min_df', [2, 3, 4]),\n",
    "    'feats__ngram_tf_idf__counts__ngram_range': hp.choice('mngram_range', [(1, 2), (1, 3)]),\n",
    "    'feats__ngram_tf_idf__counts__analyzer': hp.choice('analyzer', ['word', 'char', 'char_wb']),\n",
    "    'feats__ngram_tf_idf__counts__stop_words': hp.choice('stop_words', [stop_words, None]),\n",
    "    'feats__ngram_tf_idf__counts__tokenizer': hp.choice('tokenizer', [tokenizer_split, tokenizer_porter]),\n",
    "    'GB__max_depth'        : hp.choice(\"max_depth\",        np.arange(4, 7,    dtype=int)), \n",
    "    'GB__learning_rate'    : hp.loguniform('learning_rate', -6.9, -2.3),\n",
    "#     'GB__n_estimators'     : hp.choice('n_estimators', 100, 500, 1000),\n",
    "    'GB__random_state'    : hp.randint('random_state',20)\n",
    "   }\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "    ('GB', clf['GB'])])\n",
    "\n",
    "# pipe.fit(X_train, y_train)\n",
    "md_GB_2 = Analytica_Bolada(clf['GB'], param['GB_2'], 'GB_2_2')\n",
    "md_GB_2.evaluate_HP2(pipe, pkl_W=True)\n",
    "\n",
    "time_elapsed = datetime.now() - start_time \n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc : 0.49444\n",
      "RF_2_2   pickled to disk\n",
      "RF_2_2   HP2 Done. Model is Fitted and Scored. Results in Evaluations_all.\n",
      "Time elapsed (hh:mm:ss.ms) 0:07:43.958674\n",
      "CPU times: user 5min 11s, sys: 1.22 s, total: 5min 12s\n",
      "Wall time: 7min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = datetime.now() \n",
    "# RF\n",
    "start = timer()\n",
    "param['RF_2'] = {\n",
    "    'feats__ngram_tf_idf__counts__min_df': hp.choice('zz_min_df', [2, 3, 4]),\n",
    "    'feats__ngram_tf_idf__counts__ngram_range': hp.choice('zz_ngram_range', [(1, 2), (1, 3)]),\n",
    "    'feats__ngram_tf_idf__counts__analyzer': hp.choice('analyzer', ['word', 'char', 'char_wb']),\n",
    "    'feats__ngram_tf_idf__counts__stop_words': hp.choice('stop_words', [stop_words, None]),\n",
    "    'feats__ngram_tf_idf__counts__tokenizer': hp.choice('tokenizer', [tokenizer_split, tokenizer_porter]),\n",
    "    'RF__n_estimators': hp.choice('zz_RF__n_estimators',         np.arange(20, 1001, 50, dtype=int)),\n",
    "    'RF__max_depth': hp.choice(\"zz_RF__max_depth\",            np.arange(5, 100, 10,    dtype=int)),\n",
    "    'RF__min_samples_split': hp.choice(\"zz_RF__min_samples_split\",    np.arange(2, 30,    dtype=int)),\n",
    "    'RF__min_samples_leaf': hp.uniform(\"RF__min_samples_leaf\", 0, 0.5),\n",
    "    'RF__criterion': hp.choice('RF__criterion', [\"gini\", \"entropy\"]),\n",
    "    'RF__max_features': hp.choice('RF__max_features', ['auto', 'sqrt']),\n",
    "    'RF__n_jobs': -1,\n",
    "    'RF__oob_score': True,\n",
    "#     'RF__verbose': 1,\n",
    "    'RF__random_state': hp.randint('random_state', 20)\n",
    "}\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "    ('RF', clf['RF'])])\n",
    "\n",
    "# pipe.fit(X_train, y_train)\n",
    "md_RF_2 = Analytica_Bolada(clf['RF'], param['RF_2'], 'RF_2_2')\n",
    "md_RF_2.evaluate_HP2(pipe, pkl_W=True)\n",
    "\n",
    "time_elapsed = datetime.now() - start_time \n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc : 0.49444\n",
      "XT_2_2   pickled to disk\n",
      "XT_2_2   HP2 Done. Model is Fitted and Scored. Results in Evaluations_all.\n",
      "Time elapsed (hh:mm:ss.ms) 0:03:28.807762\n",
      "CPU times: user 2min 24s, sys: 2.82 s, total: 2min 27s\n",
      "Wall time: 3min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = datetime.now() \n",
    "# XT\n",
    "start = timer()\n",
    "param['XT_2'] = {\n",
    "    'feats__ngram_tf_idf__counts__min_df': hp.choice('zz_min_df', [2, 3, 4]),\n",
    "    'feats__ngram_tf_idf__counts__ngram_range': hp.choice('mngram_range', [(1, 2), (1, 3)]),\n",
    "    'feats__ngram_tf_idf__counts__analyzer': hp.choice('analyzer', ['word', 'char', 'char_wb']),\n",
    "    'feats__ngram_tf_idf__counts__stop_words': hp.choice('stop_words', [stop_words, None]),\n",
    "    'feats__ngram_tf_idf__counts__tokenizer': hp.choice('tokenizer', [tokenizer_split, tokenizer_porter]),\n",
    "    'XT__n_estimators': hp.choice('zz_XT__n_estimators',         np.arange(20, 1001, 50, dtype=int)),\n",
    "    'XT__max_depth': hp.choice(\"zz_XT__max_depth\",            np.arange(5, 100, 10,    dtype=int)),\n",
    "    'XT__min_samples_split': hp.choice(\"zz_XT__min_samples_split\",    np.arange(2, 30,    dtype=int)),\n",
    "    'XT__min_samples_leaf': hp.uniform(\"XT__min_samples_leaf\", 0, 0.5),\n",
    "    'XT__criterion': hp.choice('RF__criterion', [\"gini\", \"entropy\"]),\n",
    "    'XT__max_features': hp.choice('RF__max_features', ['auto', 'sqrt']),\n",
    "    'XT__n_jobs': -1,\n",
    "    'XT__oob_score': True,\n",
    "    'XT__bootstrap': True,\n",
    "#     'XT__verbose': 1,\n",
    "    'XT__random_state': hp.randint('random_state', 20)\n",
    "}\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('col', Col_Extractor(['review'])),\n",
    "    ('prep', Preprocessor()),\n",
    "\n",
    "    ('feats', FeatureUnion([\n",
    "        ('ngram_tf_idf', Pipeline([\n",
    "            ('to_array', To_array()),\n",
    "            ('counts', CountVectorizer(vocabulary=vocab)),\n",
    "            ('tf_idf', TfidfTransformer())])),\n",
    "        ('mean_word_len', mean_word_len()),\n",
    "    ])),\n",
    "    ('XT', clf['XT'])])\n",
    "\n",
    "# pipe.fit(X_train, y_train)\n",
    "md_XT_2 = Analytica_Bolada(clf['XT'], param['XT_2'], 'XT_2_2')\n",
    "md_XT_2.evaluate_HP2(pipe, pkl_W=True)\n",
    "\n",
    "time_elapsed = datetime.now() - start_time \n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "master.get_members_evaluations_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGR_1_2\n",
      "saving l_curve_ image for  LGR_1_2\n",
      "LGR_1_2_2\n",
      "saving l_curve_ image for  LGR_1_2_2\n",
      "LinearSVC_1_2\n",
      "saving l_curve_ image for  LinearSVC_1_2\n",
      "DT_1_2\n",
      "saving l_curve_ image for  DT_1_2\n",
      "ADA_1_2\n",
      "saving l_curve_ image for  ADA_1_2\n",
      "RF_1_2\n",
      "saving l_curve_ image for  RF_1_2\n",
      "XT_1_2\n",
      "saving l_curve_ image for  XT_1_2\n",
      "GB_1_2\n",
      "saving l_curve_ image for  GB_1_2\n",
      "NB_1_2\n",
      "saving l_curve_ image for  NB_1_2\n",
      "M_NB_1_2\n",
      "saving l_curve_ image for  M_NB_1_2\n",
      "KNN_1_2\n",
      "saving l_curve_ image for  KNN_1_2\n",
      "SGDC_1_2\n",
      "saving l_curve_ image for  SGDC_1_2\n",
      "LGR_2_2\n",
      "saving l_curve_ image for  LGR_2_2\n",
      "GB_2_2\n",
      "saving l_curve_ image for  GB_2_2\n",
      "RF_2_2\n",
      "saving l_curve_ image for  RF_2_2\n",
      "XT_2_2\n",
      "saving l_curve_ image for  XT_2_2\n",
      "saving c_reprt_ image for LGR_1_2\n",
      "saving c_reprt_ image for LGR_1_2_2\n",
      "saving c_reprt_ image for LinearSVC_1_2\n",
      "saving c_reprt_ image for DT_1_2\n",
      "saving c_reprt_ image for ADA_1_2\n",
      "saving c_reprt_ image for RF_1_2\n",
      "saving c_reprt_ image for XT_1_2\n",
      "saving c_reprt_ image for GB_1_2\n",
      "saving c_reprt_ image for NB_1_2\n",
      "saving c_reprt_ image for M_NB_1_2\n",
      "saving c_reprt_ image for KNN_1_2\n",
      "saving c_reprt_ image for SGDC_1_2\n",
      "saving c_reprt_ image for LGR_2_2\n",
      "saving c_reprt_ image for GB_2_2\n",
      "saving c_reprt_ image for RF_2_2\n",
      "saving c_reprt_ image for XT_2_2\n",
      "saving c_matrx_ image for LGR_1_2\n",
      "saving c_matrx_ image for LGR_1_2_2\n",
      "saving c_matrx_ image for LinearSVC_1_2\n",
      "saving c_matrx_ image for DT_1_2\n",
      "saving c_matrx_ image for ADA_1_2\n",
      "saving c_matrx_ image for RF_1_2\n",
      "saving c_matrx_ image for XT_1_2\n",
      "saving c_matrx_ image for GB_1_2\n",
      "saving c_matrx_ image for NB_1_2\n",
      "saving c_matrx_ image for M_NB_1_2\n",
      "saving c_matrx_ image for KNN_1_2\n",
      "saving c_matrx_ image for SGDC_1_2\n",
      "saving c_matrx_ image for LGR_2_2\n",
      "saving c_matrx_ image for GB_2_2\n",
      "saving c_matrx_ image for RF_2_2\n",
      "saving c_matrx_ image for XT_2_2\n",
      "CPU times: user 38min 5s, sys: 2min 32s, total: 40min 38s\n",
      "Wall time: 2h 55min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "master.plot_learning_curve(load_saved=False)\n",
    "master.plot_Classification_Report(load_saved=False)\n",
    "master.plot_Confusion_Matrix(load_saved=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving roc_auc_ image for LGR_1_2\n",
      "saving roc_auc_ image for LGR_1_2_2\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-caa0e9a72533>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmaster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_ROC_AUC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_saved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-bf17829c688b>\u001b[0m in \u001b[0;36mplot_ROC_AUC\u001b[0;34m(self, load_saved, chosen)\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0mvisualizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mROCAUC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mvisualizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m                 \u001b[0mvisualizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m                 \u001b[0mvisualizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../pkl/roc_auc_'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/yellowbrick/classifier/rocauc.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m# Compute ROC curve and ROC area for each class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_auc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "master.plot_ROC_AUC(load_saved=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "328px",
    "left": "797px",
    "top": "93px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
